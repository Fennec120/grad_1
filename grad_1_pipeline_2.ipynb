{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "fb2aa0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import json\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0b8766df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_action(df3):\n",
    "    print('event_action start')\n",
    "    target_action = ['sub_car_claim_click', \n",
    "                 'sub_car_claim_submit_click',\n",
    "                 'sub_open_dialog_click', \n",
    "                 'sub_custom_question_submit_click', \n",
    "                 'sub_call_number_click', \n",
    "                 'sub_callback_submit_click', \n",
    "                 'sub_submit_success', \n",
    "                 'sub_car_request_submit_click'\n",
    "                ]\n",
    "\n",
    "    df3['event_action'] = df3['event_action'].apply(lambda x: 1 if x in target_action else 0)\n",
    "    \n",
    "    print( 'event_action end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "77d1991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_df3(df3, total_rows =  200000, neg_percent = 50, pos_percent = 50):\n",
    "    print( 'sample_df3 start')\n",
    "    df3_pos = df3[df3['event_action'] == 1].sample(int(total_rows / 100 * pos_percent))\n",
    "    df3_neg = df3[df3['event_action'] == 0].sample(int(total_rows / 100 * neg_percent))\n",
    "    df3_pos = df3_pos.reset_index()\n",
    "    df3_neg = df3_neg.reset_index()\n",
    "    df3_pos = df3_pos.drop('index', axis=1)\n",
    "    df3_neg = df3_neg.drop('index', axis=1)\n",
    "    df3 = pd.concat([df3_pos, df3_neg])\n",
    "    \n",
    "    print( 'sample_df3 end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08ea152",
   "metadata": {},
   "source": [
    "df = pd.read_csv('data/ga_hits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397591b0",
   "metadata": {},
   "source": [
    "df2 = pd.read_csv('data/ga_sessions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4eeb49",
   "metadata": {},
   "source": [
    "df3 = df3 = pd.merge(df, df2, on='session_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53431a9d",
   "metadata": {},
   "source": [
    "df3 = event_action(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "540c97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ad_campaign(df3):\n",
    "    print( 'ad_campaign start')\n",
    "    try:\n",
    "        with open('data/utm_c_frec_dict2.json', 'r') as f:\n",
    "            utm_c_frec_dict = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "\n",
    "        utm_c_frec_dict = {}\n",
    "        counter = 1\n",
    "        for pos in df3.utm_campaign.unique():\n",
    "            if len(df3[(df3.utm_campaign == pos) & (df3.event_action == 1)]) == 0:\n",
    "                utm_c_frec_dict[str(pos)] = 0\n",
    "            else:\n",
    "                utm_c_frec_dict[str(pos)] = round(len(df3[(df3.utm_campaign == pos) & (df3.event_action == 1)]) / len(df3[df3.utm_campaign == pos]), 5)\n",
    "\n",
    "            #print(counter)\n",
    "            counter = counter  + 1\n",
    "        with open('data/utm_c_frec_dict2.json', 'w') as f: \n",
    "            json.dump(utm_c_frec_dict, f)\n",
    "\n",
    "    finally:\n",
    "        df3['camp_succ_rate'] = df3.utm_campaign.apply(lambda x: utm_c_frec_dict[str(x)])\n",
    "    \n",
    "    #print(utm_c_frec_dict)\n",
    "    print( 'ad_campaign end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1ed08b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ad_campaign_v_2(df3):\n",
    "    \n",
    "    print( 'ad_campaign v2 start')\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        with open('data/utm_c_frec_dict3.json', 'r') as f:\n",
    "            utm_c_frec_dict = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "        df5 = df3[['utm_campaign', 'event_action']]\n",
    "        succ_camps = df5[df5.event_action == 1].utm_campaign.value_counts(dropna=False)\n",
    "        all_camps = df5.utm_campaign.value_counts(dropna=False)\n",
    "\n",
    "        utm_c_frec_dict = {}\n",
    "        \n",
    "        for pos in all_camps.keys():\n",
    "            if pos in succ_camps.keys():\n",
    "                utm_c_frec_dict[str(pos)] = round(succ_camps[pos] / all_camps[pos], 5)\n",
    "            else:\n",
    "                utm_c_frec_dict[str(pos)] = 0\n",
    "        \n",
    "        \n",
    "        with open('data/utm_c_frec_dict3.json', 'w') as f: \n",
    "            json.dump(utm_c_frec_dict, f)\n",
    "\n",
    "    finally:\n",
    "        df3['camp_succ_rate'] = df3.utm_campaign.apply(lambda x: utm_c_frec_dict[str(x)])\n",
    "    \n",
    "    #print(utm_c_frec_dict)\n",
    "    print( 'ad_campaign v2 end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "40072e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_of_week(df3):\n",
    "    print( 'day_of_week start')\n",
    "    df3['new_date'] = pd.to_datetime(df3['visit_date'])\n",
    "    df3['day_of_week'] = df3.new_date.dt.dayofweek\n",
    "    \n",
    "    df3 = df3.drop('new_date', axis=1)\n",
    "    print('day_of_week end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "21610a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def empties(df3):\n",
    "    print( 'empties end')\n",
    "    df3.loc[df3.utm_source.isna() == True, 'utm_source'] = 'other'\n",
    "    df3.loc[df3.utm_adcontent.isna() == True, 'utm_adcontent'] = 'Other'\n",
    "    df3.loc[df3.device_brand.isna() == True, 'device_brand'] = 'other'\n",
    "    \n",
    "    print( 'empties end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')  \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "41d98c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolution_func(df3):\n",
    "    print('resolution_func start')\n",
    "    #resolution\n",
    "    bounds = []\n",
    "    df3['resolution'] = df3.device_screen_resolution.apply(lambda x:eval(x.replace('x','*')))\n",
    "    for device in df3.device_category.unique():\n",
    "        q25 = df3[df3.device_category == device].resolution.quantile(0.25)\n",
    "        q75 = df3[df3.device_category == device].resolution.quantile(0.75)\n",
    "        iqr = q75 - q25\n",
    "        bounds.append((device, q25 - 1.5 * iqr, q75 + 1.5 * iqr))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    test_list = list(df3.device_screen_resolution)\n",
    "    test_list2 = list(df3.device_category)\n",
    "\n",
    "    for i in range(len(test_list)):\n",
    "        test_list[i] = eval(test_list[i].replace('x','*'))\n",
    "\n",
    "    tst_l = list(zip(test_list2, test_list))\n",
    "\n",
    "    resolution = []\n",
    "\n",
    "    for i in range(len(tst_l)):\n",
    "        if tst_l[i][0] == bounds[0][0]:\n",
    "            resolution.append(bounds[0][0]+'_high' if tst_l[i][1] >= bounds[0][2] * 0.7 else (bounds[0][0]+'_medium' if bounds[0][2] * 0.7 > tst_l[i][1] >= bounds[0][2] * 0.1 else bounds[0][0]+'_low'))\n",
    "        elif tst_l[i][0] == bounds[1][0]:\n",
    "            resolution.append(bounds[1][0]+'_high' if tst_l[i][1] >= bounds[1][2] * 0.7 else (bounds[1][0]+'_medium' if bounds[1][2] * 0.7 > tst_l[i][1] >= bounds[1][2] * 0.1 else bounds[1][0]+'_low'))\n",
    "        elif tst_l[i][0] == bounds[2][0]:\n",
    "            resolution.append(bounds[2][0]+'_high' if tst_l[i][1] >= bounds[2][2] * 0.7 else (bounds[2][0]+'_medium' if bounds[2][2] * 0.7 > tst_l[i][1] >= bounds[2][2] * 0.1 else bounds[2][0]+'_low'))\n",
    "\n",
    "    df3['device_screen_resolution'] = resolution\n",
    "    df3 = df3.drop('resolution', axis=1)\n",
    "    \n",
    "    print('resolution_func end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    \n",
    "    return df3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4f81310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolution_func_v_2(df3):\n",
    "    print('resolution_func v2 start')\n",
    "    #resolution\n",
    "    bounds = []\n",
    "    df3['device_screen_resolution'] = df3.device_screen_resolution.apply(lambda x:eval(x.replace('x','*')))\n",
    "\n",
    "    \n",
    "    print('resolution_func v2 end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    \n",
    "    return df3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "23b6e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country(df3, trsh = 0.001):\n",
    "    print('country start')\n",
    "    #geo_country\n",
    "    country_list = list(df3.geo_country.unique())\n",
    "    for i in range(len(country_list)):\n",
    "        country_list[i] = ( len(df3[df3.geo_country == country_list[i]]), country_list[i])\n",
    "    country_list = sorted(country_list, reverse=True)\n",
    "\n",
    "#    trsh = 0.0005\n",
    "    df3_len = len(df3) \n",
    "    for item in country_list:\n",
    "        if item[0] / df3_len >= trsh:\n",
    "            continue\n",
    "        else:\n",
    "            df3.loc[df3.geo_country == item[1], 'geo_country'] = 'some_unimportant_country'\n",
    "    \n",
    "    print( 'country end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3af77a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_v_2(df3):\n",
    "    print('country v2  start')\n",
    "    #geo_country\n",
    "    counter = 0\n",
    "    country_list_new = dict()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        with open('data/country_list_new.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                country_list_new[my_tuple[0]] = my_tuple[1]\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "        \n",
    "        succ_total = len(df3[df3.event_action == 1])\n",
    "        country_list_success = df3[df3.event_action == 1].geo_country.value_counts().sort_values(ascending=False)\n",
    "        country_list_new = []\n",
    "        for country in country_list_success.keys():\n",
    "            country_list_new.append(f'{country}*{str(round(country_list_success[country] / succ_total, 4))}%')\n",
    "            counter += 1\n",
    "            if counter == 23:\n",
    "                break\n",
    "\n",
    "        with open('data/country_list_new.txt', 'w') as f:\n",
    "            for t in country_list_new:\n",
    "                f.write(str(t) +'\\n')\n",
    "                \n",
    "        country_list_new = dict()        \n",
    "        with open('data/country_list_new.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                country_list_new[my_tuple[0]] = my_tuple[1]                \n",
    "\n",
    "\n",
    "    finally:\n",
    "        df3['geo_country'] = df3['geo_country'].apply(lambda x: country_list_new[x] if x in country_list_new else 0.0001)\n",
    "        \n",
    "    \n",
    "\n",
    "    #print(sum(df4.isnull().sum().values))\n",
    "    #print(df4.isnull().sum())\n",
    "    print('country v2 end')    \n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')     \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "82a5c836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def city(df3, trsh = 0.001):\n",
    "    print('city start')\n",
    "    #geo_city\n",
    "    city_list = []\n",
    "    df3_len = len(df3)\n",
    "    try:\n",
    "        with open('data/city_list1.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace('(', '').replace(')', '').replace(\"'\", '')\n",
    "                # split on comma and convert each element to correct type\n",
    "                tuple_elements = [int(e.strip()) if e.strip().isdigit() else e.strip() for e in line.split(',')]\n",
    "                # create tuple and add to list\n",
    "                my_tuple = tuple(tuple_elements)\n",
    "                city_list.append(my_tuple)\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "\n",
    "        city_list = list(zip(df3.geo_city.value_counts().values, df3.geo_city.value_counts().keys() ))\n",
    "        city_list = sorted(city_list, reverse=True)\n",
    "\n",
    "        with open('data/city_list1.txt', 'w') as f:\n",
    "            for t in city_list:\n",
    "                f.write(str(t) +'\\n')\n",
    "\n",
    "\n",
    "\n",
    "    finally:\n",
    "#        trsh = 0.0005\n",
    "        city_list_valid = []\n",
    "        \n",
    "        for item in city_list:\n",
    "            #print(item[1], ' - ', round(item[0] / df3_len, 4),'%' )\n",
    "            if round(item[0] / 15000000, 4) >= trsh:   #df3_len, 4) >= trsh:\n",
    "                city_list_valid.append(item[1])\n",
    "                #print('trsh == 2000 - ', item[0], item[1], round(item[0] / df3_len, 4) >= trsh, ' - appended')\n",
    "\n",
    "        df3.loc[(~df3['geo_city'].isin(city_list_valid)), 'geo_city'] = 'some_unimportant_city'\n",
    "    \n",
    "    \n",
    "\n",
    "    #print(sum(df4.isnull().sum().values))\n",
    "    #print(df4.isnull().sum())\n",
    "    print('city end')    \n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')      \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d07109ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def city_v_2(df3):\n",
    "    print('city v2  start')\n",
    "    #geo_city\n",
    "    counter = 0\n",
    "    city_list_new = dict()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        with open('data/city_list_new.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                city_list_new[my_tuple[0]] = my_tuple[1]\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "        \n",
    "        succ_total = len(df3[df3.event_action == 1])\n",
    "        city_list_success = df3[df3.event_action == 1].geo_city.value_counts().sort_values(ascending=False)\n",
    "        city_list_new = []\n",
    "        for city in city_list_success.keys():\n",
    "            city_list_new.append(f'{city}*{str(round(city_list_success[city] / succ_total, 4))}%')\n",
    "            counter += 1\n",
    "            if counter == 26:\n",
    "                break\n",
    "\n",
    "        with open('data/city_list_new.txt', 'w') as f:\n",
    "            for t in city_list_new:\n",
    "                f.write(str(t) +'\\n')\n",
    "                \n",
    "        with open('data/city_list_new.txt', 'r') as f:\n",
    "            city_list_new = dict()\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                city_list_new[my_tuple[0]] = my_tuple[1]                \n",
    "\n",
    "\n",
    "    finally:\n",
    "        \n",
    "        df3['geo_city'] = df3['geo_city'].apply(lambda x: city_list_new[x] if x in city_list_new else 0.0001)\n",
    "        \n",
    "    \n",
    "\n",
    "    #print(sum(df4.isnull().sum().values))\n",
    "    #print(df4.isnull().sum())\n",
    "    print('city v2 end')    \n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')      \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "314e9d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['dev_brand_copy'] = df3.device_brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "98aefb93",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_brand start\n",
      "oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\n",
      "device_brand end\n",
      "-\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>hit_date</th>\n",
       "      <th>hit_time</th>\n",
       "      <th>hit_number</th>\n",
       "      <th>hit_type</th>\n",
       "      <th>hit_referer</th>\n",
       "      <th>hit_page_path</th>\n",
       "      <th>event_category</th>\n",
       "      <th>event_action</th>\n",
       "      <th>event_label</th>\n",
       "      <th>...</th>\n",
       "      <th>utm_keyword</th>\n",
       "      <th>device_category</th>\n",
       "      <th>device_os</th>\n",
       "      <th>device_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>device_screen_resolution</th>\n",
       "      <th>device_browser</th>\n",
       "      <th>geo_country</th>\n",
       "      <th>geo_city</th>\n",
       "      <th>dev_brand_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5639623078712724064.1640254056.1640254056</td>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>597864.0</td>\n",
       "      <td>30</td>\n",
       "      <td>event</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sberauto.com/cars?utm_source_initial=google&amp;ut...</td>\n",
       "      <td>quiz</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>wvtWRwiRmvPIsSQuXnvd</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Android</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360x780</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Saint Petersburg</td>\n",
       "      <td>Huawei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5639623078712724064.1640254056.1640254056</td>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>290095.0</td>\n",
       "      <td>12</td>\n",
       "      <td>event</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sberauto.com/cars/all/kia/seltos/20f30855?utm_...</td>\n",
       "      <td>card_web</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>wvtWRwiRmvPIsSQuXnvd</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Android</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360x780</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Saint Petersburg</td>\n",
       "      <td>Huawei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5639623078712724064.1640254056.1640254056</td>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>294857.0</td>\n",
       "      <td>18</td>\n",
       "      <td>event</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sberauto.com/cars/all/volkswagen/tiguan/0208cd...</td>\n",
       "      <td>card_web</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>wvtWRwiRmvPIsSQuXnvd</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Android</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360x780</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Saint Petersburg</td>\n",
       "      <td>Huawei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5639623078712724064.1640254056.1640254056</td>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>295591.0</td>\n",
       "      <td>20</td>\n",
       "      <td>event</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sberauto.com/cars/all/volkswagen/tiguan/0208cd...</td>\n",
       "      <td>card_web</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>wvtWRwiRmvPIsSQuXnvd</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Android</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360x780</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Saint Petersburg</td>\n",
       "      <td>Huawei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5639623078712724064.1640254056.1640254056</td>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>290039.0</td>\n",
       "      <td>8</td>\n",
       "      <td>event</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sberauto.com/cars/all/kia/seltos/20f30855?utm_...</td>\n",
       "      <td>card_web</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>wvtWRwiRmvPIsSQuXnvd</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Android</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360x780</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Saint Petersburg</td>\n",
       "      <td>Huawei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15685214</th>\n",
       "      <td>1706097853564481669.1640267190.1640267190</td>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>event</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sberauto.com/moskva/cars?datefrom=2021&amp;rental_...</td>\n",
       "      <td>quiz</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>puhZPIYqKXeFPaUviSjo</td>\n",
       "      <td>mobile</td>\n",
       "      <td>iOS</td>\n",
       "      <td>0.2802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>428x926</td>\n",
       "      <td>Safari</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Moscow</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15685215</th>\n",
       "      <td>8262758806963127884.1640272536.1640272536</td>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>event</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sberauto.com/cars/all/renault/logan/8c3c73f2?u...</td>\n",
       "      <td>quiz</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>puhZPIYqKXeFPaUviSjo</td>\n",
       "      <td>mobile</td>\n",
       "      <td>Android</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360x800</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Ulyanovsk</td>\n",
       "      <td>Realme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15685216</th>\n",
       "      <td>3349670872968620291.1640264206.1640264206</td>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>event</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sberauto.com/cars/all/kia/rio/fee33fe6?rental_...</td>\n",
       "      <td>quiz</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mobile</td>\n",
       "      <td>iOS</td>\n",
       "      <td>0.2802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>375x667</td>\n",
       "      <td>Safari (in-app)</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Samara</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15685217</th>\n",
       "      <td>1009509786569589790.1640244938.1640244938</td>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>600274.0</td>\n",
       "      <td>3</td>\n",
       "      <td>event</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sberauto.com/cars?utm_source_initial=yandex&amp;ut...</td>\n",
       "      <td>quiz</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>tVtbIKrPSOvrXLCznVVe</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Windows</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1366x768</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Orenburg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15685218</th>\n",
       "      <td>5381267721977892188.1640271196.1640271196</td>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>600811.0</td>\n",
       "      <td>3</td>\n",
       "      <td>event</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sberauto.com/voronej/cars?rental_car=rental_on...</td>\n",
       "      <td>quiz</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>puhZPIYqKXeFPaUviSjo</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Windows</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1536x864</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Voronezh</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15685219 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         session_id    hit_date  hit_time  \\\n",
       "0         5639623078712724064.1640254056.1640254056  2021-12-23  597864.0   \n",
       "1         5639623078712724064.1640254056.1640254056  2021-12-23  290095.0   \n",
       "2         5639623078712724064.1640254056.1640254056  2021-12-23  294857.0   \n",
       "3         5639623078712724064.1640254056.1640254056  2021-12-23  295591.0   \n",
       "4         5639623078712724064.1640254056.1640254056  2021-12-23  290039.0   \n",
       "...                                             ...         ...       ...   \n",
       "15685214  1706097853564481669.1640267190.1640267190  2021-12-23       0.0   \n",
       "15685215  8262758806963127884.1640272536.1640272536  2021-12-23       0.0   \n",
       "15685216  3349670872968620291.1640264206.1640264206  2021-12-23       0.0   \n",
       "15685217  1009509786569589790.1640244938.1640244938  2021-12-23  600274.0   \n",
       "15685218  5381267721977892188.1640271196.1640271196  2021-12-23  600811.0   \n",
       "\n",
       "          hit_number hit_type hit_referer  \\\n",
       "0                 30    event         NaN   \n",
       "1                 12    event         NaN   \n",
       "2                 18    event         NaN   \n",
       "3                 20    event         NaN   \n",
       "4                  8    event         NaN   \n",
       "...              ...      ...         ...   \n",
       "15685214           1    event         NaN   \n",
       "15685215           1    event         NaN   \n",
       "15685216           1    event         NaN   \n",
       "15685217           3    event         NaN   \n",
       "15685218           3    event         NaN   \n",
       "\n",
       "                                              hit_page_path event_category  \\\n",
       "0         sberauto.com/cars?utm_source_initial=google&ut...           quiz   \n",
       "1         sberauto.com/cars/all/kia/seltos/20f30855?utm_...       card_web   \n",
       "2         sberauto.com/cars/all/volkswagen/tiguan/0208cd...       card_web   \n",
       "3         sberauto.com/cars/all/volkswagen/tiguan/0208cd...       card_web   \n",
       "4         sberauto.com/cars/all/kia/seltos/20f30855?utm_...       card_web   \n",
       "...                                                     ...            ...   \n",
       "15685214  sberauto.com/moskva/cars?datefrom=2021&rental_...           quiz   \n",
       "15685215  sberauto.com/cars/all/renault/logan/8c3c73f2?u...           quiz   \n",
       "15685216  sberauto.com/cars/all/kia/rio/fee33fe6?rental_...           quiz   \n",
       "15685217  sberauto.com/cars?utm_source_initial=yandex&ut...           quiz   \n",
       "15685218  sberauto.com/voronej/cars?rental_car=rental_on...           quiz   \n",
       "\n",
       "          event_action event_label  ...           utm_keyword device_category  \\\n",
       "0                    0         NaN  ...  wvtWRwiRmvPIsSQuXnvd          mobile   \n",
       "1                    0         NaN  ...  wvtWRwiRmvPIsSQuXnvd          mobile   \n",
       "2                    0         NaN  ...  wvtWRwiRmvPIsSQuXnvd          mobile   \n",
       "3                    0         NaN  ...  wvtWRwiRmvPIsSQuXnvd          mobile   \n",
       "4                    0         NaN  ...  wvtWRwiRmvPIsSQuXnvd          mobile   \n",
       "...                ...         ...  ...                   ...             ...   \n",
       "15685214             0         NaN  ...  puhZPIYqKXeFPaUviSjo          mobile   \n",
       "15685215             0         NaN  ...  puhZPIYqKXeFPaUviSjo          mobile   \n",
       "15685216             0         NaN  ...                   NaN          mobile   \n",
       "15685217             0         NaN  ...  tVtbIKrPSOvrXLCznVVe         desktop   \n",
       "15685218             0         NaN  ...  puhZPIYqKXeFPaUviSjo         desktop   \n",
       "\n",
       "         device_os device_brand  device_model device_screen_resolution  \\\n",
       "0          Android       0.0893           NaN                  360x780   \n",
       "1          Android       0.0893           NaN                  360x780   \n",
       "2          Android       0.0893           NaN                  360x780   \n",
       "3          Android       0.0893           NaN                  360x780   \n",
       "4          Android       0.0893           NaN                  360x780   \n",
       "...            ...          ...           ...                      ...   \n",
       "15685214       iOS       0.2802           NaN                  428x926   \n",
       "15685215   Android       0.0084           NaN                  360x800   \n",
       "15685216       iOS       0.2802           NaN                  375x667   \n",
       "15685217   Windows       0.0001           NaN                 1366x768   \n",
       "15685218   Windows       0.0001           NaN                 1536x864   \n",
       "\n",
       "           device_browser geo_country          geo_city dev_brand_copy  \n",
       "0                  Chrome      Russia  Saint Petersburg         Huawei  \n",
       "1                  Chrome      Russia  Saint Petersburg         Huawei  \n",
       "2                  Chrome      Russia  Saint Petersburg         Huawei  \n",
       "3                  Chrome      Russia  Saint Petersburg         Huawei  \n",
       "4                  Chrome      Russia  Saint Petersburg         Huawei  \n",
       "...                   ...         ...               ...            ...  \n",
       "15685214           Safari      Russia            Moscow          Apple  \n",
       "15685215           Chrome      Russia         Ulyanovsk         Realme  \n",
       "15685216  Safari (in-app)      Russia            Samara          Apple  \n",
       "15685217             Edge      Russia          Orenburg            NaN  \n",
       "15685218           Chrome      Russia          Voronezh            NaN  \n",
       "\n",
       "[15685219 rows x 29 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_brand(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "807197d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['device_brand'] = df3.dev_brand_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ae66ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def device_brand(df3):\n",
    "    print('device_brand start')\n",
    "    #device_brand\n",
    "    counter = 0\n",
    "    device_brand_list_new = {}\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        with open('data/device_brand_list_new1.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                device_brand_list_new[my_tuple[0]] = my_tuple[1]\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "        succ_total = len(df3[df3.event_action == 1])\n",
    "        device_brand_list_success = df3[df3.event_action == 1].device_brand.value_counts().sort_values(ascending=False)\n",
    "        device_brand_list_new = []\n",
    "        for device_brand in device_brand_list_success.keys():\n",
    "            device_brand_list_new.append(f'{device_brand}*{str(round(device_brand_list_success[device_brand] / succ_total, 4))}%')\n",
    "            counter += 1\n",
    "            if counter == 23:\n",
    "                break\n",
    "\n",
    "        with open('data/device_brand_list_new1.txt', 'w') as f:\n",
    "            for t in device_brand_list_new:\n",
    "                f.write(str(t) +'\\n')\n",
    "                \n",
    "        device_brand_list_new = {}\n",
    "        with open('data/device_brand_list_new1.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                device_brand_list_new[my_tuple[0]] = my_tuple[1]                \n",
    "\n",
    "\n",
    "    finally:\n",
    "        df3['device_brand'] = df3['device_brand'].apply(lambda x: device_brand_list_new[x] if x in device_brand_list_new else 0.0001)\n",
    "        \n",
    "    \n",
    "\n",
    "    #print(sum(df4.isnull().sum().values))\n",
    "    #print(df4.isnull().sum())\n",
    "    print('device_brand end')    \n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')      \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c2719895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def device_brand_v_2(df3, trsh = 0.0012):\n",
    "    print('device_brand v 2 start')\n",
    "    #device_brand\n",
    "    brand_list = []\n",
    "    df3_len = len(df3)\n",
    "    \n",
    "    try:\n",
    "        with open('data/brand_list1.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace('(', '').replace(')', '').replace(\"'\", '')\n",
    "                # split on comma and convert each element to correct type\n",
    "                tuple_elements = [int(e.strip()) if e.strip().isdigit() else e.strip() for e in line.split(',')]\n",
    "                # create tuple and add to list\n",
    "                my_tuple = tuple(tuple_elements)\n",
    "                brand_list.append(my_tuple)\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "\n",
    "        brand_list = list(zip(df3.device_brand.value_counts().values, df3.device_brand.value_counts().keys() ))\n",
    "        brand_list = sorted(brand_list, reverse=True)\n",
    "\n",
    "        with open('data/brand_list1.txt', 'w') as f:\n",
    "            for t in brand_list:\n",
    "                f.write(str(t) +'\\n')\n",
    "\n",
    "\n",
    "\n",
    "    finally:\n",
    "#        trsh = 0.0005\n",
    "        brand_list_valid = []\n",
    "        \n",
    "        for item in brand_list:\n",
    "            #print(item[0], ' ', item[0] / df3_len,'>=', trsh, ' ', round(item[0] / df3_len, 4) >= trsh )\n",
    "            if item[0] / df3_len >= trsh:\n",
    "                brand_list_valid.append(item[1])\n",
    "                #print(len(brand_list_valid), ' ', item[0],' ',item[1] )\n",
    "\n",
    "        df3.loc[(~df3['device_brand'].isin(brand_list_valid)), 'device_brand'] = 'some_unimportant_brand'\n",
    "    \n",
    "    \n",
    "    print('device_brand v 2 end')    \n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')      \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ff60f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_stuff(df3):\n",
    "    print('encode_stuff start')\n",
    "    cols_to_encode = ['utm_source', \n",
    "                      'utm_medium', \n",
    "                      'utm_adcontent', \n",
    "                      #'device_brand', \n",
    "                      'device_category', \n",
    "                      'device_screen_resolution', \n",
    "                      'device_browser',\n",
    "                      'utm_campaign'\n",
    "                      #,'geo_country',\n",
    "                      #'geo_city'\n",
    "                     ]\n",
    "    \n",
    "    #encoding\n",
    "    encoded_features = pd.DataFrame()\n",
    "\n",
    "    for col in cols_to_encode:\n",
    "\n",
    "        pre_encoded_df3 = df3[[col]]\n",
    "        encoder = OneHotEncoder(categories='auto', handle_unknown='ignore', sparse=False)\n",
    "        encoded_array = encoder.fit_transform(pre_encoded_df3)\n",
    "        #feature_names = [f'{col}_{name}' for name in encoder.get_feature_names_out()]\n",
    "        feature_names = encoder.get_feature_names_out()\n",
    "        encoded_df3 = pd.DataFrame(encoded_array, columns=feature_names)\n",
    "\n",
    "        #if len(encoded_features) == 0:\n",
    "        #    encoded_features = encoded_df3.copy()\n",
    "        #else:\n",
    "        #    encoded_features[feature_names] = encoded_df3.values\n",
    "        \n",
    "        df3[feature_names] = encoded_df3.values\n",
    "    #print(encoded_features.isnull().sum())\n",
    "\n",
    "    #df3 = df3.join(encoded_features)\n",
    "    #print(df3.isnull().sum())\n",
    "    df3 = df3.drop(cols_to_encode, axis=1)\n",
    "    print( 'encode_stuff end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')  \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "439622ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_stuff(df3):\n",
    "    #scaling\n",
    "    print('scale_stuff start')\n",
    "    cols_to_scale = ['visit_number',\n",
    "                     #'day_of_week'\n",
    "                    # ,'device_screen_resolution'\n",
    "                    ]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(df3.loc[:,cols_to_scale])\n",
    "    scaled_feature_names = [f'{name}_scaled' for name in scaler.get_feature_names_out()]\n",
    "    #scaler.get_feature_names_out()\n",
    "\n",
    "    #scaled_df = pd.DataFrame(scaled_features, columns=scaled_feature_names)\n",
    "    df3[scaled_feature_names] = scaled_features\n",
    "    #print(scaled_df.shape, scaled_df.columns)\n",
    "    #print(scaled_df.isnull().sum())\n",
    "\n",
    "    #df3['scaled_feature_names'] = scaled_df\n",
    "    #print(df3.shape, df3.columns)\n",
    "    df3 = df3.drop(cols_to_scale, axis=1)\n",
    "    for column in df3.columns:\n",
    "        print(column)\n",
    "    print(len(df3.columns))\n",
    "    #print(df3.isnull().sum())\n",
    "    #print(len(df3.columns), df3.columns)\n",
    "    print('scale_stuff end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')  \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f2a7612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stuff(df3):\n",
    "    #pre-existing list of columns\n",
    "    print('filter_stuff start')\n",
    "    cols_to_drop = [\n",
    "        'session_id',\n",
    "        'hit_date',\n",
    "        'hit_time',\n",
    "        'hit_number',\n",
    "        'hit_type',\n",
    "        'hit_referer',\n",
    "        'hit_page_path',\n",
    "        'event_category',\n",
    "        'event_label',\n",
    "        'event_value',\n",
    "        'client_id',\n",
    "        #'new_date',\n",
    "        'visit_date',\n",
    "        'visit_number',\n",
    "        'utm_keyword',\n",
    "        'device_os',\n",
    "        'device_model',\n",
    "        'visit_time'\n",
    "    ]\n",
    "    \n",
    "    cols_to_encode = [\n",
    "        'utm_source',\n",
    "        'utm_medium', \n",
    "        'utm_adcontent',\n",
    "        'device_brand', \n",
    "        'device_category', \n",
    "        'device_screen_resolution',\n",
    "        'device_browser',\n",
    "        'utm_campaign',\n",
    "        'geo_country',\n",
    "        'geo_city'\n",
    "    ]\n",
    "    #dropping\n",
    "    #cols_to_drop = []\n",
    "    #for col in df_columns:\n",
    "    #    cols_to_drop.append(str(col))\n",
    "    #cols_to_drop = cols_to_drop + ['client_id','new_date', 'visit_date', 'utm_keyword', 'device_os', 'device_model', 'visit_time']    \n",
    "    \n",
    "    df3 = df3.drop(cols_to_drop, axis=1)\n",
    "    #df3 = df3.drop(cols_to_encode, axis=1)\n",
    "    \n",
    "    try:\n",
    "        df3 = df3.drop('Unnamed: 0', axis=1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        df3 = df3.drop('Unnamed: 0.1', axis=1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        df3 = df3.drop('Unnamed: 0.2', axis=1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    print('filter_stuff end')\n",
    "    #print(sum(df3.isnull().sum().values))\n",
    "    #print(df3.isnull().sum())\n",
    "    print(df3.columns)\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "859940a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stuff(df3):\n",
    "    #checking\n",
    "    print('check_stuff start')\n",
    "    counter = 0\n",
    "    for feature in df3.columns:\n",
    "        if df3[feature].dtype != 'O':\n",
    "            #print(feature, ' - ', df3[feature].dtype)\n",
    "            counter += 1\n",
    "        else:\n",
    "            print(feature)\n",
    "    print(counter == len(df3.columns))\n",
    "\n",
    "\n",
    "    #checking 2\n",
    "    counter = 0\n",
    "    for feature in df3.columns:\n",
    "        if len(df3[df3[str(feature)].isna() == True]) != 0:\n",
    "            print(feature, ' - ', len(df3[df3[str(feature)].isna() == True]))\n",
    "            counter += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if counter == 0:\n",
    "        print('vse zaebis\", pustukh fi4ei net')    \n",
    "    \n",
    "    \n",
    "    print('check_stuff end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "814b693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stuff_2(df3):\n",
    "    #checking\n",
    "    print('check_stuff_2 start')\n",
    "\n",
    "    counter = 0\n",
    "    for feature in df3.columns:\n",
    "        if df3[feature].dtype != 'O':\n",
    "            #print(feature, ' - ', df3[feature].dtype)\n",
    "            counter += 1\n",
    "        else:\n",
    "            print(feature)\n",
    "    print(counter == len(df3.columns))\n",
    "\n",
    "\n",
    "    #checking 2\n",
    "    empty_features = False\n",
    "    if sum(df3.isnull().sum()) != 0:\n",
    "        print(df3.isnull().sum())\n",
    "        empty_features = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if empty_features == False:\n",
    "        print('vse zaebis\", pustukh fi4ei net') \n",
    "    #print(len(df3.isnull().sum()))\n",
    "    print(df3.shape,  'check_stuff_2 end') #df3.shape,\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')     \n",
    "    \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b018e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stuff_3(df3):\n",
    "    print(len(df3.columns), df3.columns)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "a48f726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_stuff(df3):\n",
    "    y = df3['event_action']\n",
    "    \n",
    "    df3 = df3.drop('event_action', axis=1)\n",
    "    print(df3.columns)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df3,y, test_size=0.3)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=400, min_samples_leaf=2, max_features='sqrt')\n",
    "    rf.fit(x_train, y_train)\n",
    "    \n",
    "    predicted_train = rf.predict(x_train)\n",
    "    predicted_test = rf.predict(x_test)\n",
    "    \n",
    "    #print(df3.shape, ' - shape', ' function - ')\n",
    "    \n",
    "    \n",
    "    print('train acc score - ',accuracy_score(y_train, predicted_train))\n",
    "    print('test acc score - ', accuracy_score(y_test, predicted_test))\n",
    "\n",
    "    print('train roc score - ',roc_auc_score(y_train, rf.predict_proba(x_train)[:,1]))\n",
    "    print('test roc score - ',roc_auc_score(y_test, rf.predict_proba(x_test)[:,1]))\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c73138c",
   "metadata": {},
   "source": [
    "with open('models/rf_model.pkl', 'wb') as file:\n",
    "    dill.dump(rf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d65451",
   "metadata": {},
   "source": [
    "## function declarations end here. its wildlands after that...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e72138",
   "metadata": {},
   "source": [
    "df = pd.read_csv('data/ga_hits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7945579",
   "metadata": {},
   "source": [
    "df2 = pd.read_csv('data/ga_sessions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe5c01f",
   "metadata": {},
   "source": [
    "df3 = pd.merge(df, df2, on='session_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272d113e",
   "metadata": {},
   "source": [
    "df3 = event_action(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "301c1097",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = [[0.6375, 'ad_camp V, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
    " [0.6375, 'ad_camp X, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
    " [0.6375, ', ad_camp X, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
    " [0.6482, ', ad_camp V, resol v1 X, ctry v1 V, ct v1 V, brand v1 V'],\n",
    " [0.6504, ', ad_camp X, resol v1 X, ctry v1 X, ct v1 X, brand v1 X'],\n",
    " [0.6409, ', ad_camp X, resol v1 V, ctry v1 X, ct v1 X, brand v1 X'],\n",
    " [0.6396, ', ad_camp X, resol v2 V, ctry v1 X, ct v1 X, brand v1 X'],\n",
    " [0.6502, ', ad_camp X, resol v2 X, ctry v1 V, ct v1 X, brand v1 X'],\n",
    " [0.6503, ', ad_camp X, resol v2 X, ctry v2 V, ct v1 X, brand v1 X'],\n",
    " [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v1 X, brand v1 X'],\n",
    " [0.6498, ', ad_camp X, resol v2 X, ctry v2 X, ct v1 V, brand v1 X'],\n",
    " [0.6389, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 V, brand v1 X'],\n",
    " [0.649, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v1 V'],\n",
    " [0.6503, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
    " [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
    " [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
    " [0.6603, 'ad_camp V, resol V, cntry V, ct V, brand V, 200k 50/50'],\n",
    " [0.6576, 'ad_camp V, resol V, cntry V, ct V, brand V, 200k 70/30'],\n",
    " [0.6456, 'ad_camp V, resol V, cntry V, ct V, brand V, 140k 30/70']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "46f13be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_single_fit = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a3befdb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['utm_source', 'utm_medium', 'utm_campaign', 'utm_adcontent',\n",
      "       'device_category', 'device_brand', 'device_screen_resolution',\n",
      "       'device_browser', 'geo_country', 'geo_city', 'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "11 Index(['utm_source', 'utm_medium', 'utm_campaign', 'utm_adcontent',\n",
      "       'device_category', 'device_brand', 'device_screen_resolution',\n",
      "       'device_browser', 'geo_country', 'geo_city', 'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['utm_source', 'utm_medium', 'utm_campaign', 'utm_adcontent',\n",
      "       'device_category', 'device_brand', 'device_screen_resolution',\n",
      "       'device_browser', 'geo_country', 'geo_city', 'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "11 Index(['utm_source', 'utm_medium', 'utm_campaign', 'utm_adcontent',\n",
      "       'device_category', 'device_brand', 'device_screen_resolution',\n",
      "       'device_browser', 'geo_country', 'geo_city', 'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['utm_source', 'utm_medium', 'utm_campaign', 'utm_adcontent',\n",
      "       'device_category', 'device_brand', 'device_screen_resolution',\n",
      "       'device_browser', 'geo_country', 'geo_city', 'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "11 Index(['utm_source', 'utm_medium', 'utm_campaign', 'utm_adcontent',\n",
      "       'device_category', 'device_brand', 'device_screen_resolution',\n",
      "       'device_browser', 'geo_country', 'geo_city', 'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['utm_source', 'utm_medium', 'utm_campaign', 'utm_adcontent',\n",
      "       'device_category', 'device_brand', 'device_screen_resolution',\n",
      "       'device_browser', 'geo_country', 'geo_city', 'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "11 Index(['utm_source', 'utm_medium', 'utm_campaign', 'utm_adcontent',\n",
      "       'device_category', 'device_brand', 'device_screen_resolution',\n",
      "       'device_browser', 'geo_country', 'geo_city', 'camp_succ_rate'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\advok\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "4 fits failed out of a total of 4.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\advok\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\advok\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\advok\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\advok\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\advok\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\advok\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 434, in fit_transform\n",
      "    return last_step.fit_transform(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\advok\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 668, in fit_transform\n",
      "    X = _check_X(X)\n",
      "  File \"C:\\Users\\advok\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 820, in _check_X\n",
      "    return check_array(X, force_all_finite=\"allow-nan\", dtype=object)\n",
      "  File \"C:\\Users\\advok\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 761, in check_array\n",
      "    raise ValueError(\n",
      "ValueError: Expected 2D array, got scalar array instead:\n",
      "array=None.\n",
      "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv('data/df3_100k_50n_50p.csv')\n",
    "\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    #('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "f_transformer = ColumnTransformer(transformers=[\n",
    "    ('categorical', categorical_transformer, make_column_selector(dtype_include='object'))\n",
    "])\n",
    "\n",
    "preprocessor = Pipeline(steps=[\n",
    "    #('event', FunctionTransformer(event_action)),\n",
    "    #('sampling', FunctionTransformer(sample_df3)),\n",
    "    ('ad_campaign_feature_creating', FunctionTransformer(ad_campaign)),\n",
    "    #('day_of_week', FunctionTransformer(day_of_week)),\n",
    "    ('empties', FunctionTransformer(empties)),\n",
    "    ('resolution_func', FunctionTransformer(resolution_func)),\n",
    "    ('country', FunctionTransformer(country)),\n",
    "    ('city', FunctionTransformer(city)),\n",
    "    ('device brand', FunctionTransformer(device_brand)),\n",
    "    ('filter_stuff', FunctionTransformer(filter_stuff)),\n",
    "    #('encode_stuff', FunctionTransformer(encode_stuff)),\n",
    "    #('scale_stuff(visit_num)', FunctionTransformer(scale_stuff)),\n",
    "    ('check_stuff_3', FunctionTransformer(check_stuff_3)),\n",
    "    ('f_transformer', f_transformer),\n",
    "    #('filter_stuff', FunctionTransformer(filter_stuff)),\n",
    "    #('check_stuff_3', FunctionTransformer(check_stuff_3))\n",
    "])\n",
    "\n",
    "models = [\n",
    "    #RandomForestClassifier(n_estimators=300, max_depth= 10, max_features='sqrt', min_samples_split=2),\n",
    "    #SVC(C=10, gamma=0.01, kernel='rbf'),\n",
    "    #DecisionTreeClassifier(criterion='gini', max_depth=7, min_samples_split=10),\n",
    "    #LogisticRegression( C=1.0, penalty='l2', solver='saga'),\n",
    "    MLPClassifier(hidden_layer_sizes=(100, ), solver='adam', activation='tanh')\n",
    "    ]\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "\n",
    "    pipeline = Pipeline(steps = [\n",
    "        ('preprocessor', preprocessor), \n",
    "        ('classifier', model)  \n",
    "    ])\n",
    "\n",
    "    y = df4['event_action']\n",
    "    x = df4.drop('event_action', axis=1)\n",
    "\n",
    "    #x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\n",
    "    #pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    #predictions = pipeline.predict(x_test)\n",
    "    #probs = pipeline.predict_proba(x_test)\n",
    "    #scores_single_fit.append([type(model).__name__,' test roc score - ', roc_auc_score(y_test, probs[:,1])])\n",
    "    #scores_single_fit.append([type(model).__name__,' test acc score - ', accuracy_score(y_test, predictions)])\n",
    "    #print(type(model).__name__,' test roc score - ', roc_auc_score(y_test, probs[:,1]))\n",
    "    #print(type(model).__name__,' test acc score - ', accuracy_score(y_test, predictions))\n",
    "    #interm_scores.append((str(model), 'test roc score - ', roc_auc_score(y_test, pipeline.predict_proba(x_test)[:,1])))\n",
    "    #interm_scores.append((str(model), 'test acc score - ', accuracy_score(y_test, predictions)))\n",
    "    \n",
    "    log = 'ad_camp v2 V, resol V, cntry V, ct V, brand V'\n",
    "    score = cross_val_score(pipeline, x, y, cv=4, scoring='roc_auc')\n",
    "    #score = cross_val_score(pipeline, x, y, cv=4, scoring='accuracy')\n",
    "    cv_scores.append([ round(score.mean(), 4), log]) #type(model).__name__,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4ffa87e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6375, 'ad_camp V, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
       " [0.6375, 'ad_camp X, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
       " [0.6375, ', ad_camp X, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
       " [0.6482, ', ad_camp V, resol v1 X, ctry v1 V, ct v1 V, brand v1 V'],\n",
       " [0.6504, ', ad_camp X, resol v1 X, ctry v1 X, ct v1 X, brand v1 X'],\n",
       " [0.6409, ', ad_camp X, resol v1 V, ctry v1 X, ct v1 X, brand v1 X'],\n",
       " [0.6396, ', ad_camp X, resol v2 V, ctry v1 X, ct v1 X, brand v1 X'],\n",
       " [0.6502, ', ad_camp X, resol v2 X, ctry v1 V, ct v1 X, brand v1 X'],\n",
       " [0.6503, ', ad_camp X, resol v2 X, ctry v2 V, ct v1 X, brand v1 X'],\n",
       " [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v1 X, brand v1 X'],\n",
       " [0.6498, ', ad_camp X, resol v2 X, ctry v2 X, ct v1 V, brand v1 X'],\n",
       " [0.6389, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 V, brand v1 X'],\n",
       " [0.649, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v1 V'],\n",
       " [0.6503, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
       " [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
       " [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
       " [0.6603, 'ad_camp V, resol V, cntry V, ct V, brand V, 200k 50/50'],\n",
       " [0.6576, 'ad_camp V, resol V, cntry V, ct V, brand V, 200k 70/30'],\n",
       " [0.6456, 'ad_camp V, resol V, cntry V, ct V, brand V, 140k 30/70'],\n",
       " [nan, 'ad_camp v2 V, resol V, cntry V, ct V, brand V'],\n",
       " [nan, 'ad_camp v2 V, resol V, cntry V, ct V, brand V'],\n",
       " [nan, 'ad_camp v2 V, resol V, cntry V, ct V, brand V'],\n",
       " [nan, 'ad_camp v2 V, resol V, cntry V, ct V, brand V'],\n",
       " [nan, 'ad_camp v2 V, resol V, cntry V, ct V, brand V'],\n",
       " [nan, 'ad_camp v2 V, resol V, cntry V, ct V, brand V'],\n",
       " [nan, 'ad_camp v2 V, resol V, cntry V, ct V, brand V'],\n",
       " [nan, 'ad_camp v2 V, resol V, cntry V, ct V, brand V']]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f66ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421bfaab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70051ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f40e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "225d5b63",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_action start\n",
      "event_action start\n",
      "event_action start\n",
      "event_action start\n",
      "event_action start\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3802, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas\\_libs\\index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'event_action'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 437, in fit_transform\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 862, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 236, in transform\n    return self._transform(X, func=self.func, kw_args=self.kw_args)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 307, in _transform\n    return func(X, **(kw_args if kw_args else {}))\n  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1844\\1663308378.py\", line 13, in event_action\n    df3['event_action'] = df3['event_action'].apply(lambda x: 1 if x in target_action else 0)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 3807, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3804, in get_loc\n    raise KeyError(key) from err\nKeyError: 'event_action'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 40\u001b[0m\n\u001b[0;32m     33\u001b[0m high_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     36\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     37\u001b[0m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[0;32m     38\u001b[0m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, rf)\n\u001b[0;32m     39\u001b[0m ])\n\u001b[1;32m---> 40\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, error_score='raise')\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, acc_mean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, acc_std: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m high_score \u001b[38;5;241m<\u001b[39m score\u001b[38;5;241m.\u001b[39mmean():\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(scoring):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3802, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas\\_libs\\index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'event_action'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 437, in fit_transform\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 862, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 236, in transform\n    return self._transform(X, func=self.func, kw_args=self.kw_args)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 307, in _transform\n    return func(X, **(kw_args if kw_args else {}))\n  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1844\\1663308378.py\", line 13, in event_action\n    df3['event_action'] = df3['event_action'].apply(lambda x: 1 if x in target_action else 0)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 3807, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3804, in get_loc\n    raise KeyError(key) from err\nKeyError: 'event_action'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#f_transformer = ColumnTransformer(transformers=[\n",
    " #   ('numerical', numerical_transformer, make_column_selector(dtype_include=['int64', 'float64'])),\n",
    "  #  ('categorical', categorical_transformer, make_column_selector(dtype_include='object'))\n",
    "#])\n",
    "df4 = pd.read_csv('data/df3_10k_50n_50p.csv')\n",
    "\n",
    "#df4 = event_action(df4)\n",
    "\n",
    "#df4 = sample_df3(df4)\n",
    "\n",
    "\n",
    "y = df4['event_action']\n",
    "X = df4.drop('event_action', axis=1)\n",
    "\n",
    "preprocessor = Pipeline(steps=[\n",
    "    ('target', FunctionTransformer(event_action)),\n",
    "    ('sampling', FunctionTransformer(sample_df3)),\n",
    "    ('ad_campaign_feature_creating', FunctionTransformer(ad_campaign)),\n",
    "    ('day_of_week', FunctionTransformer(day_of_week)),\n",
    "    ('empties', FunctionTransformer(empties)),\n",
    "    ('resolution_func', FunctionTransformer(resolution_func)),\n",
    "    ('country', FunctionTransformer(country)),\n",
    "    ('city', FunctionTransformer(city)),\n",
    "    ('encode_stuff', FunctionTransformer(encode_stuff)),\n",
    "    ('scale_stuff', FunctionTransformer(scale_stuff)),\n",
    "    ('filter_stuff', FunctionTransformer(filter_stuff)),\n",
    "    ('check_stuff', FunctionTransformer(check_stuff))\n",
    "    ])\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=400, min_samples_leaf=2, max_features='sqrt')\n",
    "\n",
    "\n",
    "high_score = 0\n",
    "\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "('preprocessor', preprocessor),\n",
    "('classifier', rf)\n",
    "])\n",
    "score = cross_val_score(pipe, X, y, cv=5, scoring='a''accuracy')#, error_score='raise')\n",
    "print(f'model: {type(model).__name__}, acc_mean: {score.mean():.4f}, acc_std: {score.std():.4f}')\n",
    "if high_score < score.mean():\n",
    "    high_score = score.mean()\n",
    "    cars_pipe = pipe\n",
    "\n",
    "else:\n",
    "    continue\n",
    "\n",
    "\n",
    "#cars_pipe.fit(X, y)\n",
    "\n",
    "\n",
    "#with open('data/cars_pipe.pkl', 'wb') as file:\n",
    "#    dill.dump({\n",
    "#        'model': cars_pipe,\n",
    "#        'metadata': {\n",
    "#            'name': 'car price prediction',\n",
    "#           'author': 'collaborative ffs by this point can i really write myself here yet?)',\n",
    "#           'version': 0.00000000000000000001,\n",
    "#            'date': datetime.now(),\n",
    "#            'type': type(cars_pipe.named_steps[\"classifier\"]).__name__,\n",
    "#           'accuracy': high_score\n",
    "#       }\n",
    "#   }, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "989dd4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2abb4648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8084ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4f461240",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/best_params_lr_10k_50_50.json', 'w') as f: json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be1b28cf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country v2  start\n",
      "country v2 end\n",
      "-\n",
      "city v2  start\n",
      "city v2 end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "encode_stuff start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\4057170813.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[scaled_feature_names] = scaled_features\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\4057170813.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[scaled_feature_names] = scaled_features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_stuff end\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['event_action', 'device_brand', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate', 'utm_source_BHcvLfOaCWvWTykYqHVe',\n",
      "       'utm_source_BKeImrJuRDZcHiSSTdzm', 'utm_source_DnEUulZAecfGPvdtZBYS',\n",
      "       'utm_source_EvhrtRzIJnQYHziPiLzV', 'utm_source_FTAuYVNoYYxgvKMpKSLW',\n",
      "       ...\n",
      "       'utm_campaign_ydXTgkwKyFWEAJoahduP',\n",
      "       'utm_campaign_yxtFdhyijaALzWWYtzHE',\n",
      "       'utm_campaign_zDGMDYOBPSeVFZNNwoxT',\n",
      "       'utm_campaign_zPJpddwzkFqLMSYgtDqy',\n",
      "       'utm_campaign_zfwIehuEfWYdYrEZgRLo',\n",
      "       'utm_campaign_zmnpxOKDENholtspXiGy',\n",
      "       'utm_campaign_zxoiLxhuSIFrCeTLQVWZ', 'utm_campaign_nan',\n",
      "       'visit_number_scaled', 'day_of_week_scaled'],\n",
      "      dtype='object', length=376)\n",
      "-\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 10}\n",
      "Best Parameters:  {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 10}\n",
      "Best Score (ROC AUC):  0.6005072640206555\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "df4 = pd.read_csv('data/df3_10k_50n_50p.csv')\n",
    "\n",
    "\n",
    "df4 = ad_campaign(df4)\n",
    "df4 = day_of_week(df4)\n",
    "df4 = empties(df4)\n",
    "df4 = resolution_func(df4)\n",
    "df4 = country_v_2(df4)\n",
    "df4 = city_v_2(df4)\n",
    "df4 = device_brand(df4)\n",
    "df4 = encode_stuff(df4)\n",
    "df4 = scale_stuff(df4)\n",
    "df4 = filter_stuff(df4)\n",
    "\n",
    "y = df4['event_action']\n",
    "x = df4.drop('event_action', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define parameters and their possible values in a dictionary\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Create Logistic Regression classifier object\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Perform Grid Search with cross-validation (e.g., using k-fold CV)\n",
    "grid_search = GridSearchCV(classifier,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='roc_auc',\n",
    "                           cv=5)\n",
    "\n",
    "# Fit the model on training data and find optimal parameters based on performance metric (default is accuracy)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get best parameters found during grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best estimator/model for predictions on test data \n",
    "y_pred = grid_search.predict(x_test)\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score (ROC AUC): \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd1a29f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/best_params_des_tree_10k_50_50.json', 'w') as f: json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "011eb1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "-\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "-\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "-\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "-\n",
      "-\n",
      "country v2  start\n",
      "country v2 end\n",
      "-\n",
      "-\n",
      "-\n",
      "city v2  start\n",
      "city v2 end\n",
      "-\n",
      "-\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "-\n",
      "-\n",
      "encode_stuff start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\1991897665.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[scaled_feature_names] = scaled_features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_stuff end\n",
      "-\n",
      "-\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n",
      "-\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "-\n",
      "-\n",
      "-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1.0, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.5863333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "df4 = pd.read_csv('data/df3_10k_50n_50p.csv')\n",
    "\n",
    "\n",
    "df4 = ad_campaign(df4)\n",
    "df4 = day_of_week(df4)\n",
    "df4 = empties(df4)\n",
    "df4 = resolution_func(df4)\n",
    "df4 = country_v_2(df4)\n",
    "df4 = city_v_2(df4)\n",
    "df4 = device_brand(df4)\n",
    "df4 = encode_stuff(df4)\n",
    "df4 = scale_stuff(df4)\n",
    "df4 = filter_stuff(df4)\n",
    "\n",
    "y = df4['event_action']\n",
    "x = df4.drop('event_action', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\n",
    "\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],                # Regularization penalty ('l1' or 'l2')\n",
    "    'C': [0.01, 0.1, 1.0],                   # Inverse regularization strength (smaller values specify stronger regularization)\n",
    "    'solver': ['liblinear', 'saga']          # Algorithm to use in optimization problem\n",
    "}\n",
    "\n",
    "# Create Logistic Regression classifier object\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Perform Grid Search with cross-validation (e.g., using k-fold CV)\n",
    "grid_search = GridSearchCV(estimator=lr_model, param_grid=param_grid)\n",
    "\n",
    "# Fit the model on training data and find optimal parameters based on performance metric (default is accuracy)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get best parameters found during grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best estimator/model for predictions on test data \n",
    "y_pred = grid_search.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a6d44992",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/best_params_rf_10k_50_50.json', 'w') as f: json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e7ee9da5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "-\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "-\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "-\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "-\n",
      "-\n",
      "country v2  start\n",
      "country v2 end\n",
      "-\n",
      "-\n",
      "-\n",
      "city v2  start\n",
      "city v2 end\n",
      "-\n",
      "-\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "-\n",
      "-\n",
      "encode_stuff start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\1991897665.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[scaled_feature_names] = scaled_features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_stuff end\n",
      "-\n",
      "-\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n",
      "-\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "-\n",
      "-\n",
      "-\n",
      "Best Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 300}\n",
      "0.5943333333333334\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv('data/df3_10k_50n_50p.csv')\n",
    "\n",
    "\n",
    "df4 = ad_campaign(df4)\n",
    "df4 = day_of_week(df4)\n",
    "df4 = empties(df4)\n",
    "df4 = resolution_func(df4)\n",
    "df4 = country_v_2(df4)\n",
    "df4 = city_v_2(df4)\n",
    "df4 = device_brand(df4)\n",
    "df4 = encode_stuff(df4)\n",
    "df4 = scale_stuff(df4)\n",
    "df4 = filter_stuff(df4)\n",
    "\n",
    "y = df4['event_action']\n",
    "x = df4.drop('event_action', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400],    # Number of trees in the forest\n",
    "    'max_depth': [None, 5, 10],          # Maximum depth of each tree\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'min_samples_split': [2, 5, 10], # Minimum number of samples required to split an internal node\n",
    "}\n",
    "\n",
    "# Create Random Forest classifier object\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Perform Grid Search with cross-validation (e.g., using k-fold CV)\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid)\n",
    "\n",
    "# Fit the model on training data and find optimal parameters based on performance metric (default is accuracy)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get best parameters found during grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best estimator/model for predictions on test data \n",
    "y_pred = grid_search.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "47e21c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200k, 70n\\x18p'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
