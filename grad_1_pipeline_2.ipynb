{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb2aa0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import json\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b8766df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_action(df3):\n",
    "    print('event_action start')\n",
    "    target_action = ['sub_car_claim_click', \n",
    "                 'sub_car_claim_submit_click',\n",
    "                 'sub_open_dialog_click', \n",
    "                 'sub_custom_question_submit_click', \n",
    "                 'sub_call_number_click', \n",
    "                 'sub_callback_submit_click', \n",
    "                 'sub_submit_success', \n",
    "                 'sub_car_request_submit_click'\n",
    "                ]\n",
    "\n",
    "    df3['event_action'] = df3['event_action'].apply(lambda x: 1 if x in target_action else 0)\n",
    "    \n",
    "    print( 'event_action end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77d1991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_df3(df3, total_rows =  200000, neg_percent = 50, pos_percent = 50):\n",
    "    print( 'sample_df3 start')\n",
    "    df3_pos = df3[df3['event_action'] == 1].sample(int(total_rows / 100 * pos_percent))\n",
    "    df3_neg = df3[df3['event_action'] == 0].sample(int(total_rows / 100 * neg_percent))\n",
    "    df3_pos = df3_pos.reset_index()\n",
    "    df3_neg = df3_neg.reset_index()\n",
    "    df3_pos = df3_pos.drop('index', axis=1)\n",
    "    df3_neg = df3_neg.drop('index', axis=1)\n",
    "    df3 = pd.concat([df3_pos, df3_neg])\n",
    "    \n",
    "    print( 'sample_df3 end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d558628",
   "metadata": {},
   "source": [
    "df = pd.read_csv('data/ga_hits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f805c1c7",
   "metadata": {},
   "source": [
    "df2 = pd.read_csv('data/ga_sessions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1328ebdf",
   "metadata": {},
   "source": [
    "df3 = df3 = pd.merge(df, df2, on='session_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae4546d",
   "metadata": {},
   "source": [
    "df3 = event_action(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "540c97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ad_campaign(df3):\n",
    "    print( 'ad_campaign start')\n",
    "    try:\n",
    "        with open('data/utm_c_frec_dict2.json', 'r') as f:\n",
    "            utm_c_frec_dict = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "\n",
    "        utm_c_frec_dict = {}\n",
    "        counter = 1\n",
    "        for pos in df3.utm_campaign.unique():\n",
    "            if len(df3[(df3.utm_campaign == pos) & (df3.event_action == 1)]) == 0:\n",
    "                utm_c_frec_dict[str(pos)] = 0\n",
    "            else:\n",
    "                utm_c_frec_dict[str(pos)] = round(len(df3[(df3.utm_campaign == pos) & (df3.event_action == 1)]) / len(df3[df3.utm_campaign == pos]), 5)\n",
    "\n",
    "            #print(counter)\n",
    "            counter = counter  + 1\n",
    "        with open('data/utm_c_frec_dict2.json', 'w') as f: \n",
    "            json.dump(utm_c_frec_dict, f)\n",
    "\n",
    "    finally:\n",
    "        df3['camp_succ_rate'] = df3.utm_campaign.apply(lambda x: utm_c_frec_dict[str(x)])\n",
    "    \n",
    "    #print(utm_c_frec_dict)\n",
    "    print( 'ad_campaign end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ed08b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ad_campaign_v_2(df3):\n",
    "    \n",
    "    print( 'ad_campaign v2 start')\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        with open('data/utm_c_frec_dict3.json', 'r') as f:\n",
    "            utm_c_frec_dict = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "        df5 = df3[['utm_campaign', 'event_action']]\n",
    "        succ_camps = df5[df5.event_action == 1].utm_campaign.value_counts(dropna=False)\n",
    "        all_camps = df5.utm_campaign.value_counts(dropna=False)\n",
    "\n",
    "        utm_c_frec_dict = {}\n",
    "        \n",
    "        for pos in all_camps.keys():\n",
    "            if pos in succ_camps.keys():\n",
    "                utm_c_frec_dict[str(pos)] = round(succ_camps[pos] / all_camps[pos], 5)\n",
    "            else:\n",
    "                utm_c_frec_dict[str(pos)] = 0\n",
    "        \n",
    "        \n",
    "        with open('data/utm_c_frec_dict3.json', 'w') as f: \n",
    "            json.dump(utm_c_frec_dict, f)\n",
    "\n",
    "    finally:\n",
    "        df3['camp_succ_rate'] = df3.utm_campaign.apply(lambda x: utm_c_frec_dict[str(x)])\n",
    "    \n",
    "    #print(utm_c_frec_dict)\n",
    "    print( 'ad_campaign v2 end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40072e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_of_week(df3):\n",
    "    print( 'day_of_week start')\n",
    "    df3['new_date'] = pd.to_datetime(df3['visit_date'])\n",
    "    df3['day_of_week'] = df3.new_date.dt.dayofweek\n",
    "    \n",
    "    df3 = df3.drop('new_date', axis=1)\n",
    "    print('day_of_week end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21610a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def empties(df3):\n",
    "    print( 'empties end')\n",
    "    df3.loc[df3.utm_source.isna() == True, 'utm_source'] = 'other'\n",
    "    df3.loc[df3.utm_adcontent.isna() == True, 'utm_adcontent'] = 'Other'\n",
    "    df3.loc[df3.device_brand.isna() == True, 'device_brand'] = 'other'\n",
    "    \n",
    "    print( 'empties end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')  \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41d98c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolution_func(df3):\n",
    "    print('resolution_func start')\n",
    "    #resolution\n",
    "    bounds = []\n",
    "    df3['resolution'] = df3.device_screen_resolution.apply(lambda x:eval(x.replace('x','*')))\n",
    "    for device in df3.device_category.unique():\n",
    "        q25 = df3[df3.device_category == device].resolution.quantile(0.25)\n",
    "        q75 = df3[df3.device_category == device].resolution.quantile(0.75)\n",
    "        iqr = q75 - q25\n",
    "        bounds.append((device, q25 - 1.5 * iqr, q75 + 1.5 * iqr))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    test_list = list(df3.device_screen_resolution)\n",
    "    test_list2 = list(df3.device_category)\n",
    "\n",
    "    for i in range(len(test_list)):\n",
    "        test_list[i] = eval(test_list[i].replace('x','*'))\n",
    "\n",
    "    tst_l = list(zip(test_list2, test_list))\n",
    "\n",
    "    resolution = []\n",
    "\n",
    "    for i in range(len(tst_l)):\n",
    "        if tst_l[i][0] == bounds[0][0]:\n",
    "            resolution.append(bounds[0][0]+'_high' if tst_l[i][1] >= bounds[0][2] * 0.7 else (bounds[0][0]+'_medium' if bounds[0][2] * 0.7 > tst_l[i][1] >= bounds[0][2] * 0.1 else bounds[0][0]+'_low'))\n",
    "        elif tst_l[i][0] == bounds[1][0]:\n",
    "            resolution.append(bounds[1][0]+'_high' if tst_l[i][1] >= bounds[1][2] * 0.7 else (bounds[1][0]+'_medium' if bounds[1][2] * 0.7 > tst_l[i][1] >= bounds[1][2] * 0.1 else bounds[1][0]+'_low'))\n",
    "        elif tst_l[i][0] == bounds[2][0]:\n",
    "            resolution.append(bounds[2][0]+'_high' if tst_l[i][1] >= bounds[2][2] * 0.7 else (bounds[2][0]+'_medium' if bounds[2][2] * 0.7 > tst_l[i][1] >= bounds[2][2] * 0.1 else bounds[2][0]+'_low'))\n",
    "\n",
    "    df3['device_screen_resolution'] = resolution\n",
    "    df3 = df3.drop('resolution', axis=1)\n",
    "    \n",
    "    print('resolution_func end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    \n",
    "    return df3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f81310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolution_func_v_2(df3):\n",
    "    print('resolution_func v2 start')\n",
    "    #resolution\n",
    "    bounds = []\n",
    "    df3['device_screen_resolution'] = df3.device_screen_resolution.apply(lambda x:eval(x.replace('x','*')))\n",
    "\n",
    "    \n",
    "    print('resolution_func v2 end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    \n",
    "    return df3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23b6e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country(df3, trsh = 0.001):\n",
    "    print('country start')\n",
    "    #geo_country\n",
    "    country_list = list(df3.geo_country.unique())\n",
    "    for i in range(len(country_list)):\n",
    "        country_list[i] = ( len(df3[df3.geo_country == country_list[i]]), country_list[i])\n",
    "    country_list = sorted(country_list, reverse=True)\n",
    "\n",
    "#    trsh = 0.0005\n",
    "    df3_len = len(df3) \n",
    "    for item in country_list:\n",
    "        if item[0] / df3_len >= trsh:\n",
    "            continue\n",
    "        else:\n",
    "            df3.loc[df3.geo_country == item[1], 'geo_country'] = 'some_unimportant_country'\n",
    "    \n",
    "    print( 'country end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3af77a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_v_2(df3):\n",
    "    print('country v2  start')\n",
    "    #geo_country\n",
    "    counter = 0\n",
    "    country_list_new = dict()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        with open('data/country_list_new.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                country_list_new[my_tuple[0]] = my_tuple[1]\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "        \n",
    "        succ_total = len(df3[df3.event_action == 1])\n",
    "        country_list_success = df3[df3.event_action == 1].geo_country.value_counts().sort_values(ascending=False)\n",
    "        country_list_new = []\n",
    "        for country in country_list_success.keys():\n",
    "            country_list_new.append(f'{country}*{str(round(country_list_success[country] / succ_total, 4))}%')\n",
    "            counter += 1\n",
    "            if counter == 23:\n",
    "                break\n",
    "\n",
    "        with open('data/country_list_new.txt', 'w') as f:\n",
    "            for t in country_list_new:\n",
    "                f.write(str(t) +'\\n')\n",
    "                \n",
    "        country_list_new = dict()        \n",
    "        with open('data/country_list_new.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                country_list_new[my_tuple[0]] = my_tuple[1]                \n",
    "\n",
    "\n",
    "    finally:\n",
    "        df3['geo_country'] = df3['geo_country'].apply(lambda x: country_list_new[x] if x in country_list_new else 0.0001)\n",
    "        \n",
    "    \n",
    "\n",
    "    #print(sum(df4.isnull().sum().values))\n",
    "    #print(df4.isnull().sum())\n",
    "    print('country v2 end')    \n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')     \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82a5c836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def city(df3, trsh = 0.001):\n",
    "    print('city start')\n",
    "    #geo_city\n",
    "    city_list = []\n",
    "    df3_len = len(df3)\n",
    "    try:\n",
    "        with open('data/city_list1.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace('(', '').replace(')', '').replace(\"'\", '')\n",
    "                # split on comma and convert each element to correct type\n",
    "                tuple_elements = [int(e.strip()) if e.strip().isdigit() else e.strip() for e in line.split(',')]\n",
    "                # create tuple and add to list\n",
    "                my_tuple = tuple(tuple_elements)\n",
    "                city_list.append(my_tuple)\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "\n",
    "        city_list = list(zip(df3.geo_city.value_counts().values, df3.geo_city.value_counts().keys() ))\n",
    "        city_list = sorted(city_list, reverse=True)\n",
    "\n",
    "        with open('data/city_list1.txt', 'w') as f:\n",
    "            for t in city_list:\n",
    "                f.write(str(t) +'\\n')\n",
    "\n",
    "\n",
    "\n",
    "    finally:\n",
    "#        trsh = 0.0005\n",
    "        city_list_valid = []\n",
    "        \n",
    "        for item in city_list:\n",
    "            #print(item[1], ' - ', round(item[0] / df3_len, 4),'%' )\n",
    "            if round(item[0] / 15000000, 4) >= trsh:   #df3_len, 4) >= trsh:\n",
    "                city_list_valid.append(item[1])\n",
    "                #print('trsh == 2000 - ', item[0], item[1], round(item[0] / df3_len, 4) >= trsh, ' - appended')\n",
    "\n",
    "        df3.loc[(~df3['geo_city'].isin(city_list_valid)), 'geo_city'] = 'some_unimportant_city'\n",
    "    \n",
    "    \n",
    "\n",
    "    #print(sum(df4.isnull().sum().values))\n",
    "    #print(df4.isnull().sum())\n",
    "    print('city end')    \n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')      \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d07109ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def city_v_2(df3):\n",
    "    print('city v2  start')\n",
    "    #geo_city\n",
    "    counter = 0\n",
    "    city_list_new = dict()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        with open('data/city_list_new.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                city_list_new[my_tuple[0]] = my_tuple[1]\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "        \n",
    "        succ_total = len(df3[df3.event_action == 1])\n",
    "        city_list_success = df3[df3.event_action == 1].geo_city.value_counts().sort_values(ascending=False)\n",
    "        city_list_new = []\n",
    "        for city in city_list_success.keys():\n",
    "            city_list_new.append(f'{city}*{str(round(city_list_success[city] / succ_total, 4))}%')\n",
    "            counter += 1\n",
    "            if counter == 26:\n",
    "                break\n",
    "\n",
    "        with open('data/city_list_new.txt', 'w') as f:\n",
    "            for t in city_list_new:\n",
    "                f.write(str(t) +'\\n')\n",
    "                \n",
    "        with open('data/city_list_new.txt', 'r') as f:\n",
    "            city_list_new = dict()\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                city_list_new[my_tuple[0]] = my_tuple[1]                \n",
    "\n",
    "\n",
    "    finally:\n",
    "        \n",
    "        df3['geo_city'] = df3['geo_city'].apply(lambda x: city_list_new[x] if x in city_list_new else 0.0001)\n",
    "        \n",
    "    \n",
    "\n",
    "    #print(sum(df4.isnull().sum().values))\n",
    "    #print(df4.isnull().sum())\n",
    "    print('city v2 end')    \n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')      \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae66ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def device_brand(df3):\n",
    "    print('device_brand start')\n",
    "    #device_brand\n",
    "    counter = 0\n",
    "    device_brand_list_new = dict()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        with open('data/device_brand_list_new1.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                device_brand_list_new[my_tuple[0]] = my_tuple[1]\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "        succ_total = len(df3[df3.event_action == 1])\n",
    "        device_brand_list_success = df3[df3.event_action == 1].device_brand.value_counts().sort_values(ascending=False)\n",
    "        device_brand_list_new = []\n",
    "        for device_brand in device_brand_list_success.keys():\n",
    "            device_brand_list_new.append(f'{device_brand}*{str(round(device_brand_list_success[device_brand] / succ_total, 4))}%')\n",
    "            counter += 1\n",
    "            if counter == 23:\n",
    "                break\n",
    "\n",
    "        with open('data/device_brand_list_new1.txt', 'w') as f:\n",
    "            for t in device_brand_list_new:\n",
    "                f.write(str(t) +'\\n')\n",
    "                \n",
    "        device_brand_list_new = dict()\n",
    "        with open('data/device_brand_list_new1.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                device_brand_list_new[my_tuple[0]] = my_tuple[1]                \n",
    "\n",
    "\n",
    "    finally:\n",
    "        df3['device_brand'] = df3['device_brand'].apply(lambda x: device_brand_list_new[x] if x in device_brand_list_new else 0.0001)\n",
    "        \n",
    "    \n",
    "\n",
    "    #print(sum(df4.isnull().sum().values))\n",
    "    #print(df4.isnull().sum())\n",
    "    print('device_brand end')    \n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')      \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a3a125ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_brand v 2 start\n",
      "device_brand v 2 end\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "df3 = device_brand_v_2(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da9daf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv('data/df3_10k_50n_50p.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c30c2907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_brand v 2 start\n",
      "device_brand v 2 end\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "df4 = device_brand_v_2(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "51da2dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apple                     2961\n",
       "some_unimportant_brand    2519\n",
       "Samsung                   1775\n",
       "Xiaomi                    1323\n",
       "Huawei                     881\n",
       "Realme                      89\n",
       "OPPO                        69\n",
       "Vivo                        50\n",
       "OnePlus                     42\n",
       "Nokia                       36\n",
       "Asus                        34\n",
       "Google                      30\n",
       "Sony                        28\n",
       "ZTE                         25\n",
       "Lenovo                      17\n",
       "Blackview                   16\n",
       "Motorola                    13\n",
       "Meizu                       13\n",
       "Tecno                       10\n",
       "LG                           9\n",
       "DOOGEE                       9\n",
       "BQ                           7\n",
       "Umidigi                      5\n",
       "Alcatel                      4\n",
       "HTC                          4\n",
       "AGM                          4\n",
       "itel                         4\n",
       "Vsmart                       3\n",
       "Oukitel                      3\n",
       "TP-Link                      2\n",
       "BlackBerry                   2\n",
       "LeEco                        2\n",
       "Haier                        1\n",
       "Highscreen                   1\n",
       "Leagoo                       1\n",
       "Coolpad                      1\n",
       "Fly                          1\n",
       "Mozilla                      1\n",
       "LeTV                         1\n",
       "Ulefone                      1\n",
       "Mito                         1\n",
       "Condor                       1\n",
       "MXQ                          1\n",
       "Name: device_brand, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.device_brand.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2719895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def device_brand_v_2(df3, trsh = 0.0012):\n",
    "    print('device_brand v 2 start')\n",
    "    #device_brand\n",
    "    brand_list = []\n",
    "    df3_len = len(df3)\n",
    "    \n",
    "    try:\n",
    "        with open('data/brand_list1.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace('(', '').replace(')', '').replace(\"'\", '')\n",
    "                # split on comma and convert each element to correct type\n",
    "                tuple_elements = [int(e.strip()) if e.strip().isdigit() else e.strip() for e in line.split(',')]\n",
    "                # create tuple and add to list\n",
    "                my_tuple = tuple(tuple_elements)\n",
    "                brand_list.append(my_tuple)\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "\n",
    "        brand_list = list(zip(df3.device_brand.value_counts().values, df3.device_brand.value_counts().keys() ))\n",
    "        brand_list = sorted(brand_list, reverse=True)\n",
    "\n",
    "        with open('data/brand_list1.txt', 'w') as f:\n",
    "            for t in brand_list:\n",
    "                f.write(str(t) +'\\n')\n",
    "\n",
    "\n",
    "\n",
    "    finally:\n",
    "#        trsh = 0.0005\n",
    "        brand_list_valid = []\n",
    "        \n",
    "        for item in brand_list:\n",
    "            #print(item[0], ' ', item[0] / df3_len,'>=', trsh, ' ', round(item[0] / df3_len, 4) >= trsh )\n",
    "            if item[0] / df3_len >= trsh:\n",
    "                brand_list_valid.append(item[1])\n",
    "                #print(len(brand_list_valid), ' ', item[0],' ',item[1] )\n",
    "\n",
    "        df3.loc[(~df3['device_brand'].isin(brand_list_valid)), 'device_brand'] = 'some_unimportant_brand'\n",
    "    \n",
    "    \n",
    "    print('device_brand v 2 end')    \n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')      \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff60f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_stuff(df3):\n",
    "    print('encode_stuff start')\n",
    "    cols_to_encode = ['utm_source', \n",
    "                      'utm_medium', \n",
    "                      'utm_adcontent', \n",
    "                      #'device_brand', \n",
    "                      'device_category', \n",
    "                      'device_screen_resolution', \n",
    "                      'device_browser',\n",
    "                      'utm_campaign'\n",
    "                      #,'geo_country',\n",
    "                      #'geo_city'\n",
    "                     ]\n",
    "    \n",
    "    #encoding\n",
    "    encoded_features = pd.DataFrame()\n",
    "\n",
    "    for col in cols_to_encode:\n",
    "\n",
    "        pre_encoded_df3 = df3[[col]]\n",
    "        encoder = OneHotEncoder(categories='auto', handle_unknown='ignore', sparse=False)\n",
    "        encoded_array = encoder.fit_transform(pre_encoded_df3)\n",
    "        #feature_names = [f'{col}_{name}' for name in encoder.get_feature_names_out()]\n",
    "        feature_names = encoder.get_feature_names_out()\n",
    "        encoded_df3 = pd.DataFrame(encoded_array, columns=feature_names)\n",
    "\n",
    "        #if len(encoded_features) == 0:\n",
    "        #    encoded_features = encoded_df3.copy()\n",
    "        #else:\n",
    "        #    encoded_features[feature_names] = encoded_df3.values\n",
    "        \n",
    "        df3[feature_names] = encoded_df3.values\n",
    "    #print(encoded_features.isnull().sum())\n",
    "\n",
    "    #df3 = df3.join(encoded_features)\n",
    "    #print(df3.isnull().sum())\n",
    "    df3 = df3.drop(cols_to_encode, axis=1)\n",
    "    print( 'encode_stuff end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')  \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "439622ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_stuff(df3):\n",
    "    #scaling\n",
    "    print('scale_stuff start')\n",
    "    cols_to_scale = ['visit_number',\n",
    "                     #'day_of_week'\n",
    "                    # ,'device_screen_resolution'\n",
    "                    ]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(df3.loc[:,cols_to_scale])\n",
    "    scaled_feature_names = [f'{name}_scaled' for name in scaler.get_feature_names_out()]\n",
    "    #scaler.get_feature_names_out()\n",
    "\n",
    "    #scaled_df = pd.DataFrame(scaled_features, columns=scaled_feature_names)\n",
    "    df3[scaled_feature_names] = scaled_features\n",
    "    #print(scaled_df.shape, scaled_df.columns)\n",
    "    #print(scaled_df.isnull().sum())\n",
    "\n",
    "    #df3['scaled_feature_names'] = scaled_df\n",
    "    #print(df3.shape, df3.columns)\n",
    "    df3 = df3.drop(cols_to_scale, axis=1)\n",
    "    for column in df3.columns:\n",
    "        print(column)\n",
    "    print(len(df3.columns))\n",
    "    #print(df3.isnull().sum())\n",
    "    #print(len(df3.columns), df3.columns)\n",
    "    print('scale_stuff end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')  \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2a7612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stuff(df3):\n",
    "    #pre-existing list of columns\n",
    "    print('filter_stuff start')\n",
    "    cols_to_drop = [\n",
    "        'session_id',\n",
    "        'hit_date',\n",
    "        'hit_time',\n",
    "        'hit_number',\n",
    "        'hit_type',\n",
    "        'hit_referer',\n",
    "        'hit_page_path',\n",
    "        'event_category',\n",
    "        'event_label',\n",
    "        'event_value',\n",
    "        'client_id',\n",
    "        #'new_date',\n",
    "        'visit_date',\n",
    "        'visit_number',\n",
    "        'utm_keyword',\n",
    "        'device_os',\n",
    "        'device_model',\n",
    "        'visit_time'\n",
    "    ]\n",
    "    \n",
    "    cols_to_encode = [\n",
    "        'utm_source',\n",
    "        'utm_medium', \n",
    "        'utm_adcontent',\n",
    "        'device_brand', \n",
    "        'device_category', \n",
    "        'device_screen_resolution',\n",
    "        'device_browser',\n",
    "        'utm_campaign',\n",
    "        'geo_country',\n",
    "        'geo_city'\n",
    "    ]\n",
    "    #dropping\n",
    "    #cols_to_drop = []\n",
    "    #for col in df_columns:\n",
    "    #    cols_to_drop.append(str(col))\n",
    "    #cols_to_drop = cols_to_drop + ['client_id','new_date', 'visit_date', 'utm_keyword', 'device_os', 'device_model', 'visit_time']    \n",
    "    \n",
    "    df3 = df3.drop(cols_to_drop, axis=1)\n",
    "    #df3 = df3.drop(cols_to_encode, axis=1)\n",
    "    \n",
    "    try:\n",
    "        df3 = df3.drop('Unnamed: 0', axis=1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        df3 = df3.drop('Unnamed: 0.1', axis=1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        df3 = df3.drop('Unnamed: 0.2', axis=1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    print('filter_stuff end')\n",
    "    #print(sum(df3.isnull().sum().values))\n",
    "    #print(df3.isnull().sum())\n",
    "    print(df3.columns)\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "859940a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stuff(df3):\n",
    "    #checking\n",
    "    print('check_stuff start')\n",
    "    counter = 0\n",
    "    for feature in df3.columns:\n",
    "        if df3[feature].dtype != 'O':\n",
    "            #print(feature, ' - ', df3[feature].dtype)\n",
    "            counter += 1\n",
    "        else:\n",
    "            print(feature)\n",
    "    print(counter == len(df3.columns))\n",
    "\n",
    "\n",
    "    #checking 2\n",
    "    counter = 0\n",
    "    for feature in df3.columns:\n",
    "        if len(df3[df3[str(feature)].isna() == True]) != 0:\n",
    "            print(feature, ' - ', len(df3[df3[str(feature)].isna() == True]))\n",
    "            counter += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if counter == 0:\n",
    "        print('vse zaebis\", pustukh fi4ei net')    \n",
    "    \n",
    "    \n",
    "    print('check_stuff end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "814b693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stuff_2(df3):\n",
    "    #checking\n",
    "    print('check_stuff_2 start')\n",
    "\n",
    "    counter = 0\n",
    "    for feature in df3.columns:\n",
    "        if df3[feature].dtype != 'O':\n",
    "            #print(feature, ' - ', df3[feature].dtype)\n",
    "            counter += 1\n",
    "        else:\n",
    "            print(feature)\n",
    "    print(counter == len(df3.columns))\n",
    "\n",
    "\n",
    "    #checking 2\n",
    "    empty_features = False\n",
    "    if sum(df3.isnull().sum()) != 0:\n",
    "        print(df3.isnull().sum())\n",
    "        empty_features = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if empty_features == False:\n",
    "        print('vse zaebis\", pustukh fi4ei net') \n",
    "    #print(len(df3.isnull().sum()))\n",
    "    print(df3.shape,  'check_stuff_2 end') #df3.shape,\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')     \n",
    "    \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b018e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stuff_3(df3):\n",
    "    for column in df3.columns:\n",
    "        print(column)\n",
    "        print(df3[column].value_counts())\n",
    "    print(len(df3.columns))\n",
    "    print(' - ')\n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a48f726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_stuff(df3):\n",
    "    y = df3['event_action']\n",
    "    \n",
    "    df3 = df3.drop('event_action', axis=1)\n",
    "    print(df3.columns)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df3,y, test_size=0.3)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=400, min_samples_leaf=2, max_features='sqrt')\n",
    "    rf.fit(x_train, y_train)\n",
    "    \n",
    "    predicted_train = rf.predict(x_train)\n",
    "    predicted_test = rf.predict(x_test)\n",
    "    \n",
    "    #print(df3.shape, ' - shape', ' function - ')\n",
    "    \n",
    "    \n",
    "    print('train acc score - ',accuracy_score(y_train, predicted_train))\n",
    "    print('test acc score - ', accuracy_score(y_test, predicted_test))\n",
    "\n",
    "    print('train roc score - ',roc_auc_score(y_train, rf.predict_proba(x_train)[:,1]))\n",
    "    print('test roc score - ',roc_auc_score(y_test, rf.predict_proba(x_test)[:,1]))\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c73138c",
   "metadata": {},
   "source": [
    "with open('models/rf_model.pkl', 'wb') as file:\n",
    "    dill.dump(rf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d65451",
   "metadata": {},
   "source": [
    "## function declarations end here. its wildlands after that...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e72138",
   "metadata": {},
   "source": [
    "df = pd.read_csv('data/ga_hits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7945579",
   "metadata": {},
   "source": [
    "df2 = pd.read_csv('data/ga_sessions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe5c01f",
   "metadata": {},
   "source": [
    "df3 = pd.merge(df, df2, on='session_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272d113e",
   "metadata": {},
   "source": [
    "df3 = event_action(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "301c1097",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = [[0.6375, 'ad_camp V, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
    " [0.6375, 'ad_camp X, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
    " [0.6375, 'ad_camp X, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
    " [0.6482, 'ad_camp V, resol v1 X, ctry v1 V, ct v1 V, brand v1 V'],\n",
    " [0.6504, 'ad_camp X, resol v1 X, ctry v1 X, ct v1 X, brand v1 X'],\n",
    " [0.6409, 'ad_camp X, resol v1 V, ctry v1 X, ct v1 X, brand v1 X'],\n",
    " [0.6396, 'ad_camp X, resol v2 V, ctry v1 X, ct v1 X, brand v1 X'],\n",
    " [0.6502, 'ad_camp X, resol v2 X, ctry v1 V, ct v1 X, brand v1 X'],\n",
    " [0.6503, 'ad_camp X, resol v2 X, ctry v2 V, ct v1 X, brand v1 X'],\n",
    " [0.6504, 'ad_camp X, resol v2 X, ctry v2 X, ct v1 X, brand v1 X'],\n",
    " [0.6498, 'ad_camp X, resol v2 X, ctry v2 X, ct v1 V, brand v1 X'],\n",
    " [0.6389, 'ad_camp X, resol v2 X, ctry v2 X, ct v2 V, brand v1 X'],\n",
    " [0.649, 'ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v1 V'],\n",
    " [0.6503, 'ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
    " [0.6504, 'ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
    " [0.6504, 'ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
    " [0.6603, 'ad_camp V, resol V, cntry V, ct V, brand V, 200k 50/50'],\n",
    " [0.6576, 'ad_camp V, resol V, cntry V, ct V, brand V, 200k 70/30'],\n",
    " [0.6456, 'ad_camp V, resol V, cntry V, ct V, brand V, 140k 30/70'],\n",
    " [0.6469, 'ad_camp V, resol V, cntry V, ct V, brand V, 100k 50/50'],\n",
    " [0.6428, 'ad_camp V, resol V, cntry V, ct V, brand V, 100k 70/30'],\n",
    " [0.6447, 'ad_camp V, resol V, cntry V, ct V, brand V, 100k 30/70'],\n",
    " [0.6438, 'ad_camp v2 V, resol V, cntry V, ct V, brand V, 100k 30/70'],\n",
    " [0.6445, 'ad_camp v2 V, resol V, cntry V, ct V, brand v2 V, 100k 30/70'],\n",
    " [0.6459, 'ad_camp V, resol V, cntry V, ct V, brand v2 V, 100k 30/70'],\n",
    " [0.6312, 'ad_camp V, resol V, cntry V, ct v2 V, brand v2 V, 100k 30/70'],\n",
    " [0.6463, 'ad_camp V, resol V, cntry v 2V, ct V, brand v2 V, 100k 30/70'],\n",
    " [0.6461, 'ad_camp V, resol v2 V, cntry v2 V, ct V, brand v2 V, 100k 30/70'],\n",
    " [0.6482, 'ad_camp V, resol v2 V, cntry v2 V, ct V, brand v2 V, 100k 50/50'],\n",
    " [0.6486, 'ad_camp V, resol v2 V, cntry v2 V, ct V, brand v2 V, 100k 50/50']\n",
    " [0.6463, 'ad_camp X, resol v2 V, cntry v 2V, ct V, brand v2 V, 100k 50/50']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46f13be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_single_fit = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a3befdb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func v2 start\n",
      "resolution_func v2 end\n",
      "-\n",
      "country v2  start\n",
      "country v2 end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand v 2 start\n",
      "device_brand v 2 end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['utm_source', 'utm_medium', 'utm_campaign', 'utm_adcontent',\n",
      "       'device_category', 'device_brand', 'device_screen_resolution',\n",
      "       'device_browser', 'geo_country', 'geo_city', 'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "utm_source\n",
      "ZpYIoDJMcFzVoPFsHGJL    2407\n",
      "fDLlAcSmythWSCVMvqvL    1498\n",
      "kjsLglQLzykiRbcDiGcD     960\n",
      "bByPQxmDaMXgpHeypKSM     772\n",
      "BHcvLfOaCWvWTykYqHVe     594\n",
      "                        ... \n",
      "EvhrtRzIJnQYHziPiLzV       1\n",
      "other                      1\n",
      "PKriXrefSFPLBYtCRGSE       1\n",
      "XzfzEBYZWgSDtJNXOadn       1\n",
      "SgIUDYUKnyWHVowUOqid       1\n",
      "Name: utm_source, Length: 67, dtype: int64\n",
      "utm_medium\n",
      "banner             2281\n",
      "cpc                1557\n",
      "(none)             1498\n",
      "referral           1074\n",
      "cpm                 361\n",
      "organic             323\n",
      "push                123\n",
      "email                88\n",
      "blogger_channel      35\n",
      "stories              29\n",
      "smartbanner          24\n",
      "cpv                  18\n",
      "cpa                  17\n",
      "blogger_stories      13\n",
      "smm                  12\n",
      "tg                   11\n",
      "post                  9\n",
      "app                   5\n",
      "outlook               4\n",
      "clicks                4\n",
      "(not set)             4\n",
      "link                  3\n",
      "landing               2\n",
      "medium                2\n",
      "blogger_header        2\n",
      "CPM                   1\n",
      "Name: utm_medium, dtype: int64\n",
      "utm_campaign\n",
      "LTuZkdKfxRGVceoWkVyg    2622\n",
      "LEoPHuyFvzoNfnzGgfcd    1435\n",
      "gecBYcKZCPMcVYdSSzKP     608\n",
      "FTjNLDyTrXaWYgZymFkV     367\n",
      "sbJRYgVfvcnqKJNDDYIr      91\n",
      "                        ... \n",
      "MBHgRPNeTcONuVFFXgmz       1\n",
      "ukwEyFczbqbKStCfJGsY       1\n",
      "iYBYglGljMDRQyqHRiPH       1\n",
      "vNNYHvZtTVtJICHsjBBL       1\n",
      "KGpIIoFhRfLgffkknBkK       1\n",
      "Name: utm_campaign, Length: 159, dtype: int64\n",
      "utm_adcontent\n",
      "JNHcPlZPxEMWDnRiyoBf    4788\n",
      "Other                   1373\n",
      "vCIpmpaGBnIQhyYNkXqp     728\n",
      "xhoenQgDQsgfEPYNPwKO     153\n",
      "PkybGvWbaqORmxjNunqZ     151\n",
      "                        ... \n",
      "vilbbyUvEWbiJvxXpaNN       1\n",
      "htRZUQDANvNrHaxZjsjz       1\n",
      "qukbsiXCRCiIMciUjStT       1\n",
      "LrfKeexYNjGjsqQVSCdi       1\n",
      "IwBedorwDIzxDRIZUTNo       1\n",
      "Name: utm_adcontent, Length: 67, dtype: int64\n",
      "device_category\n",
      "mobile     5628\n",
      "desktop    1795\n",
      "tablet       77\n",
      "Name: device_category, dtype: int64\n",
      "device_brand\n",
      "Apple                     2228\n",
      "some_unimportant_brand    1875\n",
      "Samsung                   1357\n",
      "Xiaomi                     971\n",
      "Huawei                     661\n",
      "Realme                      69\n",
      "OPPO                        49\n",
      "Vivo                        35\n",
      "OnePlus                     29\n",
      "Asus                        28\n",
      "Nokia                       27\n",
      "Google                      23\n",
      "ZTE                         23\n",
      "Sony                        19\n",
      "Lenovo                      16\n",
      "Blackview                   12\n",
      "Meizu                       10\n",
      "Motorola                     9\n",
      "DOOGEE                       7\n",
      "Tecno                        6\n",
      "BQ                           5\n",
      "LG                           5\n",
      "AGM                          4\n",
      "itel                         4\n",
      "Umidigi                      4\n",
      "Vsmart                       2\n",
      "TP-Link                      2\n",
      "BlackBerry                   2\n",
      "LeEco                        2\n",
      "HTC                          2\n",
      "Oukitel                      2\n",
      "Haier                        1\n",
      "Highscreen                   1\n",
      "Ulefone                      1\n",
      "Leagoo                       1\n",
      "Mito                         1\n",
      "Coolpad                      1\n",
      "Fly                          1\n",
      "Mozilla                      1\n",
      "LeTV                         1\n",
      "Alcatel                      1\n",
      "Condor                       1\n",
      "MXQ                          1\n",
      "Name: device_brand, dtype: int64\n",
      "device_screen_resolution\n",
      "370944     692\n",
      "2073600    551\n",
      "304500     493\n",
      "334443     426\n",
      "250125     366\n",
      "          ... \n",
      "427042       1\n",
      "5308416      1\n",
      "409920       1\n",
      "323439       1\n",
      "1445906      1\n",
      "Name: device_screen_resolution, Length: 224, dtype: int64\n",
      "device_browser\n",
      "Chrome              4065\n",
      "Safari              2031\n",
      "YaBrowser            610\n",
      "Android Webview      212\n",
      "Safari (in-app)      207\n",
      "Samsung Internet     123\n",
      "Firefox               92\n",
      "Edge                  85\n",
      "Opera                 72\n",
      "UC Browser             2\n",
      "Android Runtime        1\n",
      "Name: device_browser, dtype: int64\n",
      "geo_country\n",
      "0.9810    7316\n",
      "0.0035      34\n",
      "0.0001      28\n",
      "0.0009      24\n",
      "0.0004      21\n",
      "0.0012      17\n",
      "0.0006      16\n",
      "0.0014      13\n",
      "0.0003       9\n",
      "0.0007       7\n",
      "0.0010       6\n",
      "0.0002       5\n",
      "0.0005       4\n",
      "Name: geo_country, dtype: int64\n",
      "geo_city\n",
      "Moscow                   3476\n",
      "Saint Petersburg         1036\n",
      "some_unimportant_city     815\n",
      "Krasnodar                 164\n",
      "Kazan                     151\n",
      "                         ... \n",
      "Penza                       5\n",
      "Astrakhan                   4\n",
      "Tomsk                       4\n",
      "Reutov                      4\n",
      "Pushkino                    4\n",
      "Name: geo_city, Length: 80, dtype: int64\n",
      "camp_succ_rate\n",
      "0.00731    2622\n",
      "0.00577    1435\n",
      "0.00000    1129\n",
      "0.00845     608\n",
      "0.00612     367\n",
      "           ... \n",
      "0.00386       1\n",
      "0.01053       1\n",
      "0.00222       1\n",
      "0.00505       1\n",
      "0.00499       1\n",
      "Name: camp_succ_rate, Length: 144, dtype: int64\n",
      "11\n",
      " - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func v2 start\n",
      "resolution_func v2 end\n",
      "-\n",
      "country v2  start\n",
      "country v2 end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand v 2 start\n",
      "device_brand v 2 end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['utm_source', 'utm_medium', 'utm_campaign', 'utm_adcontent',\n",
      "       'device_category', 'device_brand', 'device_screen_resolution',\n",
      "       'device_browser', 'geo_country', 'geo_city', 'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "utm_source\n",
      "ZpYIoDJMcFzVoPFsHGJL    807\n",
      "fDLlAcSmythWSCVMvqvL    518\n",
      "kjsLglQLzykiRbcDiGcD    288\n",
      "bByPQxmDaMXgpHeypKSM    245\n",
      "BHcvLfOaCWvWTykYqHVe    214\n",
      "MvfHsxITijuriZxsqZqt     94\n",
      "QxAxdyPLuQMEcrdZWdWb     74\n",
      "aXQzDWsJuGXeBXexNHjc     72\n",
      "jaSOmLICuBzCFqHfBdRg     42\n",
      "vFcAhRxLfOWKhvxjELkx     24\n",
      "RmEBuqrriAfAVsLQQmhk     22\n",
      "hTjLvqNxGggkGnxSCaTm     17\n",
      "oZCzWSykfixnjMPDNjSU      8\n",
      "ISrKoXQCxqqYvAZICvjs      7\n",
      "eLzNJHzPelJpEyBwMrKo      6\n",
      "IZEXUFLARCUMynmHNBGo      6\n",
      "nSReTmyFtbSjlPrTKoaX      4\n",
      "fgymSoTvjKPEgaIJqsiH      4\n",
      "HFaOtpcChAlcMuxEAlpu      4\n",
      "XiUifkjKLLnomcDRhswp      4\n",
      "gVRrcxiDQubJiljoTbGm      4\n",
      "DnEUulZAecfGPvdtZBYS      4\n",
      "TxKUcPpthBDPieTGmVhx      3\n",
      "SzZERoLMmrEUEhDaYcyN      2\n",
      "WEXkMlsnJodrzBgKJBpG      2\n",
      "BKeImrJuRDZcHiSSTdzm      2\n",
      "qVXuCoVQtPxcUkAXiXBa      2\n",
      "YlsczTIyBSwTLNtuDkCd      2\n",
      "LIWKeifdTCbuNeniIUqm      2\n",
      "HbolMJUevblAbkHClEQa      1\n",
      "dyicZQGoeASogoSafjEh      1\n",
      "pvCdohkUBGPPZOsCzVAu      1\n",
      "cAqxcRdSSFAyCPUxQHqy      1\n",
      "PlbkrSYoHuZBWfYjYnfw      1\n",
      "WeIwsqEbpZGZwhcQktNS      1\n",
      "MYrKypXYDhDVwJMUhCqu      1\n",
      "RxecHElWobBxIeAkqFXV      1\n",
      "FTAuYVNoYYxgvKMpKSLW      1\n",
      "eimRuUrNhZLAYcwRrNXu      1\n",
      "JcVHXwVSrnfIuOMMEkrJ      1\n",
      "NwLFDlNWnYxuLZEAZppl      1\n",
      "NwuIyBhuPCXhJVPLtXCC      1\n",
      "vNNYHvZtTVtJICHsjBBL      1\n",
      "oCqKpnSZJeYOVZTgTmKR      1\n",
      "iNFgfQPqHPBuvGCYtrQE      1\n",
      "ghoaGAksqhKomdFrxgyJ      1\n",
      "Name: utm_source, dtype: int64\n",
      "utm_medium\n",
      "banner             762\n",
      "(none)             518\n",
      "cpc                517\n",
      "referral           343\n",
      "cpm                108\n",
      "organic            102\n",
      "email               42\n",
      "push                38\n",
      "stories             12\n",
      "smartbanner         12\n",
      "blogger_channel     12\n",
      "cpa                  6\n",
      "tg                   5\n",
      "post                 4\n",
      "cpv                  4\n",
      "clicks               3\n",
      "blogger_stories      3\n",
      "outlook              2\n",
      "link                 2\n",
      "sms                  1\n",
      "landing              1\n",
      "(not set)            1\n",
      "smm                  1\n",
      "info_text            1\n",
      "Name: utm_medium, dtype: int64\n",
      "utm_campaign\n",
      "LTuZkdKfxRGVceoWkVyg    846\n",
      "LEoPHuyFvzoNfnzGgfcd    486\n",
      "gecBYcKZCPMcVYdSSzKP    212\n",
      "FTjNLDyTrXaWYgZymFkV    108\n",
      "SgIUDYUKnyWHVowUOqid     27\n",
      "                       ... \n",
      "WYZTTdhWPjttFYmcGjBP      1\n",
      "zmnpxOKDENholtspXiGy      1\n",
      "qjmBmKWCivQiONdxBwQN      1\n",
      "EvhrtRzIJnQYHziPiLzV      1\n",
      "quxdQHtdlpFZfBZSiXFZ      1\n",
      "Name: utm_campaign, Length: 105, dtype: int64\n",
      "utm_adcontent\n",
      "JNHcPlZPxEMWDnRiyoBf    1566\n",
      "Other                    469\n",
      "vCIpmpaGBnIQhyYNkXqp     250\n",
      "xhoenQgDQsgfEPYNPwKO      51\n",
      "PkybGvWbaqORmxjNunqZ      39\n",
      "LLfCasrxQzJIyuldcuWy      24\n",
      "nNqUcgFgcqQbTVSvgaHr      15\n",
      "XSkXBCPfnJjvxbfeewtd      15\n",
      "guyNoEvzgofQvvwExGOq       8\n",
      "AdeErYgVTbRcAWtHrMHq       6\n",
      "qhEmhjPXvwgEHdBikgEQ       6\n",
      "SOkCdPxfUcZUzzOdgGES       5\n",
      "yYdBRbPmBMUZHXwqGxNx       4\n",
      "sYzBROYhjSDbFZCpzGyf       4\n",
      "eEkLatVAYTkibdzPIyDi       4\n",
      "SAVVWaMghGnnvPOqMOIt       4\n",
      "aYAcKhelKzYpXrRYknSP       3\n",
      "LcGIUNPUAmXtQJaDfFBR       3\n",
      "dUuXlWzvmhDSyclWRhNP       2\n",
      "xZYEHLyYdGXkJENJpTtu       2\n",
      "WAeycgIqKXoOMXPzDUDX       2\n",
      "DZYjhfIUfdqhfuTNUmjn       2\n",
      "ZKlsrASsGaoEHfwkdKjL       1\n",
      "twlfGCnyRPFtCeUKaust       1\n",
      "sDHhLoedJZYxlBhsXywf       1\n",
      "rqvMZiqGRTZpxvRSUTzX       1\n",
      "OJiWyBKOyDITzXCZRSMH       1\n",
      "NNFDaOyxNbRfjYvClLnM       1\n",
      "TuyPWsGQruPMpKvRxeBF       1\n",
      "fxKLUhFToKQtGIyvjZXQ       1\n",
      "QEPLWgIvqPEGXcwBrsFw       1\n",
      "vilbbyUvEWbiJvxXpaNN       1\n",
      "BdalQBXFeDGQTswaQtOL       1\n",
      "eOWmIGTKVDPewucDtZXG       1\n",
      "AIONnJpjXjEluFHEjOyg       1\n",
      "EteMoEECGsaJeMnuvAZD       1\n",
      "qukbsiXCRCiIMciUjStT       1\n",
      "NhvfEqcSTGEZKxxvUZlj       1\n",
      "Name: utm_adcontent, dtype: int64\n",
      "device_category\n",
      "mobile     1870\n",
      "desktop     616\n",
      "tablet       14\n",
      "Name: device_category, dtype: int64\n",
      "device_brand\n",
      "Apple                     733\n",
      "some_unimportant_brand    644\n",
      "Samsung                   418\n",
      "Xiaomi                    352\n",
      "Huawei                    220\n",
      "Realme                     20\n",
      "OPPO                       20\n",
      "Vivo                       15\n",
      "OnePlus                    13\n",
      "Sony                        9\n",
      "Nokia                       9\n",
      "Google                      7\n",
      "Asus                        6\n",
      "LG                          4\n",
      "Tecno                       4\n",
      "Motorola                    4\n",
      "Blackview                   4\n",
      "Meizu                       3\n",
      "Alcatel                     3\n",
      "HTC                         2\n",
      "DOOGEE                      2\n",
      "ZTE                         2\n",
      "BQ                          2\n",
      "Vsmart                      1\n",
      "Umidigi                     1\n",
      "Lenovo                      1\n",
      "Oukitel                     1\n",
      "Name: device_brand, dtype: int64\n",
      "device_screen_resolution\n",
      "370944     224\n",
      "2073600    207\n",
      "304500     167\n",
      "334443     158\n",
      "376980     119\n",
      "          ... \n",
      "360192       1\n",
      "1882041      1\n",
      "2146560      1\n",
      "339768       1\n",
      "255267       1\n",
      "Name: device_screen_resolution, Length: 136, dtype: int64\n",
      "device_browser\n",
      "Chrome              1324\n",
      "Safari               682\n",
      "YaBrowser            229\n",
      "Android Webview       78\n",
      "Safari (in-app)       66\n",
      "Samsung Internet      36\n",
      "Edge                  34\n",
      "Firefox               30\n",
      "Opera                 21\n",
      "Name: device_browser, dtype: int64\n",
      "geo_country\n",
      "0.9810    2448\n",
      "0.0001      12\n",
      "0.0035       8\n",
      "0.0009       6\n",
      "0.0012       5\n",
      "0.0004       5\n",
      "0.0002       4\n",
      "0.0014       4\n",
      "0.0003       3\n",
      "0.0010       2\n",
      "0.0007       2\n",
      "0.0006       1\n",
      "Name: geo_country, dtype: int64\n",
      "geo_city\n",
      "Moscow                   1184\n",
      "Saint Petersburg          324\n",
      "some_unimportant_city     283\n",
      "Kazan                      59\n",
      "Krasnodar                  54\n",
      "                         ... \n",
      "Shchyolkovo                 1\n",
      "Orenburg                    1\n",
      "Lobnya                      1\n",
      "Surgut                      1\n",
      "Penza                       1\n",
      "Name: geo_city, Length: 75, dtype: int64\n",
      "camp_succ_rate\n",
      "0.00731    846\n",
      "0.00577    486\n",
      "0.00000    381\n",
      "0.00845    212\n",
      "0.00612    108\n",
      "          ... \n",
      "0.08198      1\n",
      "0.01599      1\n",
      "0.00047      1\n",
      "0.00561      1\n",
      "0.00241      1\n",
      "Name: camp_succ_rate, Length: 103, dtype: int64\n",
      "11\n",
      " - \n",
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func v2 start\n",
      "resolution_func v2 end\n",
      "-\n",
      "country v2  start\n",
      "country v2 end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand v 2 start\n",
      "device_brand v 2 end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['utm_source', 'utm_medium', 'utm_campaign', 'utm_adcontent',\n",
      "       'device_category', 'device_brand', 'device_screen_resolution',\n",
      "       'device_browser', 'geo_country', 'geo_city', 'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "utm_source\n",
      "ZpYIoDJMcFzVoPFsHGJL    2384\n",
      "fDLlAcSmythWSCVMvqvL    1498\n",
      "kjsLglQLzykiRbcDiGcD     950\n",
      "bByPQxmDaMXgpHeypKSM     777\n",
      "BHcvLfOaCWvWTykYqHVe     613\n",
      "                        ... \n",
      "NwuIyBhuPCXhJVPLtXCC       1\n",
      "FTAuYVNoYYxgvKMpKSLW       1\n",
      "vNNYHvZtTVtJICHsjBBL       1\n",
      "JcVHXwVSrnfIuOMMEkrJ       1\n",
      "SgIUDYUKnyWHVowUOqid       1\n",
      "Name: utm_source, Length: 69, dtype: int64\n",
      "utm_medium\n",
      "banner             2253\n",
      "cpc                1576\n",
      "(none)             1498\n",
      "referral           1071\n",
      "cpm                 362\n",
      "organic             325\n",
      "push                123\n",
      "email                99\n",
      "blogger_channel      36\n",
      "stories              30\n",
      "smartbanner          26\n",
      "cpa                  18\n",
      "cpv                  17\n",
      "tg                   12\n",
      "post                 11\n",
      "blogger_stories      11\n",
      "smm                   6\n",
      "clicks                5\n",
      "(not set)             4\n",
      "outlook               3\n",
      "link                  3\n",
      "app                   3\n",
      "landing               2\n",
      "medium                2\n",
      "blogger_header        2\n",
      "sms                   1\n",
      "info_text             1\n",
      "Name: utm_medium, dtype: int64\n",
      "utm_campaign\n",
      "LTuZkdKfxRGVceoWkVyg    2585\n",
      "LEoPHuyFvzoNfnzGgfcd    1412\n",
      "gecBYcKZCPMcVYdSSzKP     620\n",
      "FTjNLDyTrXaWYgZymFkV     361\n",
      "sbJRYgVfvcnqKJNDDYIr      86\n",
      "                        ... \n",
      "DBLWVjTjVZuzWYWTaDfZ       1\n",
      "yCnTwlCLkqZHwAglrEll       1\n",
      "BKeImrJuRDZcHiSSTdzm       1\n",
      "fDLlAcSmythWSCVMvqvL       1\n",
      "KGpIIoFhRfLgffkknBkK       1\n",
      "Name: utm_campaign, Length: 160, dtype: int64\n",
      "utm_adcontent\n",
      "JNHcPlZPxEMWDnRiyoBf    4736\n",
      "Other                   1423\n",
      "vCIpmpaGBnIQhyYNkXqp     713\n",
      "xhoenQgDQsgfEPYNPwKO     157\n",
      "PkybGvWbaqORmxjNunqZ     144\n",
      "                        ... \n",
      "LrfKeexYNjGjsqQVSCdi       1\n",
      "htRZUQDANvNrHaxZjsjz       1\n",
      "ghufNFaaSqCETrIZcgal       1\n",
      "YGYMDHtQgUvxgMZvXaZM       1\n",
      "lXYxbSFluucyYXDQeIHX       1\n",
      "Name: utm_adcontent, Length: 63, dtype: int64\n",
      "device_category\n",
      "mobile     5596\n",
      "desktop    1837\n",
      "tablet       67\n",
      "Name: device_category, dtype: int64\n",
      "device_brand\n",
      "Apple                     2212\n",
      "some_unimportant_brand    1912\n",
      "Samsung                   1331\n",
      "Xiaomi                     985\n",
      "Huawei                     664\n",
      "Realme                      57\n",
      "OPPO                        48\n",
      "Vivo                        38\n",
      "OnePlus                     34\n",
      "Asus                        29\n",
      "Nokia                       23\n",
      "Sony                        21\n",
      "Google                      20\n",
      "ZTE                         20\n",
      "Lenovo                      16\n",
      "Blackview                   10\n",
      "Motorola                    10\n",
      "Meizu                        9\n",
      "Tecno                        7\n",
      "BQ                           6\n",
      "LG                           6\n",
      "DOOGEE                       6\n",
      "Alcatel                      4\n",
      "Umidigi                      4\n",
      "HTC                          3\n",
      "Vsmart                       3\n",
      "AGM                          3\n",
      "TP-Link                      2\n",
      "BlackBerry                   2\n",
      "Oukitel                      2\n",
      "LeEco                        2\n",
      "itel                         2\n",
      "Haier                        1\n",
      "Highscreen                   1\n",
      "Leagoo                       1\n",
      "Mozilla                      1\n",
      "LeTV                         1\n",
      "Ulefone                      1\n",
      "Mito                         1\n",
      "Condor                       1\n",
      "MXQ                          1\n",
      "Name: device_brand, dtype: int64\n",
      "device_screen_resolution\n",
      "370944     687\n",
      "2073600    582\n",
      "304500     499\n",
      "334443     418\n",
      "376980     351\n",
      "          ... \n",
      "694375       1\n",
      "1639680      1\n",
      "265680       1\n",
      "268799       1\n",
      "1445906      1\n",
      "Name: device_screen_resolution, Length: 213, dtype: int64\n",
      "device_browser\n",
      "Chrome              4032\n",
      "Safari              2036\n",
      "YaBrowser            641\n",
      "Android Webview      216\n",
      "Safari (in-app)      204\n",
      "Samsung Internet     119\n",
      "Firefox               95\n",
      "Edge                  94\n",
      "Opera                 60\n",
      "UC Browser             2\n",
      "Android Runtime        1\n",
      "Name: device_browser, dtype: int64\n",
      "geo_country\n",
      "0.9810    7330\n",
      "0.0001      31\n",
      "0.0035      29\n",
      "0.0009      22\n",
      "0.0004      20\n",
      "0.0012      17\n",
      "0.0014      13\n",
      "0.0003       9\n",
      "0.0002       8\n",
      "0.0010       7\n",
      "0.0007       7\n",
      "0.0006       6\n",
      "0.0005       1\n",
      "Name: geo_country, dtype: int64\n",
      "geo_city\n",
      "Moscow                   3532\n",
      "Saint Petersburg         1017\n",
      "some_unimportant_city     810\n",
      "Krasnodar                 164\n",
      "Kazan                     154\n",
      "                         ... \n",
      "Tomsk                       5\n",
      "Kirov                       5\n",
      "Astrakhan                   5\n",
      "Ivanovo                     4\n",
      "Penza                       4\n",
      "Name: geo_city, Length: 80, dtype: int64\n",
      "camp_succ_rate\n",
      "0.00731    2585\n",
      "0.00577    1412\n",
      "0.00000    1158\n",
      "0.00845     620\n",
      "0.00612     361\n",
      "           ... \n",
      "0.01367       1\n",
      "0.00451       1\n",
      "0.00187       1\n",
      "0.00587       1\n",
      "0.00499       1\n",
      "Name: camp_succ_rate, Length: 147, dtype: int64\n",
      "11\n",
      " - \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func v2 start\n",
      "resolution_func v2 end\n",
      "-\n",
      "country v2  start\n",
      "country v2 end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand v 2 start\n",
      "device_brand v 2 end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['utm_source', 'utm_medium', 'utm_campaign', 'utm_adcontent',\n",
      "       'device_category', 'device_brand', 'device_screen_resolution',\n",
      "       'device_browser', 'geo_country', 'geo_city', 'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "utm_source\n",
      "ZpYIoDJMcFzVoPFsHGJL    830\n",
      "fDLlAcSmythWSCVMvqvL    518\n",
      "kjsLglQLzykiRbcDiGcD    298\n",
      "bByPQxmDaMXgpHeypKSM    240\n",
      "BHcvLfOaCWvWTykYqHVe    195\n",
      "MvfHsxITijuriZxsqZqt     92\n",
      "aXQzDWsJuGXeBXexNHjc     75\n",
      "QxAxdyPLuQMEcrdZWdWb     66\n",
      "jaSOmLICuBzCFqHfBdRg     31\n",
      "RmEBuqrriAfAVsLQQmhk     23\n",
      "hTjLvqNxGggkGnxSCaTm     15\n",
      "ISrKoXQCxqqYvAZICvjs     13\n",
      "vFcAhRxLfOWKhvxjELkx     12\n",
      "nSReTmyFtbSjlPrTKoaX      7\n",
      "oZCzWSykfixnjMPDNjSU      7\n",
      "fgymSoTvjKPEgaIJqsiH      7\n",
      "IZEXUFLARCUMynmHNBGo      6\n",
      "gVRrcxiDQubJiljoTbGm      5\n",
      "GpAkIXsclxDGyILfNlrR      4\n",
      "KgicpPxiEQfzPlPwQZJq      4\n",
      "iNFgfQPqHPBuvGCYtrQE      4\n",
      "BKeImrJuRDZcHiSSTdzm      3\n",
      "nrKihqcWGIzDsOqljdAv      3\n",
      "eLzNJHzPelJpEyBwMrKo      3\n",
      "PlbkrSYoHuZBWfYjYnfw      3\n",
      "YlsczTIyBSwTLNtuDkCd      3\n",
      "geDcueAOghDzHkGMmdOq      2\n",
      "TxKUcPpthBDPieTGmVhx      2\n",
      "oCqKpnSZJeYOVZTgTmKR      2\n",
      "qVXuCoVQtPxcUkAXiXBa      2\n",
      "eimRuUrNhZLAYcwRrNXu      2\n",
      "WEXkMlsnJodrzBgKJBpG      2\n",
      "DnEUulZAecfGPvdtZBYS      2\n",
      "XiUifkjKLLnomcDRhswp      2\n",
      "LIWKeifdTCbuNeniIUqm      2\n",
      "other                     1\n",
      "dyicZQGoeASogoSafjEh      1\n",
      "nmfptFmSirEqNzAzqbXA      1\n",
      "TTtiRKFZIaQpIWggfCoF      1\n",
      "klTrhUaShgnjIbaPmqjc      1\n",
      "HFaOtpcChAlcMuxEAlpu      1\n",
      "HbolMJUevblAbkHClEQa      1\n",
      "NTQAiqAhSTbkRRmxVKoQ      1\n",
      "PKriXrefSFPLBYtCRGSE      1\n",
      "ghoaGAksqhKomdFrxgyJ      1\n",
      "YpBKcihLLfFjWuxOLfvW      1\n",
      "QzPMrfYhYSLYYPtPaBxI      1\n",
      "XzfzEBYZWgSDtJNXOadn      1\n",
      "azajeHUvPOKkHBvWFbjz      1\n",
      "zwpKjjsMoRVCdipntaHt      1\n",
      "Name: utm_source, dtype: int64\n",
      "utm_medium\n",
      "banner             790\n",
      "(none)             518\n",
      "cpc                498\n",
      "referral           346\n",
      "cpm                107\n",
      "organic            100\n",
      "push                38\n",
      "email               31\n",
      "blogger_channel     11\n",
      "stories             11\n",
      "smartbanner         10\n",
      "smm                  7\n",
      "cpv                  5\n",
      "blogger_stories      5\n",
      "cpa                  5\n",
      "tg                   4\n",
      "outlook              3\n",
      "post                 2\n",
      "clicks               2\n",
      "app                  2\n",
      "link                 2\n",
      "(not set)            1\n",
      "CPM                  1\n",
      "landing              1\n",
      "Name: utm_medium, dtype: int64\n",
      "utm_campaign\n",
      "LTuZkdKfxRGVceoWkVyg    883\n",
      "LEoPHuyFvzoNfnzGgfcd    509\n",
      "gecBYcKZCPMcVYdSSzKP    200\n",
      "FTjNLDyTrXaWYgZymFkV    114\n",
      "sbJRYgVfvcnqKJNDDYIr     28\n",
      "                       ... \n",
      "NLWjXuYiXlKrFJfSWfKt      1\n",
      "WZxCpdfLzrgIfGUqxGpE      1\n",
      "JdLDXLLzKXZlxBJrDTXh      1\n",
      "qpUkxmFZPYAfFrViyYab      1\n",
      "yxtFdhyijaALzWWYtzHE      1\n",
      "Name: utm_campaign, Length: 106, dtype: int64\n",
      "utm_adcontent\n",
      "JNHcPlZPxEMWDnRiyoBf    1618\n",
      "Other                    419\n",
      "vCIpmpaGBnIQhyYNkXqp     265\n",
      "xhoenQgDQsgfEPYNPwKO      47\n",
      "PkybGvWbaqORmxjNunqZ      46\n",
      "LLfCasrxQzJIyuldcuWy      13\n",
      "SOkCdPxfUcZUzzOdgGES      13\n",
      "nNqUcgFgcqQbTVSvgaHr       7\n",
      "yYdBRbPmBMUZHXwqGxNx       7\n",
      "XSkXBCPfnJjvxbfeewtd       6\n",
      "fxKLUhFToKQtGIyvjZXQ       3\n",
      "SAVVWaMghGnnvPOqMOIt       3\n",
      "dUuXlWzvmhDSyclWRhNP       3\n",
      "AdeErYgVTbRcAWtHrMHq       3\n",
      "sYzBROYhjSDbFZCpzGyf       3\n",
      "TuyPWsGQruPMpKvRxeBF       3\n",
      "XKsYZiUFcdkUXQpoLKyS       2\n",
      "LcGIUNPUAmXtQJaDfFBR       2\n",
      "qhEmhjPXvwgEHdBikgEQ       2\n",
      "LxluDbGsLnaemhTtGuvB       2\n",
      "FkiRXDLOWtzVfvhEkhNo       2\n",
      "ZKlsrASsGaoEHfwkdKjL       2\n",
      "WAeycgIqKXoOMXPzDUDX       2\n",
      "eEkLatVAYTkibdzPIyDi       2\n",
      "EteMoEECGsaJeMnuvAZD       2\n",
      "JJRVNKFvKSInZxhrcjHK       1\n",
      "FXpnPQVvfePoCAKRMpRV       1\n",
      "uovjRGXgBwVqoPWweONb       1\n",
      "GpVVpqYEqQSmYZrOPfSZ       1\n",
      "WYLajZgbUhGimwBKDZUH       1\n",
      "EsbpyHMkFkavykEeYhch       1\n",
      "xnyHaukLtAvgViiZSyBC       1\n",
      "eOWmIGTKVDPewucDtZXG       1\n",
      "ZbhjTfTaZOUpHAHHpvsP       1\n",
      "WyligyAVjsWBDjaYTidY       1\n",
      "ptYJgYxtYQLiZcgpjmXe       1\n",
      "nsxJgFVqhmchGMaUusie       1\n",
      "aYAcKhelKzYpXrRYknSP       1\n",
      "NOBKLgtuvqYWkXQHeYWM       1\n",
      "GaKENkrnDlLzOgREieaI       1\n",
      "lXYxbSFluucyYXDQeIHX       1\n",
      "HhkEQvDgekUQWMWUpfqW       1\n",
      "guyNoEvzgofQvvwExGOq       1\n",
      "ZIMljraejFHmkkHvoNxk       1\n",
      "DZYjhfIUfdqhfuTNUmjn       1\n",
      "NhvfEqcSTGEZKxxvUZlj       1\n",
      "BdalQBXFeDGQTswaQtOL       1\n",
      "LBoFGHDbSeBOgvTnNlmS       1\n",
      "Name: utm_adcontent, dtype: int64\n",
      "device_category\n",
      "mobile     1902\n",
      "desktop     574\n",
      "tablet       24\n",
      "Name: device_category, dtype: int64\n",
      "device_brand\n",
      "Apple                     749\n",
      "some_unimportant_brand    607\n",
      "Samsung                   444\n",
      "Xiaomi                    338\n",
      "Huawei                    217\n",
      "Realme                     32\n",
      "OPPO                       21\n",
      "Nokia                      13\n",
      "Vivo                       12\n",
      "Google                     10\n",
      "OnePlus                     8\n",
      "Sony                        7\n",
      "Blackview                   6\n",
      "ZTE                         5\n",
      "Asus                        5\n",
      "Meizu                       4\n",
      "Tecno                       3\n",
      "Motorola                    3\n",
      "LG                          3\n",
      "DOOGEE                      3\n",
      "itel                        2\n",
      "Fly                         1\n",
      "Coolpad                     1\n",
      "HTC                         1\n",
      "Oukitel                     1\n",
      "Lenovo                      1\n",
      "BQ                          1\n",
      "AGM                         1\n",
      "Umidigi                     1\n",
      "Name: device_brand, dtype: int64\n",
      "device_screen_resolution\n",
      "370944     229\n",
      "2073600    176\n",
      "334443     166\n",
      "304500     161\n",
      "250125     135\n",
      "          ... \n",
      "319488       1\n",
      "4147200      1\n",
      "277920       1\n",
      "407968       1\n",
      "329752       1\n",
      "Name: device_screen_resolution, Length: 146, dtype: int64\n",
      "device_browser\n",
      "Chrome              1357\n",
      "Safari               677\n",
      "YaBrowser            198\n",
      "Android Webview       74\n",
      "Safari (in-app)       69\n",
      "Samsung Internet      40\n",
      "Opera                 33\n",
      "Firefox               27\n",
      "Edge                  25\n",
      "Name: device_browser, dtype: int64\n",
      "geo_country\n",
      "0.9810    2434\n",
      "0.0035      13\n",
      "0.0006      11\n",
      "0.0001       9\n",
      "0.0009       8\n",
      "0.0004       6\n",
      "0.0012       5\n",
      "0.0014       4\n",
      "0.0005       3\n",
      "0.0003       3\n",
      "0.0007       2\n",
      "0.0002       1\n",
      "0.0010       1\n",
      "Name: geo_country, dtype: int64\n",
      "geo_city\n",
      "Moscow                   1128\n",
      "Saint Petersburg          343\n",
      "some_unimportant_city     288\n",
      "Kazan                      56\n",
      "Krasnodar                  54\n",
      "                         ... \n",
      "Shchyolkovo                 2\n",
      "Chita                       2\n",
      "Ramenskoye                  1\n",
      "Kursk                       1\n",
      "Reutov                      1\n",
      "Name: geo_city, Length: 77, dtype: int64\n",
      "camp_succ_rate\n",
      "0.00731    883\n",
      "0.00577    509\n",
      "0.00000    352\n",
      "0.00845    200\n",
      "0.00612    114\n",
      "          ... \n",
      "0.04296      1\n",
      "0.00306      1\n",
      "0.00084      1\n",
      "0.00800      1\n",
      "0.00050      1\n",
      "Name: camp_succ_rate, Length: 100, dtype: int64\n",
      "11\n",
      " - \n",
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func v2 start\n",
      "resolution_func v2 end\n",
      "-\n",
      "country v2  start\n",
      "country v2 end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand v 2 start\n",
      "device_brand v 2 end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['utm_source', 'utm_medium', 'utm_campaign', 'utm_adcontent',\n",
      "       'device_category', 'device_brand', 'device_screen_resolution',\n",
      "       'device_browser', 'geo_country', 'geo_city', 'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "utm_source\n",
      "ZpYIoDJMcFzVoPFsHGJL    2444\n",
      "fDLlAcSmythWSCVMvqvL    1512\n",
      "kjsLglQLzykiRbcDiGcD     912\n",
      "bByPQxmDaMXgpHeypKSM     768\n",
      "BHcvLfOaCWvWTykYqHVe     618\n",
      "                        ... \n",
      "other                      1\n",
      "TTtiRKFZIaQpIWggfCoF       1\n",
      "PKriXrefSFPLBYtCRGSE       1\n",
      "azajeHUvPOKkHBvWFbjz       1\n",
      "SgIUDYUKnyWHVowUOqid       1\n",
      "Name: utm_source, Length: 67, dtype: int64\n",
      "utm_medium\n",
      "banner             2304\n",
      "cpc                1554\n",
      "(none)             1512\n",
      "referral           1069\n",
      "cpm                 332\n",
      "organic             304\n",
      "push                126\n",
      "email               101\n",
      "blogger_channel      35\n",
      "smartbanner          31\n",
      "stories              30\n",
      "tg                   14\n",
      "cpa                  14\n",
      "cpv                  12\n",
      "blogger_stories      11\n",
      "post                 10\n",
      "smm                  10\n",
      "clicks                6\n",
      "outlook               6\n",
      "link                  5\n",
      "(not set)             4\n",
      "landing               3\n",
      "app                   3\n",
      "sms                   1\n",
      "CPM                   1\n",
      "blogger_header        1\n",
      "info_text             1\n",
      "Name: utm_medium, dtype: int64\n",
      "utm_campaign\n",
      "LTuZkdKfxRGVceoWkVyg    2577\n",
      "LEoPHuyFvzoNfnzGgfcd    1471\n",
      "gecBYcKZCPMcVYdSSzKP     618\n",
      "FTjNLDyTrXaWYgZymFkV     341\n",
      "sbJRYgVfvcnqKJNDDYIr      89\n",
      "                        ... \n",
      "PuSsXRwSpZeHuyXoHqhm       1\n",
      "VzoFtfHotWfgMqOvhhpk       1\n",
      "quxdQHtdlpFZfBZSiXFZ       1\n",
      "UrZcnCerRbiVophgfqbk       1\n",
      "KGpIIoFhRfLgffkknBkK       1\n",
      "Name: utm_campaign, Length: 152, dtype: int64\n",
      "utm_adcontent\n",
      "JNHcPlZPxEMWDnRiyoBf    4757\n",
      "Other                   1375\n",
      "vCIpmpaGBnIQhyYNkXqp     751\n",
      "xhoenQgDQsgfEPYNPwKO     146\n",
      "PkybGvWbaqORmxjNunqZ     134\n",
      "                        ... \n",
      "htRZUQDANvNrHaxZjsjz       1\n",
      "OJiWyBKOyDITzXCZRSMH       1\n",
      "NNFDaOyxNbRfjYvClLnM       1\n",
      "LrfKeexYNjGjsqQVSCdi       1\n",
      "IwBedorwDIzxDRIZUTNo       1\n",
      "Name: utm_adcontent, Length: 64, dtype: int64\n",
      "device_category\n",
      "mobile     5626\n",
      "desktop    1804\n",
      "tablet       70\n",
      "Name: device_category, dtype: int64\n",
      "device_brand\n",
      "Apple                     2206\n",
      "some_unimportant_brand    1886\n",
      "Samsung                   1327\n",
      "Xiaomi                    1001\n",
      "Huawei                     665\n",
      "Realme                      75\n",
      "OPPO                        54\n",
      "Vivo                        42\n",
      "OnePlus                     31\n",
      "Nokia                       28\n",
      "Sony                        25\n",
      "Google                      23\n",
      "Asus                        22\n",
      "ZTE                         15\n",
      "Blackview                   11\n",
      "Meizu                       11\n",
      "Motorola                    10\n",
      "Lenovo                      10\n",
      "Tecno                        9\n",
      "LG                           8\n",
      "DOOGEE                       7\n",
      "BQ                           5\n",
      "Umidigi                      5\n",
      "Oukitel                      3\n",
      "HTC                          3\n",
      "Alcatel                      3\n",
      "AGM                          2\n",
      "itel                         2\n",
      "BlackBerry                   2\n",
      "TP-Link                      2\n",
      "Vsmart                       1\n",
      "LeEco                        1\n",
      "Leagoo                       1\n",
      "Coolpad                      1\n",
      "Fly                          1\n",
      "Condor                       1\n",
      "MXQ                          1\n",
      "Name: device_brand, dtype: int64\n",
      "device_screen_resolution\n",
      "370944     678\n",
      "2073600    573\n",
      "304500     485\n",
      "334443     455\n",
      "250125     371\n",
      "          ... \n",
      "1755404      1\n",
      "641229       1\n",
      "389425       1\n",
      "243930       1\n",
      "1445906      1\n",
      "Name: device_screen_resolution, Length: 222, dtype: int64\n",
      "device_browser\n",
      "Chrome              4050\n",
      "Safari              2028\n",
      "YaBrowser            627\n",
      "Android Webview      219\n",
      "Safari (in-app)      202\n",
      "Samsung Internet     115\n",
      "Firefox               95\n",
      "Edge                  95\n",
      "Opera                 68\n",
      "UC Browser             1\n",
      "Name: device_browser, dtype: int64\n",
      "geo_country\n",
      "0.9810    7327\n",
      "0.0035      33\n",
      "0.0001      29\n",
      "0.0009      19\n",
      "0.0012      18\n",
      "0.0004      17\n",
      "0.0006      15\n",
      "0.0014      12\n",
      "0.0003      10\n",
      "0.0002       6\n",
      "0.0007       6\n",
      "0.0010       5\n",
      "0.0005       3\n",
      "Name: geo_country, dtype: int64\n",
      "geo_city\n",
      "Moscow                   3479\n",
      "Saint Petersburg         1011\n",
      "some_unimportant_city     850\n",
      "Krasnodar                 172\n",
      "Kazan                     163\n",
      "                         ... \n",
      "Kostroma                    5\n",
      "Lyubertsy                   4\n",
      "Penza                       3\n",
      "Pushkino                    3\n",
      "Astrakhan                   2\n",
      "Name: geo_city, Length: 80, dtype: int64\n",
      "camp_succ_rate\n",
      "0.00731    2577\n",
      "0.00577    1471\n",
      "0.00000    1136\n",
      "0.00845     618\n",
      "0.00612     341\n",
      "           ... \n",
      "0.00493       1\n",
      "0.01367       1\n",
      "0.00632       1\n",
      "0.00451       1\n",
      "0.00499       1\n",
      "Name: camp_succ_rate, Length: 136, dtype: int64\n",
      "11\n",
      " - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func v2 start\n",
      "resolution_func v2 end\n",
      "-\n",
      "country v2  start\n",
      "country v2 end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand v 2 start\n",
      "device_brand v 2 end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['utm_source', 'utm_medium', 'utm_campaign', 'utm_adcontent',\n",
      "       'device_category', 'device_brand', 'device_screen_resolution',\n",
      "       'device_browser', 'geo_country', 'geo_city', 'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "utm_source\n",
      "ZpYIoDJMcFzVoPFsHGJL    770\n",
      "fDLlAcSmythWSCVMvqvL    504\n",
      "kjsLglQLzykiRbcDiGcD    336\n",
      "bByPQxmDaMXgpHeypKSM    249\n",
      "BHcvLfOaCWvWTykYqHVe    190\n",
      "MvfHsxITijuriZxsqZqt    116\n",
      "QxAxdyPLuQMEcrdZWdWb     74\n",
      "aXQzDWsJuGXeBXexNHjc     73\n",
      "RmEBuqrriAfAVsLQQmhk     30\n",
      "jaSOmLICuBzCFqHfBdRg     29\n",
      "vFcAhRxLfOWKhvxjELkx     19\n",
      "hTjLvqNxGggkGnxSCaTm     13\n",
      "ISrKoXQCxqqYvAZICvjs     11\n",
      "fgymSoTvjKPEgaIJqsiH      8\n",
      "IZEXUFLARCUMynmHNBGo      8\n",
      "nSReTmyFtbSjlPrTKoaX      7\n",
      "iNFgfQPqHPBuvGCYtrQE      7\n",
      "GpAkIXsclxDGyILfNlrR      5\n",
      "gVRrcxiDQubJiljoTbGm      5\n",
      "oZCzWSykfixnjMPDNjSU      4\n",
      "BKeImrJuRDZcHiSSTdzm      4\n",
      "geDcueAOghDzHkGMmdOq      4\n",
      "PlbkrSYoHuZBWfYjYnfw      3\n",
      "nmfptFmSirEqNzAzqbXA      3\n",
      "eLzNJHzPelJpEyBwMrKo      2\n",
      "SzZERoLMmrEUEhDaYcyN      2\n",
      "DnEUulZAecfGPvdtZBYS      2\n",
      "klTrhUaShgnjIbaPmqjc      2\n",
      "gLXXuZYbFVYlDWhMmZiU      2\n",
      "dyicZQGoeASogoSafjEh      1\n",
      "XiUifkjKLLnomcDRhswp      1\n",
      "gDBGzjFKYabGgSPZvrDH      1\n",
      "MQvSjpHGoGjbcBjfnLLm      1\n",
      "RxecHElWobBxIeAkqFXV      1\n",
      "faqsogjxCvbseFqupueU      1\n",
      "WEXkMlsnJodrzBgKJBpG      1\n",
      "nrKihqcWGIzDsOqljdAv      1\n",
      "qVXuCoVQtPxcUkAXiXBa      1\n",
      "EvhrtRzIJnQYHziPiLzV      1\n",
      "ZHCJROlbqnkXTqIuVxnm      1\n",
      "NwLFDlNWnYxuLZEAZppl      1\n",
      "RVKHNCFOYpjJjjAtwCgE      1\n",
      "eimRuUrNhZLAYcwRrNXu      1\n",
      "fJCYsujgSxIHFbOmgDdN      1\n",
      "azajeHUvPOKkHBvWFbjz      1\n",
      "zwpKjjsMoRVCdipntaHt      1\n",
      "TTtiRKFZIaQpIWggfCoF      1\n",
      "Name: utm_source, dtype: int64\n",
      "utm_medium\n",
      "banner             739\n",
      "cpc                520\n",
      "(none)             504\n",
      "referral           348\n",
      "cpm                137\n",
      "organic            121\n",
      "push                35\n",
      "email               29\n",
      "blogger_channel     12\n",
      "stories             11\n",
      "cpv                 10\n",
      "cpa                  9\n",
      "smartbanner          5\n",
      "blogger_stories      5\n",
      "smm                  3\n",
      "post                 3\n",
      "tg                   2\n",
      "medium               2\n",
      "app                  2\n",
      "(not set)            1\n",
      "blogger_header       1\n",
      "clicks               1\n",
      "Name: utm_medium, dtype: int64\n",
      "utm_campaign\n",
      "LTuZkdKfxRGVceoWkVyg    891\n",
      "LEoPHuyFvzoNfnzGgfcd    450\n",
      "gecBYcKZCPMcVYdSSzKP    202\n",
      "FTjNLDyTrXaWYgZymFkV    134\n",
      "SgIUDYUKnyWHVowUOqid     25\n",
      "                       ... \n",
      "WZxCpdfLzrgIfGUqxGpE      1\n",
      "pPhTYiQubZFNCSnIbPJs      1\n",
      "fDLlAcSmythWSCVMvqvL      1\n",
      "wWtqUernqIfFLJdJysKt      1\n",
      "YDaQaUATKHxvsCBNfjwj      1\n",
      "Name: utm_campaign, Length: 109, dtype: int64\n",
      "utm_adcontent\n",
      "JNHcPlZPxEMWDnRiyoBf    1597\n",
      "Other                    467\n",
      "vCIpmpaGBnIQhyYNkXqp     227\n",
      "xhoenQgDQsgfEPYNPwKO      58\n",
      "PkybGvWbaqORmxjNunqZ      56\n",
      "LLfCasrxQzJIyuldcuWy      17\n",
      "yYdBRbPmBMUZHXwqGxNx       8\n",
      "nNqUcgFgcqQbTVSvgaHr       7\n",
      "XSkXBCPfnJjvxbfeewtd       6\n",
      "SOkCdPxfUcZUzzOdgGES       6\n",
      "guyNoEvzgofQvvwExGOq       4\n",
      "WYLajZgbUhGimwBKDZUH       4\n",
      "xnyHaukLtAvgViiZSyBC       3\n",
      "EteMoEECGsaJeMnuvAZD       3\n",
      "TuyPWsGQruPMpKvRxeBF       2\n",
      "SitoRrEOjouuWzzGooUa       2\n",
      "DZYjhfIUfdqhfuTNUmjn       2\n",
      "FkiRXDLOWtzVfvhEkhNo       2\n",
      "qHPyQVqWZtIwxZvzhkMv       2\n",
      "BdalQBXFeDGQTswaQtOL       2\n",
      "NnaLweGiAhdtkuktFipk       2\n",
      "WAeycgIqKXoOMXPzDUDX       2\n",
      "AdeErYgVTbRcAWtHrMHq       2\n",
      "fxKLUhFToKQtGIyvjZXQ       1\n",
      "GpVVpqYEqQSmYZrOPfSZ       1\n",
      "ZIMljraejFHmkkHvoNxk       1\n",
      "UxrnyMlRBSOhOjytXnMG       1\n",
      "ZKlsrASsGaoEHfwkdKjL       1\n",
      "bIMfYqjEamEBPlExMjrZ       1\n",
      "ptYJgYxtYQLiZcgpjmXe       1\n",
      "HhkEQvDgekUQWMWUpfqW       1\n",
      "aYAcKhelKzYpXrRYknSP       1\n",
      "ESUnXCsdWADovskBLvBO       1\n",
      "DaehHXyBdjcdSRnPiAQn       1\n",
      "LBoFGHDbSeBOgvTnNlmS       1\n",
      "LxluDbGsLnaemhTtGuvB       1\n",
      "nsxJgFVqhmchGMaUusie       1\n",
      "ghufNFaaSqCETrIZcgal       1\n",
      "eEkLatVAYTkibdzPIyDi       1\n",
      "AIONnJpjXjEluFHEjOyg       1\n",
      "sYzBROYhjSDbFZCpzGyf       1\n",
      "eOWmIGTKVDPewucDtZXG       1\n",
      "Name: utm_adcontent, dtype: int64\n",
      "device_category\n",
      "mobile     1872\n",
      "desktop     607\n",
      "tablet       21\n",
      "Name: device_category, dtype: int64\n",
      "device_brand\n",
      "Apple                     755\n",
      "some_unimportant_brand    633\n",
      "Samsung                   448\n",
      "Xiaomi                    322\n",
      "Huawei                    216\n",
      "OPPO                       15\n",
      "Realme                     14\n",
      "Asus                       12\n",
      "OnePlus                    11\n",
      "ZTE                        10\n",
      "Vivo                        8\n",
      "Nokia                       8\n",
      "Google                      7\n",
      "Lenovo                      7\n",
      "Blackview                   5\n",
      "Sony                        3\n",
      "Motorola                    3\n",
      "Meizu                       2\n",
      "AGM                         2\n",
      "DOOGEE                      2\n",
      "itel                        2\n",
      "BQ                          2\n",
      "Vsmart                      2\n",
      "Mozilla                     1\n",
      "Tecno                       1\n",
      "LeEco                       1\n",
      "LG                          1\n",
      "Ulefone                     1\n",
      "Haier                       1\n",
      "Highscreen                  1\n",
      "HTC                         1\n",
      "Mito                        1\n",
      "Alcatel                     1\n",
      "LeTV                        1\n",
      "Name: device_brand, dtype: int64\n",
      "device_screen_resolution\n",
      "370944     238\n",
      "2073600    185\n",
      "304500     175\n",
      "334443     129\n",
      "280800     113\n",
      "          ... \n",
      "759278       1\n",
      "2822400      1\n",
      "1067200      1\n",
      "1638720      1\n",
      "415038       1\n",
      "Name: device_screen_resolution, Length: 130, dtype: int64\n",
      "device_browser\n",
      "Chrome              1339\n",
      "Safari               685\n",
      "YaBrowser            212\n",
      "Android Webview       71\n",
      "Safari (in-app)       71\n",
      "Samsung Internet      44\n",
      "Firefox               27\n",
      "Opera                 25\n",
      "Edge                  24\n",
      "UC Browser             1\n",
      "Android Runtime        1\n",
      "Name: device_browser, dtype: int64\n",
      "geo_country\n",
      "0.9810    2437\n",
      "0.0009      11\n",
      "0.0001      11\n",
      "0.0004       9\n",
      "0.0035       9\n",
      "0.0014       5\n",
      "0.0012       4\n",
      "0.0007       3\n",
      "0.0010       3\n",
      "0.0002       3\n",
      "0.0003       2\n",
      "0.0006       2\n",
      "0.0005       1\n",
      "Name: geo_country, dtype: int64\n",
      "geo_city\n",
      "Moscow                   1181\n",
      "Saint Petersburg          349\n",
      "some_unimportant_city     248\n",
      "Kazan                      47\n",
      "Krasnodar                  46\n",
      "                         ... \n",
      "Cheboksary                  1\n",
      "Ramenskoye                  1\n",
      "Tomsk                       1\n",
      "Ivanovo                     1\n",
      "Oryol                       1\n",
      "Name: geo_city, Length: 80, dtype: int64\n",
      "camp_succ_rate\n",
      "0.00731    891\n",
      "0.00577    450\n",
      "0.00000    374\n",
      "0.00845    202\n",
      "0.00612    134\n",
      "          ... \n",
      "0.01762      1\n",
      "0.00800      1\n",
      "0.00187      1\n",
      "0.00696      1\n",
      "0.00292      1\n",
      "Name: camp_succ_rate, Length: 107, dtype: int64\n",
      "11\n",
      " - \n",
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func v2 start\n",
      "resolution_func v2 end\n",
      "-\n",
      "country v2  start\n",
      "country v2 end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand v 2 start\n",
      "device_brand v 2 end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['utm_source', 'utm_medium', 'utm_campaign', 'utm_adcontent',\n",
      "       'device_category', 'device_brand', 'device_screen_resolution',\n",
      "       'device_browser', 'geo_country', 'geo_city', 'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "utm_source\n",
      "ZpYIoDJMcFzVoPFsHGJL    2407\n",
      "fDLlAcSmythWSCVMvqvL    1540\n",
      "kjsLglQLzykiRbcDiGcD     922\n",
      "bByPQxmDaMXgpHeypKSM     734\n",
      "BHcvLfOaCWvWTykYqHVe     599\n",
      "                        ... \n",
      "YpBKcihLLfFjWuxOLfvW       1\n",
      "XzfzEBYZWgSDtJNXOadn       1\n",
      "RVKHNCFOYpjJjjAtwCgE       1\n",
      "fJCYsujgSxIHFbOmgDdN       1\n",
      "faqsogjxCvbseFqupueU       1\n",
      "Name: utm_source, Length: 69, dtype: int64\n",
      "utm_medium\n",
      "banner             2291\n",
      "(none)             1540\n",
      "cpc                1535\n",
      "referral           1037\n",
      "cpm                 352\n",
      "organic             323\n",
      "push                111\n",
      "email               102\n",
      "blogger_channel      35\n",
      "stories              34\n",
      "smartbanner          27\n",
      "cpa                  20\n",
      "cpv                  19\n",
      "blogger_stories      13\n",
      "smm                  11\n",
      "tg                   11\n",
      "post                  9\n",
      "clicks                6\n",
      "outlook               5\n",
      "app                   4\n",
      "link                  4\n",
      "(not set)             3\n",
      "landing               2\n",
      "medium                2\n",
      "CPM                   1\n",
      "sms                   1\n",
      "blogger_header        1\n",
      "info_text             1\n",
      "Name: utm_medium, dtype: int64\n",
      "utm_campaign\n",
      "LTuZkdKfxRGVceoWkVyg    2620\n",
      "LEoPHuyFvzoNfnzGgfcd    1445\n",
      "gecBYcKZCPMcVYdSSzKP     614\n",
      "FTjNLDyTrXaWYgZymFkV     356\n",
      "sbJRYgVfvcnqKJNDDYIr      76\n",
      "                        ... \n",
      "aCaBoYaQJPVffhjBQnut       1\n",
      "wWzYQhgKgKSglyMXtXFv       1\n",
      "TmLcOgercnkJQrPmRxsU       1\n",
      "CtcATIzjbQqVOMPZfiQY       1\n",
      "YDaQaUATKHxvsCBNfjwj       1\n",
      "Name: utm_campaign, Length: 161, dtype: int64\n",
      "utm_adcontent\n",
      "JNHcPlZPxEMWDnRiyoBf    4781\n",
      "Other                   1355\n",
      "vCIpmpaGBnIQhyYNkXqp     742\n",
      "xhoenQgDQsgfEPYNPwKO     156\n",
      "PkybGvWbaqORmxjNunqZ     141\n",
      "                        ... \n",
      "NNFDaOyxNbRfjYvClLnM       1\n",
      "QEPLWgIvqPEGXcwBrsFw       1\n",
      "vilbbyUvEWbiJvxXpaNN       1\n",
      "ghufNFaaSqCETrIZcgal       1\n",
      "UxrnyMlRBSOhOjytXnMG       1\n",
      "Name: utm_adcontent, Length: 66, dtype: int64\n",
      "device_category\n",
      "mobile     5644\n",
      "desktop    1797\n",
      "tablet       59\n",
      "Name: device_category, dtype: int64\n",
      "device_brand\n",
      "Apple                     2237\n",
      "some_unimportant_brand    1884\n",
      "Samsung                   1310\n",
      "Xiaomi                    1012\n",
      "Huawei                     653\n",
      "Realme                      66\n",
      "OPPO                        56\n",
      "Vivo                        35\n",
      "OnePlus                     32\n",
      "Nokia                       30\n",
      "Google                      24\n",
      "Asus                        23\n",
      "Sony                        19\n",
      "ZTE                         17\n",
      "Blackview                   15\n",
      "Motorola                    10\n",
      "Lenovo                       9\n",
      "Meizu                        9\n",
      "Tecno                        8\n",
      "LG                           8\n",
      "DOOGEE                       7\n",
      "BQ                           5\n",
      "HTC                          4\n",
      "Alcatel                      4\n",
      "itel                         4\n",
      "Vsmart                       3\n",
      "AGM                          3\n",
      "Umidigi                      2\n",
      "Oukitel                      2\n",
      "Coolpad                      1\n",
      "Mozilla                      1\n",
      "LeEco                        1\n",
      "Fly                          1\n",
      "Ulefone                      1\n",
      "Haier                        1\n",
      "Highscreen                   1\n",
      "Mito                         1\n",
      "LeTV                         1\n",
      "Name: device_brand, dtype: int64\n",
      "device_screen_resolution\n",
      "370944     691\n",
      "2073600    568\n",
      "304500     503\n",
      "334443     453\n",
      "250125     360\n",
      "          ... \n",
      "251168       1\n",
      "339768       1\n",
      "2146560      1\n",
      "404352       1\n",
      "415038       1\n",
      "Name: device_screen_resolution, Length: 215, dtype: int64\n",
      "device_browser\n",
      "Chrome              4020\n",
      "Safari              2044\n",
      "YaBrowser            639\n",
      "Android Webview      223\n",
      "Safari (in-app)      206\n",
      "Samsung Internet     120\n",
      "Firefox               84\n",
      "Edge                  83\n",
      "Opera                 79\n",
      "UC Browser             1\n",
      "Android Runtime        1\n",
      "Name: device_browser, dtype: int64\n",
      "geo_country\n",
      "0.9810    7319\n",
      "0.0001      32\n",
      "0.0035      30\n",
      "0.0009      25\n",
      "0.0004      20\n",
      "0.0012      14\n",
      "0.0006      14\n",
      "0.0014      13\n",
      "0.0003       8\n",
      "0.0002       8\n",
      "0.0007       7\n",
      "0.0010       6\n",
      "0.0005       4\n",
      "Name: geo_country, dtype: int64\n",
      "geo_city\n",
      "Moscow                   3493\n",
      "Saint Petersburg         1016\n",
      "some_unimportant_city     819\n",
      "Kazan                     162\n",
      "Krasnodar                 154\n",
      "                         ... \n",
      "Kostroma                    5\n",
      "Astrakhan                   4\n",
      "Kursk                       4\n",
      "Ramenskoye                  4\n",
      "Kolomna                     4\n",
      "Name: geo_city, Length: 80, dtype: int64\n",
      "camp_succ_rate\n",
      "0.00731    2620\n",
      "0.00577    1445\n",
      "0.00000    1107\n",
      "0.00845     614\n",
      "0.00612     356\n",
      "           ... \n",
      "0.00493       1\n",
      "0.00516       1\n",
      "0.00392       1\n",
      "0.00815       1\n",
      "0.00292       1\n",
      "Name: camp_succ_rate, Length: 147, dtype: int64\n",
      "11\n",
      " - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func v2 start\n",
      "resolution_func v2 end\n",
      "-\n",
      "country v2  start\n",
      "country v2 end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand v 2 start\n",
      "device_brand v 2 end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['utm_source', 'utm_medium', 'utm_campaign', 'utm_adcontent',\n",
      "       'device_category', 'device_brand', 'device_screen_resolution',\n",
      "       'device_browser', 'geo_country', 'geo_city', 'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "utm_source\n",
      "ZpYIoDJMcFzVoPFsHGJL    807\n",
      "fDLlAcSmythWSCVMvqvL    476\n",
      "kjsLglQLzykiRbcDiGcD    326\n",
      "bByPQxmDaMXgpHeypKSM    283\n",
      "BHcvLfOaCWvWTykYqHVe    209\n",
      "MvfHsxITijuriZxsqZqt     95\n",
      "aXQzDWsJuGXeBXexNHjc     74\n",
      "QxAxdyPLuQMEcrdZWdWb     60\n",
      "jaSOmLICuBzCFqHfBdRg     28\n",
      "RmEBuqrriAfAVsLQQmhk     28\n",
      "vFcAhRxLfOWKhvxjELkx     15\n",
      "hTjLvqNxGggkGnxSCaTm     12\n",
      "IZEXUFLARCUMynmHNBGo     10\n",
      "oZCzWSykfixnjMPDNjSU      9\n",
      "ISrKoXQCxqqYvAZICvjs      9\n",
      "fgymSoTvjKPEgaIJqsiH      6\n",
      "iNFgfQPqHPBuvGCYtrQE      5\n",
      "nSReTmyFtbSjlPrTKoaX      4\n",
      "eLzNJHzPelJpEyBwMrKo      4\n",
      "GpAkIXsclxDGyILfNlrR      4\n",
      "KgicpPxiEQfzPlPwQZJq      3\n",
      "PlbkrSYoHuZBWfYjYnfw      3\n",
      "TxKUcPpthBDPieTGmVhx      2\n",
      "NwLFDlNWnYxuLZEAZppl      2\n",
      "nrKihqcWGIzDsOqljdAv      2\n",
      "WEXkMlsnJodrzBgKJBpG      2\n",
      "ghoaGAksqhKomdFrxgyJ      2\n",
      "dyicZQGoeASogoSafjEh      2\n",
      "geDcueAOghDzHkGMmdOq      2\n",
      "SgIUDYUKnyWHVowUOqid      1\n",
      "SzZERoLMmrEUEhDaYcyN      1\n",
      "YlsczTIyBSwTLNtuDkCd      1\n",
      "YclHumxPxSxgzHfvCaeF      1\n",
      "BKeImrJuRDZcHiSSTdzm      1\n",
      "TkzfDRIBKntFdWkzUePd      1\n",
      "UphNUPPFIJLIZnvubKDj      1\n",
      "HFaOtpcChAlcMuxEAlpu      1\n",
      "zwpKjjsMoRVCdipntaHt      1\n",
      "gVRrcxiDQubJiljoTbGm      1\n",
      "GmILPdZyuAVJCPsUBHeN      1\n",
      "qVXuCoVQtPxcUkAXiXBa      1\n",
      "ngkgBNjlzLYBofkljaBo      1\n",
      "DnEUulZAecfGPvdtZBYS      1\n",
      "LIWKeifdTCbuNeniIUqm      1\n",
      "oCqKpnSZJeYOVZTgTmKR      1\n",
      "Name: utm_source, dtype: int64\n",
      "utm_medium\n",
      "banner             752\n",
      "cpc                539\n",
      "(none)             476\n",
      "referral           380\n",
      "cpm                117\n",
      "organic            102\n",
      "push                50\n",
      "email               28\n",
      "blogger_channel     12\n",
      "smartbanner          9\n",
      "stories              7\n",
      "tg                   5\n",
      "post                 4\n",
      "cpa                  3\n",
      "cpv                  3\n",
      "blogger_stories      3\n",
      "(not set)            2\n",
      "smm                  2\n",
      "blogger_header       1\n",
      "link                 1\n",
      "app                  1\n",
      "landing              1\n",
      "clicks               1\n",
      "outlook              1\n",
      "Name: utm_medium, dtype: int64\n",
      "utm_campaign\n",
      "LTuZkdKfxRGVceoWkVyg    848\n",
      "LEoPHuyFvzoNfnzGgfcd    476\n",
      "gecBYcKZCPMcVYdSSzKP    206\n",
      "FTjNLDyTrXaWYgZymFkV    119\n",
      "sbJRYgVfvcnqKJNDDYIr     38\n",
      "                       ... \n",
      "ydXTgkwKyFWEAJoahduP      1\n",
      "zPJpddwzkFqLMSYgtDqy      1\n",
      "XGYOaJEasWTwAKNdCGVX      1\n",
      "KUROllwAYyecYcjFOgAi      1\n",
      "KGpIIoFhRfLgffkknBkK      1\n",
      "Name: utm_campaign, Length: 103, dtype: int64\n",
      "utm_adcontent\n",
      "JNHcPlZPxEMWDnRiyoBf    1573\n",
      "Other                    487\n",
      "vCIpmpaGBnIQhyYNkXqp     236\n",
      "PkybGvWbaqORmxjNunqZ      49\n",
      "xhoenQgDQsgfEPYNPwKO      48\n",
      "LLfCasrxQzJIyuldcuWy      14\n",
      "XSkXBCPfnJjvxbfeewtd       9\n",
      "SOkCdPxfUcZUzzOdgGES       7\n",
      "yYdBRbPmBMUZHXwqGxNx       6\n",
      "dUuXlWzvmhDSyclWRhNP       5\n",
      "eEkLatVAYTkibdzPIyDi       4\n",
      "qhEmhjPXvwgEHdBikgEQ       4\n",
      "nNqUcgFgcqQbTVSvgaHr       4\n",
      "AdeErYgVTbRcAWtHrMHq       4\n",
      "ZIMljraejFHmkkHvoNxk       3\n",
      "ZKlsrASsGaoEHfwkdKjL       3\n",
      "DZYjhfIUfdqhfuTNUmjn       3\n",
      "guyNoEvzgofQvvwExGOq       3\n",
      "xZYEHLyYdGXkJENJpTtu       2\n",
      "NhvfEqcSTGEZKxxvUZlj       2\n",
      "EteMoEECGsaJeMnuvAZD       2\n",
      "YTDFqIabKsQVGozQYoPf       2\n",
      "LcGIUNPUAmXtQJaDfFBR       2\n",
      "TuyPWsGQruPMpKvRxeBF       2\n",
      "WAeycgIqKXoOMXPzDUDX       2\n",
      "GaKENkrnDlLzOgREieaI       2\n",
      "aYAcKhelKzYpXrRYknSP       2\n",
      "SAVVWaMghGnnvPOqMOIt       2\n",
      "LxluDbGsLnaemhTtGuvB       1\n",
      "lXYxbSFluucyYXDQeIHX       1\n",
      "IwBedorwDIzxDRIZUTNo       1\n",
      "rqvMZiqGRTZpxvRSUTzX       1\n",
      "ptYJgYxtYQLiZcgpjmXe       1\n",
      "FkiRXDLOWtzVfvhEkhNo       1\n",
      "DaehHXyBdjcdSRnPiAQn       1\n",
      "WYLajZgbUhGimwBKDZUH       1\n",
      "sYzBROYhjSDbFZCpzGyf       1\n",
      "QEPLWgIvqPEGXcwBrsFw       1\n",
      "LrfKeexYNjGjsqQVSCdi       1\n",
      "qukbsiXCRCiIMciUjStT       1\n",
      "LBoFGHDbSeBOgvTnNlmS       1\n",
      "htRZUQDANvNrHaxZjsjz       1\n",
      "BdalQBXFeDGQTswaQtOL       1\n",
      "vilbbyUvEWbiJvxXpaNN       1\n",
      "YGYMDHtQgUvxgMZvXaZM       1\n",
      "nsxJgFVqhmchGMaUusie       1\n",
      "Name: utm_adcontent, dtype: int64\n",
      "device_category\n",
      "mobile     1854\n",
      "desktop     614\n",
      "tablet       32\n",
      "Name: device_category, dtype: int64\n",
      "device_brand\n",
      "Apple                     724\n",
      "some_unimportant_brand    635\n",
      "Samsung                   465\n",
      "Xiaomi                    311\n",
      "Huawei                    228\n",
      "Realme                     23\n",
      "Vivo                       15\n",
      "OPPO                       13\n",
      "Asus                       11\n",
      "OnePlus                    10\n",
      "Sony                        9\n",
      "ZTE                         8\n",
      "Lenovo                      8\n",
      "Nokia                       6\n",
      "Google                      6\n",
      "Meizu                       4\n",
      "Umidigi                     3\n",
      "Motorola                    3\n",
      "DOOGEE                      2\n",
      "TP-Link                     2\n",
      "BlackBerry                  2\n",
      "Tecno                       2\n",
      "BQ                          2\n",
      "LeEco                       1\n",
      "AGM                         1\n",
      "Leagoo                      1\n",
      "Blackview                   1\n",
      "LG                          1\n",
      "Oukitel                     1\n",
      "Condor                      1\n",
      "MXQ                         1\n",
      "Name: device_brand, dtype: int64\n",
      "device_screen_resolution\n",
      "370944     225\n",
      "2073600    190\n",
      "304500     157\n",
      "334443     131\n",
      "376980     130\n",
      "          ... \n",
      "567508       1\n",
      "1500000      1\n",
      "784098       1\n",
      "6144000      1\n",
      "1445906      1\n",
      "Name: device_screen_resolution, Length: 141, dtype: int64\n",
      "device_browser\n",
      "Chrome              1369\n",
      "Safari               669\n",
      "YaBrowser            200\n",
      "Android Webview       67\n",
      "Safari (in-app)       67\n",
      "Samsung Internet      39\n",
      "Firefox               38\n",
      "Edge                  36\n",
      "Opera                 14\n",
      "UC Browser             1\n",
      "Name: device_browser, dtype: int64\n",
      "geo_country\n",
      "0.9810    2445\n",
      "0.0035      12\n",
      "0.0001       8\n",
      "0.0012       8\n",
      "0.0004       6\n",
      "0.0009       5\n",
      "0.0014       4\n",
      "0.0003       4\n",
      "0.0006       3\n",
      "0.0010       2\n",
      "0.0007       2\n",
      "0.0002       1\n",
      "Name: geo_country, dtype: int64\n",
      "geo_city\n",
      "Moscow                   1167\n",
      "Saint Petersburg          344\n",
      "some_unimportant_city     279\n",
      "Krasnodar                  64\n",
      "Kazan                      48\n",
      "                         ... \n",
      "Tomsk                       1\n",
      "Bryansk                     1\n",
      "Kirov                       1\n",
      "Minsk                       1\n",
      "Pushkino                    1\n",
      "Name: geo_city, Length: 79, dtype: int64\n",
      "camp_succ_rate\n",
      "0.00731    848\n",
      "0.00577    476\n",
      "0.00000    403\n",
      "0.00845    206\n",
      "0.00612    119\n",
      "          ... \n",
      "0.01603      1\n",
      "0.00492      1\n",
      "0.00668      1\n",
      "0.00107      1\n",
      "0.00499      1\n",
      "Name: camp_succ_rate, Length: 99, dtype: int64\n",
      "11\n",
      " - \n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv('data/df3_10k_50n_50p.csv')\n",
    "\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    #('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "f_transformer = ColumnTransformer(transformers=[\n",
    "    ('categorical', categorical_transformer, make_column_selector(dtype_include='object'))\n",
    "])\n",
    "\n",
    "preprocessor = Pipeline(steps=[\n",
    "    #('event', FunctionTransformer(event_action)),\n",
    "    #('sampling', FunctionTransformer(sample_df3)),\n",
    "    ('ad_campaign_feature_creating', FunctionTransformer(ad_campaign)),\n",
    "    #('day_of_week', FunctionTransformer(day_of_week)),\n",
    "    ('empties', FunctionTransformer(empties)),\n",
    "    ('resolution_func v2', FunctionTransformer(resolution_func_v_2)),\n",
    "    ('country v2', FunctionTransformer(country_v_2)),\n",
    "    ('city', FunctionTransformer(city)),\n",
    "    ('device brand v2', FunctionTransformer(device_brand_v_2)),\n",
    "    ('filter_stuff', FunctionTransformer(filter_stuff)),\n",
    "    #('encode_stuff', FunctionTransformer(encode_stuff)),\n",
    "    #('scale_stuff(visit_num)', FunctionTransformer(scale_stuff)),\n",
    "    ('check_stuff_3', FunctionTransformer(check_stuff_3)),\n",
    "    ('f_transformer', f_transformer),\n",
    "    #('filter_stuff', FunctionTransformer(filter_stuff)),\n",
    "    #('check_stuff_3', FunctionTransformer(check_stuff_3))\n",
    "])\n",
    "\n",
    "models = [\n",
    "    #RandomForestClassifier(n_estimators=300, max_depth= 10, max_features='sqrt', min_samples_split=2),\n",
    "    #SVC(C=10, gamma=0.01, kernel='rbf'),\n",
    "    #DecisionTreeClassifier(criterion='gini', max_depth=7, min_samples_split=10),\n",
    "    #LogisticRegression( C=1.0, penalty='l2', solver='saga'),\n",
    "    MLPClassifier(hidden_layer_sizes=(100, ), solver='adam', activation='tanh')\n",
    "    ]\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "\n",
    "    pipeline = Pipeline(steps = [\n",
    "        ('preprocessor', preprocessor), \n",
    "        ('classifier', model)  \n",
    "    ])\n",
    "\n",
    "    y = df4['event_action']\n",
    "    x = df4.drop('event_action', axis=1)\n",
    "\n",
    "    #x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\n",
    "    #pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    #predictions = pipeline.predict(x_test)\n",
    "    #probs = pipeline.predict_proba(x_test)\n",
    "    #scores_single_fit.append([type(model).__name__,' test roc score - ', roc_auc_score(y_test, probs[:,1])])\n",
    "    #scores_single_fit.append([type(model).__name__,' test acc score - ', accuracy_score(y_test, predictions)])\n",
    "    #print(type(model).__name__,' test roc score - ', roc_auc_score(y_test, probs[:,1]))\n",
    "    #print(type(model).__name__,' test acc score - ', accuracy_score(y_test, predictions))\n",
    "    #interm_scores.append((str(model), 'test roc score - ', roc_auc_score(y_test, pipeline.predict_proba(x_test)[:,1])))\n",
    "    #interm_scores.append((str(model), 'test acc score - ', accuracy_score(y_test, predictions)))\n",
    "    \n",
    "    log = 'ad_camp V, resol v2 V, cntry v 2V, ct V, brand v2 V'\n",
    "    score = cross_val_score(pipeline, x, y, cv=4, scoring='roc_auc')\n",
    "    #score = cross_val_score(pipeline, x, y, cv=4, scoring='accuracy')\n",
    "    cv_scores.append([ round(score.mean(), 4), log]) #type(model).__name__,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4ffa87e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6375, 'ad_camp V, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
       " [0.6375, 'ad_camp X, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
       " [0.6375, 'ad_camp X, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
       " [0.6482, 'ad_camp V, resol v1 X, ctry v1 V, ct v1 V, brand v1 V'],\n",
       " [0.6504, 'ad_camp X, resol v1 X, ctry v1 X, ct v1 X, brand v1 X'],\n",
       " [0.6409, 'ad_camp X, resol v1 V, ctry v1 X, ct v1 X, brand v1 X'],\n",
       " [0.6396, 'ad_camp X, resol v2 V, ctry v1 X, ct v1 X, brand v1 X'],\n",
       " [0.6502, 'ad_camp X, resol v2 X, ctry v1 V, ct v1 X, brand v1 X'],\n",
       " [0.6503, 'ad_camp X, resol v2 X, ctry v2 V, ct v1 X, brand v1 X'],\n",
       " [0.6504, 'ad_camp X, resol v2 X, ctry v2 X, ct v1 X, brand v1 X'],\n",
       " [0.6498, 'ad_camp X, resol v2 X, ctry v2 X, ct v1 V, brand v1 X'],\n",
       " [0.6389, 'ad_camp X, resol v2 X, ctry v2 X, ct v2 V, brand v1 X'],\n",
       " [0.649, 'ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v1 V'],\n",
       " [0.6503, 'ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
       " [0.6504, 'ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
       " [0.6504, 'ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
       " [0.6603, 'ad_camp V, resol V, cntry V, ct V, brand V, 200k 50/50'],\n",
       " [0.6576, 'ad_camp V, resol V, cntry V, ct V, brand V, 200k 70/30'],\n",
       " [0.6456, 'ad_camp V, resol V, cntry V, ct V, brand V, 140k 30/70'],\n",
       " [0.6469, 'ad_camp V, resol V, cntry V, ct V, brand V, 100k 50/50'],\n",
       " [0.6428, 'ad_camp V, resol V, cntry V, ct V, brand V, 100k 70/30'],\n",
       " [0.6447, 'ad_camp V, resol V, cntry V, ct V, brand V, 100k 30/70'],\n",
       " [0.6438, 'ad_camp v2 V, resol V, cntry V, ct V, brand V, 100k 30/70'],\n",
       " [0.6445, 'ad_camp v2 V, resol V, cntry V, ct V, brand v2 V, 100k 30/70'],\n",
       " [0.6459, 'ad_camp V, resol V, cntry V, ct V, brand v2 V, 100k 30/70'],\n",
       " [0.6312, 'ad_camp V, resol V, cntry V, ct v2 V, brand v2 V, 100k 30/70'],\n",
       " [0.6463, 'ad_camp V, resol V, cntry v 2V, ct V, brand v2 V, 100k 30/70'],\n",
       " [0.6461, 'ad_camp V, resol v2 V, cntry v2 V, ct V, brand v2 V, 100k 30/70'],\n",
       " [0.6482, 'ad_camp V, resol v2 V, cntry v2 V, ct V, brand v2 V, 100k 50/50'],\n",
       " [0.6486, 'ad_camp V, resol v2 V, cntry v 2V, ct V, brand v2 V'],\n",
       " [0.6057, 'ad_camp V, resol v2 V, cntry v 2V, ct V, brand v2 V']]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f66ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421bfaab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70051ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f40e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "225d5b63",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_action start\n",
      "event_action start\n",
      "event_action start\n",
      "event_action start\n",
      "event_action start\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3802, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas\\_libs\\index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'event_action'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 437, in fit_transform\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 862, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 236, in transform\n    return self._transform(X, func=self.func, kw_args=self.kw_args)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 307, in _transform\n    return func(X, **(kw_args if kw_args else {}))\n  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1844\\1663308378.py\", line 13, in event_action\n    df3['event_action'] = df3['event_action'].apply(lambda x: 1 if x in target_action else 0)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 3807, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3804, in get_loc\n    raise KeyError(key) from err\nKeyError: 'event_action'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 40\u001b[0m\n\u001b[0;32m     33\u001b[0m high_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     36\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     37\u001b[0m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[0;32m     38\u001b[0m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, rf)\n\u001b[0;32m     39\u001b[0m ])\n\u001b[1;32m---> 40\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, error_score='raise')\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, acc_mean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, acc_std: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m high_score \u001b[38;5;241m<\u001b[39m score\u001b[38;5;241m.\u001b[39mmean():\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(scoring):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3802, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas\\_libs\\index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'event_action'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 437, in fit_transform\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 862, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 236, in transform\n    return self._transform(X, func=self.func, kw_args=self.kw_args)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 307, in _transform\n    return func(X, **(kw_args if kw_args else {}))\n  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1844\\1663308378.py\", line 13, in event_action\n    df3['event_action'] = df3['event_action'].apply(lambda x: 1 if x in target_action else 0)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 3807, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3804, in get_loc\n    raise KeyError(key) from err\nKeyError: 'event_action'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#f_transformer = ColumnTransformer(transformers=[\n",
    " #   ('numerical', numerical_transformer, make_column_selector(dtype_include=['int64', 'float64'])),\n",
    "  #  ('categorical', categorical_transformer, make_column_selector(dtype_include='object'))\n",
    "#])\n",
    "df4 = pd.read_csv('data/df3_10k_50n_50p.csv')\n",
    "\n",
    "#df4 = event_action(df4)\n",
    "\n",
    "#df4 = sample_df3(df4)\n",
    "\n",
    "\n",
    "y = df4['event_action']\n",
    "X = df4.drop('event_action', axis=1)\n",
    "\n",
    "preprocessor = Pipeline(steps=[\n",
    "    ('target', FunctionTransformer(event_action)),\n",
    "    ('sampling', FunctionTransformer(sample_df3)),\n",
    "    ('ad_campaign_feature_creating', FunctionTransformer(ad_campaign)),\n",
    "    ('day_of_week', FunctionTransformer(day_of_week)),\n",
    "    ('empties', FunctionTransformer(empties)),\n",
    "    ('resolution_func', FunctionTransformer(resolution_func)),\n",
    "    ('country', FunctionTransformer(country)),\n",
    "    ('city', FunctionTransformer(city)),\n",
    "    ('encode_stuff', FunctionTransformer(encode_stuff)),\n",
    "    ('scale_stuff', FunctionTransformer(scale_stuff)),\n",
    "    ('filter_stuff', FunctionTransformer(filter_stuff)),\n",
    "    ('check_stuff', FunctionTransformer(check_stuff))\n",
    "    ])\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=400, min_samples_leaf=2, max_features='sqrt')\n",
    "\n",
    "\n",
    "high_score = 0\n",
    "\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "('preprocessor', preprocessor),\n",
    "('classifier', rf)\n",
    "])\n",
    "score = cross_val_score(pipe, X, y, cv=5, scoring='a''accuracy')#, error_score='raise')\n",
    "print(f'model: {type(model).__name__}, acc_mean: {score.mean():.4f}, acc_std: {score.std():.4f}')\n",
    "if high_score < score.mean():\n",
    "    high_score = score.mean()\n",
    "    cars_pipe = pipe\n",
    "\n",
    "else:\n",
    "    continue\n",
    "\n",
    "\n",
    "#cars_pipe.fit(X, y)\n",
    "\n",
    "\n",
    "#with open('data/cars_pipe.pkl', 'wb') as file:\n",
    "#    dill.dump({\n",
    "#        'model': cars_pipe,\n",
    "#        'metadata': {\n",
    "#            'name': 'car price prediction',\n",
    "#           'author': 'collaborative ffs by this point can i really write myself here yet?)',\n",
    "#           'version': 0.00000000000000000001,\n",
    "#            'date': datetime.now(),\n",
    "#            'type': type(cars_pipe.named_steps[\"classifier\"]).__name__,\n",
    "#           'accuracy': high_score\n",
    "#       }\n",
    "#   }, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "989dd4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2abb4648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8084ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4f461240",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/best_params_lr_10k_50_50.json', 'w') as f: json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be1b28cf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country v2  start\n",
      "country v2 end\n",
      "-\n",
      "city v2  start\n",
      "city v2 end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "encode_stuff start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\4057170813.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[scaled_feature_names] = scaled_features\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\4057170813.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[scaled_feature_names] = scaled_features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_stuff end\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['event_action', 'device_brand', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate', 'utm_source_BHcvLfOaCWvWTykYqHVe',\n",
      "       'utm_source_BKeImrJuRDZcHiSSTdzm', 'utm_source_DnEUulZAecfGPvdtZBYS',\n",
      "       'utm_source_EvhrtRzIJnQYHziPiLzV', 'utm_source_FTAuYVNoYYxgvKMpKSLW',\n",
      "       ...\n",
      "       'utm_campaign_ydXTgkwKyFWEAJoahduP',\n",
      "       'utm_campaign_yxtFdhyijaALzWWYtzHE',\n",
      "       'utm_campaign_zDGMDYOBPSeVFZNNwoxT',\n",
      "       'utm_campaign_zPJpddwzkFqLMSYgtDqy',\n",
      "       'utm_campaign_zfwIehuEfWYdYrEZgRLo',\n",
      "       'utm_campaign_zmnpxOKDENholtspXiGy',\n",
      "       'utm_campaign_zxoiLxhuSIFrCeTLQVWZ', 'utm_campaign_nan',\n",
      "       'visit_number_scaled', 'day_of_week_scaled'],\n",
      "      dtype='object', length=376)\n",
      "-\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 10}\n",
      "Best Parameters:  {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 10}\n",
      "Best Score (ROC AUC):  0.6005072640206555\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "df4 = pd.read_csv('data/df3_10k_50n_50p.csv')\n",
    "\n",
    "\n",
    "df4 = ad_campaign(df4)\n",
    "df4 = day_of_week(df4)\n",
    "df4 = empties(df4)\n",
    "df4 = resolution_func(df4)\n",
    "df4 = country_v_2(df4)\n",
    "df4 = city_v_2(df4)\n",
    "df4 = device_brand(df4)\n",
    "df4 = encode_stuff(df4)\n",
    "df4 = scale_stuff(df4)\n",
    "df4 = filter_stuff(df4)\n",
    "\n",
    "y = df4['event_action']\n",
    "x = df4.drop('event_action', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define parameters and their possible values in a dictionary\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Create Logistic Regression classifier object\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Perform Grid Search with cross-validation (e.g., using k-fold CV)\n",
    "grid_search = GridSearchCV(classifier,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='roc_auc',\n",
    "                           cv=5)\n",
    "\n",
    "# Fit the model on training data and find optimal parameters based on performance metric (default is accuracy)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get best parameters found during grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best estimator/model for predictions on test data \n",
    "y_pred = grid_search.predict(x_test)\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score (ROC AUC): \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd1a29f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/best_params_des_tree_10k_50_50.json', 'w') as f: json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "011eb1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "-\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "-\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "-\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "-\n",
      "-\n",
      "country v2  start\n",
      "country v2 end\n",
      "-\n",
      "-\n",
      "-\n",
      "city v2  start\n",
      "city v2 end\n",
      "-\n",
      "-\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "-\n",
      "-\n",
      "encode_stuff start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\1991897665.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[scaled_feature_names] = scaled_features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_stuff end\n",
      "-\n",
      "-\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n",
      "-\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "-\n",
      "-\n",
      "-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1.0, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.5863333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "df4 = pd.read_csv('data/df3_10k_50n_50p.csv')\n",
    "\n",
    "\n",
    "df4 = ad_campaign(df4)\n",
    "df4 = day_of_week(df4)\n",
    "df4 = empties(df4)\n",
    "df4 = resolution_func(df4)\n",
    "df4 = country_v_2(df4)\n",
    "df4 = city_v_2(df4)\n",
    "df4 = device_brand(df4)\n",
    "df4 = encode_stuff(df4)\n",
    "df4 = scale_stuff(df4)\n",
    "df4 = filter_stuff(df4)\n",
    "\n",
    "y = df4['event_action']\n",
    "x = df4.drop('event_action', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\n",
    "\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],                # Regularization penalty ('l1' or 'l2')\n",
    "    'C': [0.01, 0.1, 1.0],                   # Inverse regularization strength (smaller values specify stronger regularization)\n",
    "    'solver': ['liblinear', 'saga']          # Algorithm to use in optimization problem\n",
    "}\n",
    "\n",
    "# Create Logistic Regression classifier object\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Perform Grid Search with cross-validation (e.g., using k-fold CV)\n",
    "grid_search = GridSearchCV(estimator=lr_model, param_grid=param_grid)\n",
    "\n",
    "# Fit the model on training data and find optimal parameters based on performance metric (default is accuracy)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get best parameters found during grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best estimator/model for predictions on test data \n",
    "y_pred = grid_search.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a6d44992",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/best_params_rf_10k_50_50.json', 'w') as f: json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e7ee9da5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "-\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "-\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "-\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "-\n",
      "-\n",
      "country v2  start\n",
      "country v2 end\n",
      "-\n",
      "-\n",
      "-\n",
      "city v2  start\n",
      "city v2 end\n",
      "-\n",
      "-\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "-\n",
      "-\n",
      "encode_stuff start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\1991897665.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[scaled_feature_names] = scaled_features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_stuff end\n",
      "-\n",
      "-\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n",
      "-\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "-\n",
      "-\n",
      "-\n",
      "Best Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 300}\n",
      "0.5943333333333334\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv('data/df3_10k_50n_50p.csv')\n",
    "\n",
    "\n",
    "df4 = ad_campaign(df4)\n",
    "df4 = day_of_week(df4)\n",
    "df4 = empties(df4)\n",
    "df4 = resolution_func(df4)\n",
    "df4 = country_v_2(df4)\n",
    "df4 = city_v_2(df4)\n",
    "df4 = device_brand(df4)\n",
    "df4 = encode_stuff(df4)\n",
    "df4 = scale_stuff(df4)\n",
    "df4 = filter_stuff(df4)\n",
    "\n",
    "y = df4['event_action']\n",
    "x = df4.drop('event_action', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400],    # Number of trees in the forest\n",
    "    'max_depth': [None, 5, 10],          # Maximum depth of each tree\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'min_samples_split': [2, 5, 10], # Minimum number of samples required to split an internal node\n",
    "}\n",
    "\n",
    "# Create Random Forest classifier object\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Perform Grid Search with cross-validation (e.g., using k-fold CV)\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid)\n",
    "\n",
    "# Fit the model on training data and find optimal parameters based on performance metric (default is accuracy)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get best parameters found during grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best estimator/model for predictions on test data \n",
    "y_pred = grid_search.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "47e21c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200k, 70n\\x18p'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
