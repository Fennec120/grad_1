{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb2aa0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import json\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b8766df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_action(df3):\n",
    "    print('event_action start')\n",
    "    target_action = ['sub_car_claim_click', \n",
    "                 'sub_car_claim_submit_click',\n",
    "                 'sub_open_dialog_click', \n",
    "                 'sub_custom_question_submit_click', \n",
    "                 'sub_call_number_click', \n",
    "                 'sub_callback_submit_click', \n",
    "                 'sub_submit_success', \n",
    "                 'sub_car_request_submit_click'\n",
    "                ]\n",
    "\n",
    "    df3['event_action'] = df3['event_action'].apply(lambda x: 1 if x in target_action else 0)\n",
    "    \n",
    "    print( 'event_action end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77d1991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_df3(df3, total_rows =  200000, neg_percent = 50, pos_percent = 50):\n",
    "    print( 'sample_df3 start')\n",
    "    df3_pos = df3[df3['event_action'] == 1].sample(int(total_rows / 100 * pos_percent))\n",
    "    df3_neg = df3[df3['event_action'] == 0].sample(int(total_rows / 100 * neg_percent))\n",
    "    df3_pos = df3_pos.reset_index()\n",
    "    df3_neg = df3_neg.reset_index()\n",
    "    df3_pos = df3_pos.drop('index', axis=1)\n",
    "    df3_neg = df3_neg.drop('index', axis=1)\n",
    "    df3 = pd.concat([df3_pos, df3_neg])\n",
    "    \n",
    "    print( 'sample_df3 end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "540c97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ad_campaign(df3):\n",
    "    print( 'ad_campaign start')\n",
    "    try:\n",
    "        with open('data/utm_c_frec_dict1.json', 'r') as f:\n",
    "            utm_c_frec_dict = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "\n",
    "        utm_c_frec_dict = {}\n",
    "        counter = 1\n",
    "        for pos in df3.utm_campaign.unique():\n",
    "            if len(df3[(df3.utm_campaign == pos) & (df3.event_action == 1)]) == 0:\n",
    "                utm_c_frec_dict[str(pos)] = 0\n",
    "            else:\n",
    "                utm_c_frec_dict[str(pos)] = round(len(df3[(df3.utm_campaign == pos) & (df3.event_action == 1)]) / len(df3[df3.utm_campaign == pos]), 5)\n",
    "\n",
    "            #print(counter)\n",
    "            counter = counter  + 1\n",
    "        with open('data/utm_c_frec_dict1.json', 'w') as f: \n",
    "            json.dump(utm_c_frec_dict, f)\n",
    "\n",
    "    finally:\n",
    "        df3['camp_succ_rate'] = df3.utm_campaign.apply(lambda x: utm_c_frec_dict[str(x)])\n",
    "    \n",
    "    print( 'ad_campaign end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40072e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_of_week(df3):\n",
    "    print( 'day_of_week start')\n",
    "    df3['new_date'] = pd.to_datetime(df3['visit_date'])\n",
    "    df3['day_of_week'] = df3.new_date.dt.dayofweek\n",
    "    \n",
    "    df3 = df3.drop('new_date', axis=1)\n",
    "    print('day_of_week end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21610a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def empties(df3):\n",
    "    print( 'empties end')\n",
    "    df3.loc[df3.utm_source.isna() == True, 'utm_source'] = 'other'\n",
    "    df3.loc[df3.utm_adcontent.isna() == True, 'utm_adcontent'] = 'Other'\n",
    "    df3.loc[df3.device_brand.isna() == True, 'device_brand'] = 'other'\n",
    "    \n",
    "    print( 'empties end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')  \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41d98c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolution_func(df3):\n",
    "    print('resolution_func start')\n",
    "    #resolution\n",
    "    bounds = []\n",
    "    df3['resolution'] = df3.device_screen_resolution.apply(lambda x:eval(x.replace('x','*')))\n",
    "    for device in df3.device_category.unique():\n",
    "        q25 = df3[df3.device_category == device].resolution.quantile(0.25)\n",
    "        q75 = df3[df3.device_category == device].resolution.quantile(0.75)\n",
    "        iqr = q75 - q25\n",
    "        bounds.append((device, q25 - 1.5 * iqr, q75 + 1.5 * iqr))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    test_list = list(df3.device_screen_resolution)\n",
    "    test_list2 = list(df3.device_category)\n",
    "\n",
    "    for i in range(len(test_list)):\n",
    "        test_list[i] = eval(test_list[i].replace('x','*'))\n",
    "\n",
    "    tst_l = list(zip(test_list2, test_list))\n",
    "\n",
    "    resolution = []\n",
    "\n",
    "    for i in range(len(tst_l)):\n",
    "        if tst_l[i][0] == bounds[0][0]:\n",
    "            resolution.append(bounds[0][0]+'_high' if tst_l[i][1] >= bounds[0][2] * 0.7 else (bounds[0][0]+'_medium' if bounds[0][2] * 0.7 > tst_l[i][1] >= bounds[0][2] * 0.1 else bounds[0][0]+'_low'))\n",
    "        elif tst_l[i][0] == bounds[1][0]:\n",
    "            resolution.append(bounds[1][0]+'_high' if tst_l[i][1] >= bounds[1][2] * 0.7 else (bounds[1][0]+'_medium' if bounds[1][2] * 0.7 > tst_l[i][1] >= bounds[1][2] * 0.1 else bounds[1][0]+'_low'))\n",
    "        elif tst_l[i][0] == bounds[2][0]:\n",
    "            resolution.append(bounds[2][0]+'_high' if tst_l[i][1] >= bounds[2][2] * 0.7 else (bounds[2][0]+'_medium' if bounds[2][2] * 0.7 > tst_l[i][1] >= bounds[2][2] * 0.1 else bounds[2][0]+'_low'))\n",
    "\n",
    "    df3['device_screen_resolution'] = resolution\n",
    "    df3 = df3.drop('resolution', axis=1)\n",
    "    \n",
    "    print('resolution_func end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    \n",
    "    return df3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f81310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolution_func_v_2(df3):\n",
    "    print('resolution_func v2 start')\n",
    "    #resolution\n",
    "    bounds = []\n",
    "    df3['device_screen_resolution'] = df3.device_screen_resolution.apply(lambda x:eval(x.replace('x','*')))\n",
    "\n",
    "    \n",
    "    print('resolution_func v2 end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    \n",
    "    return df3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23b6e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country(df3, trsh = 0.001):\n",
    "    print('country start')\n",
    "    #geo_country\n",
    "    country_list = list(df3.geo_country.unique())\n",
    "    for i in range(len(country_list)):\n",
    "        country_list[i] = ( len(df3[df3.geo_country == country_list[i]]), country_list[i])\n",
    "    country_list = sorted(country_list, reverse=True)\n",
    "\n",
    "#    trsh = 0.0005\n",
    "    df3_len = len(df3) \n",
    "    for item in country_list:\n",
    "        if item[0] / df3_len >= trsh:\n",
    "            continue\n",
    "        else:\n",
    "            df3.loc[df3.geo_country == item[1], 'geo_country'] = 'some_unimportant_country'\n",
    "    \n",
    "    print( 'country end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3af77a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_v_2(df3):\n",
    "    print('country v2  start')\n",
    "    #geo_country\n",
    "    counter = 0\n",
    "    country_list_new = dict()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        with open('data/country_list_new.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                country_list_new[my_tuple[0]] = my_tuple[1]\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "        \n",
    "        succ_total = len(df3[df3.event_action == 1])\n",
    "        country_list_success = df3[df3.event_action == 1].geo_country.value_counts().sort_values(ascending=False)\n",
    "        country_list_new = []\n",
    "        for country in country_list_success.keys():\n",
    "            country_list_new.append(f'{country}*{str(round(country_list_success[country] / succ_total, 4))}%')\n",
    "            counter += 1\n",
    "            if counter == 23:\n",
    "                break\n",
    "\n",
    "        with open('data/country_list_new.txt', 'w') as f:\n",
    "            for t in country_list_new:\n",
    "                f.write(str(t) +'\\n')\n",
    "                \n",
    "        country_list_new = dict()        \n",
    "        with open('data/country_list_new.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                country_list_new[my_tuple[0]] = my_tuple[1]                \n",
    "\n",
    "\n",
    "    finally:\n",
    "        df3['geo_country'] = df3['geo_country'].apply(lambda x: country_list_new[x] if x in country_list_new else 0.0001)\n",
    "        \n",
    "    \n",
    "\n",
    "    #print(sum(df4.isnull().sum().values))\n",
    "    #print(df4.isnull().sum())\n",
    "    print('country v2 end')    \n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')     \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82a5c836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def city(df3, trsh = 0.001):\n",
    "    print('city start')\n",
    "    #geo_city\n",
    "    city_list = []\n",
    "    df3_len = len(df3)\n",
    "    try:\n",
    "        with open('data/city_list1.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace('(', '').replace(')', '').replace(\"'\", '')\n",
    "                # split on comma and convert each element to correct type\n",
    "                tuple_elements = [int(e.strip()) if e.strip().isdigit() else e.strip() for e in line.split(',')]\n",
    "                # create tuple and add to list\n",
    "                my_tuple = tuple(tuple_elements)\n",
    "                city_list.append(my_tuple)\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "\n",
    "        city_list = list(zip(df3.geo_city.value_counts().values, df3.geo_city.value_counts().keys() ))\n",
    "        city_list = sorted(city_list, reverse=True)\n",
    "\n",
    "        with open('data/city_list1.txt', 'w') as f:\n",
    "            for t in city_list:\n",
    "                f.write(str(t) +'\\n')\n",
    "\n",
    "\n",
    "\n",
    "    finally:\n",
    "#        trsh = 0.0005\n",
    "        city_list_valid = []\n",
    "        \n",
    "        for item in city_list:\n",
    "            #print(item[1], ' - ', round(item[0] / df3_len, 4),'%' )\n",
    "            if round(item[0] / df3_len, 4) >= trsh:\n",
    "                city_list_valid.append(item[1])\n",
    "                #print('trsh == 2000 - ', item[0], item[1], round(item[0] / df3_len, 4) >= trsh, ' - appended')\n",
    "\n",
    "        df3.loc[(~df3['geo_city'].isin(city_list_valid)), 'geo_city'] = 'some_unimportant_city'\n",
    "    \n",
    "    \n",
    "\n",
    "    #print(sum(df4.isnull().sum().values))\n",
    "    #print(df4.isnull().sum())\n",
    "    print('city end')    \n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')      \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d07109ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def city_v_2(df3):\n",
    "    print('city v2  start')\n",
    "    #geo_city\n",
    "    counter = 0\n",
    "    city_list_new = dict()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        with open('data/city_list_new.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                city_list_new[my_tuple[0]] = my_tuple[1]\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "        \n",
    "        succ_total = len(df3[df3.event_action == 1])\n",
    "        city_list_success = df3[df3.event_action == 1].geo_city.value_counts().sort_values(ascending=False)\n",
    "        city_list_new = []\n",
    "        for city in city_list_success.keys():\n",
    "            city_list_new.append(f'{city}*{str(round(city_list_success[city] / succ_total, 4))}%')\n",
    "            counter += 1\n",
    "            if counter == 26:\n",
    "                break\n",
    "\n",
    "        with open('data/city_list_new.txt', 'w') as f:\n",
    "            for t in city_list_new:\n",
    "                f.write(str(t) +'\\n')\n",
    "                \n",
    "        with open('data/city_list_new.txt', 'r') as f:\n",
    "            city_list_new = dict()\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                city_list_new[my_tuple[0]] = my_tuple[1]                \n",
    "\n",
    "\n",
    "    finally:\n",
    "        \n",
    "        df3['geo_city'] = df3['geo_city'].apply(lambda x: city_list_new[x] if x in city_list_new else 0.0001)\n",
    "        \n",
    "    \n",
    "\n",
    "    #print(sum(df4.isnull().sum().values))\n",
    "    #print(df4.isnull().sum())\n",
    "    print('city v2 end')    \n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')      \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae66ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def device_brand(df3):\n",
    "    print('device_brand start')\n",
    "    #device_brand\n",
    "    counter = 0\n",
    "    device_brand_list_new = dict()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        with open('data/device_brand_list_new.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                device_brand_list_new[my_tuple[0]] = my_tuple[1]\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "        succ_total = len(df3[df3.event_action == 1])\n",
    "        device_brand_list_success = df3[df3.event_action == 1].device_brand.value_counts().sort_values(ascending=False)\n",
    "        device_brand_list_new = []\n",
    "        for device_brand in device_brand_list_success.keys():\n",
    "            device_brand_list_new.append(f'{device_brand}*{str(round(device_brand_list_success[device_brand] / succ_total, 4))}%')\n",
    "            counter += 1\n",
    "            if counter == 23:\n",
    "                break\n",
    "\n",
    "        with open('data/device_brand_list_new.txt', 'w') as f:\n",
    "            for t in device_brand_list_new:\n",
    "                f.write(str(t) +'\\n')\n",
    "                \n",
    "        device_brand_list_new = dict()        \n",
    "        with open('data/device_brand_list_new.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                device_brand_list_new[my_tuple[0]] = my_tuple[1]                \n",
    "\n",
    "\n",
    "    finally:\n",
    "        df3['device_brand'] = df3['device_brand'].apply(lambda x: device_brand_list_new[x] if x in device_brand_list_new else 0.0001)\n",
    "        \n",
    "    \n",
    "\n",
    "    #print(sum(df4.isnull().sum().values))\n",
    "    #print(df4.isnull().sum())\n",
    "    print('device_brand end')    \n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')      \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2719895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def device_brand_v_2(df3, trsh = 0.0012):\n",
    "    print('device_brand v 2 start')\n",
    "    #device_brand\n",
    "    brand_list = []\n",
    "    df3_len = len(df3)\n",
    "    \n",
    "    try:\n",
    "        with open('data/brand_list1.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace('(', '').replace(')', '').replace(\"'\", '')\n",
    "                # split on comma and convert each element to correct type\n",
    "                tuple_elements = [int(e.strip()) if e.strip().isdigit() else e.strip() for e in line.split(',')]\n",
    "                # create tuple and add to list\n",
    "                my_tuple = tuple(tuple_elements)\n",
    "                brand_list.append(my_tuple)\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "\n",
    "        brand_list = list(zip(df3.device_brand.value_counts().values, df3.device_brand.value_counts().keys() ))\n",
    "        brand_list = sorted(brand_list, reverse=True)\n",
    "\n",
    "        with open('data/brand_list1.txt', 'w') as f:\n",
    "            for t in brand_list:\n",
    "                f.write(str(t) +'\\n')\n",
    "\n",
    "\n",
    "\n",
    "    finally:\n",
    "#        trsh = 0.0005\n",
    "        brand_list_valid = []\n",
    "        \n",
    "        for item in brand_list:\n",
    "            #print(item[0], ' ', item[0] / df3_len,'>=', trsh, ' ', round(item[0] / df3_len, 4) >= trsh )\n",
    "            if item[0] / df3_len >= trsh:\n",
    "                brand_list_valid.append(item[1])\n",
    "                #print(len(brand_list_valid), ' ', item[0],' ',item[1] )\n",
    "\n",
    "        df3.loc[(~df3['device_brand'].isin(brand_list_valid)), 'device_brand'] = 'some_unimportant_brand'\n",
    "    \n",
    "    \n",
    "    print('device_brand v 2 end')    \n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')      \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff60f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_stuff(df3):\n",
    "    print('encode_stuff start')\n",
    "    cols_to_encode = ['utm_source', \n",
    "                      'utm_medium', \n",
    "                      'utm_adcontent', \n",
    "                      #'device_brand', \n",
    "                      'device_category', \n",
    "                      'device_screen_resolution', \n",
    "                      'device_browser',\n",
    "                      'utm_campaign'\n",
    "                      #,'geo_country',\n",
    "                      #'geo_city'\n",
    "                     ]\n",
    "    \n",
    "    #encoding\n",
    "    encoded_features = pd.DataFrame()\n",
    "\n",
    "    for col in cols_to_encode:\n",
    "\n",
    "        pre_encoded_df3 = df3[[col]]\n",
    "        encoder = OneHotEncoder(categories='auto', handle_unknown='ignore', sparse=False)\n",
    "        encoded_array = encoder.fit_transform(pre_encoded_df3)\n",
    "        #feature_names = [f'{col}_{name}' for name in encoder.get_feature_names_out()]\n",
    "        feature_names = encoder.get_feature_names_out()\n",
    "        encoded_df3 = pd.DataFrame(encoded_array, columns=feature_names)\n",
    "\n",
    "        #if len(encoded_features) == 0:\n",
    "        #    encoded_features = encoded_df3.copy()\n",
    "        #else:\n",
    "        #    encoded_features[feature_names] = encoded_df3.values\n",
    "        \n",
    "        df3[feature_names] = encoded_df3.values\n",
    "    #print(encoded_features.isnull().sum())\n",
    "\n",
    "    #df3 = df3.join(encoded_features)\n",
    "    #print(df3.isnull().sum())\n",
    "    df3 = df3.drop(cols_to_encode, axis=1)\n",
    "    print( 'encode_stuff end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')  \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "439622ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_stuff(df3):\n",
    "    #scaling\n",
    "    print('scale_stuff start')\n",
    "    cols_to_scale = ['visit_number',\n",
    "                     'day_of_week'\n",
    "                    # ,'device_screen_resolution'\n",
    "                    ]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(df3.loc[:,cols_to_scale])\n",
    "    scaled_feature_names = [f'{name}_scaled' for name in scaler.get_feature_names_out()]\n",
    "    #scaler.get_feature_names_out()\n",
    "\n",
    "    #scaled_df = pd.DataFrame(scaled_features, columns=scaled_feature_names)\n",
    "    df3[scaled_feature_names] = scaled_features\n",
    "    #print(scaled_df.shape, scaled_df.columns)\n",
    "    #print(scaled_df.isnull().sum())\n",
    "\n",
    "    #df3['scaled_feature_names'] = scaled_df\n",
    "    #print(df3.shape, df3.columns)\n",
    "    df3 = df3.drop(cols_to_scale, axis=1)\n",
    "    \n",
    "    #print(df3.isnull().sum())\n",
    "    #print(len(df3.columns), df3.columns)\n",
    "    print('scale_stuff end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')  \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2a7612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stuff(df3):\n",
    "    #pre-existing list of columns\n",
    "    print('filter_stuff start')\n",
    "    cols_to_drop = [\n",
    "        'session_id',\n",
    "        'hit_date',\n",
    "        'hit_time',\n",
    "        'hit_number',\n",
    "        'hit_type',\n",
    "        'hit_referer',\n",
    "        'hit_page_path',\n",
    "        'event_category',\n",
    "        'event_label',\n",
    "        'event_value',\n",
    "        'client_id',\n",
    "        #'new_date',\n",
    "        'visit_date',\n",
    "        'utm_keyword',\n",
    "        'device_os',\n",
    "        'device_model',\n",
    "        'visit_time'\n",
    "    ]\n",
    "    \n",
    "    cols_to_encode = [\n",
    "        'utm_source',\n",
    "        'utm_medium', \n",
    "        'utm_adcontent',\n",
    "        #'device_brand', \n",
    "        'device_category', \n",
    "        #'device_screen_resolution',\n",
    "        'device_browser',\n",
    "        'utm_campaign',\n",
    "        #,'geo_country',\n",
    "        #'geo_city'\n",
    "    ]\n",
    "    #dropping\n",
    "    #cols_to_drop = []\n",
    "    #for col in df_columns:\n",
    "    #    cols_to_drop.append(str(col))\n",
    "    #cols_to_drop = cols_to_drop + ['client_id','new_date', 'visit_date', 'utm_keyword', 'device_os', 'device_model', 'visit_time']    \n",
    "    \n",
    "    df3 = df3.drop(cols_to_drop, axis=1)\n",
    "    #df3 = df3.drop(cols_to_encode, axis=1)\n",
    "    \n",
    "    try:\n",
    "        df3 = df3.drop('Unnamed: 0', axis=1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        df3 = df3.drop('Unnamed: 0.1', axis=1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        df3 = df3.drop('Unnamed: 0.2', axis=1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    print('filter_stuff end')\n",
    "    #print(sum(df3.isnull().sum().values))\n",
    "    #print(df3.isnull().sum())\n",
    "    print(df3.columns)\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "859940a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stuff(df3):\n",
    "    #checking\n",
    "    print('check_stuff start')\n",
    "    counter = 0\n",
    "    for feature in df3.columns:\n",
    "        if df3[feature].dtype != 'O':\n",
    "            #print(feature, ' - ', df3[feature].dtype)\n",
    "            counter += 1\n",
    "        else:\n",
    "            print(feature)\n",
    "    print(counter == len(df3.columns))\n",
    "\n",
    "\n",
    "    #checking 2\n",
    "    counter = 0\n",
    "    for feature in df3.columns:\n",
    "        if len(df3[df3[str(feature)].isna() == True]) != 0:\n",
    "            print(feature, ' - ', len(df3[df3[str(feature)].isna() == True]))\n",
    "            counter += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if counter == 0:\n",
    "        print('vse zaebis\", pustukh fi4ei net')    \n",
    "    \n",
    "    \n",
    "    print('check_stuff end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "814b693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stuff_2(df3):\n",
    "    #checking\n",
    "    print('check_stuff_2 start')\n",
    "\n",
    "    counter = 0\n",
    "    for feature in df3.columns:\n",
    "        if df3[feature].dtype != 'O':\n",
    "            #print(feature, ' - ', df3[feature].dtype)\n",
    "            counter += 1\n",
    "        else:\n",
    "            print(feature)\n",
    "    print(counter == len(df3.columns))\n",
    "\n",
    "\n",
    "    #checking 2\n",
    "    empty_features = False\n",
    "    if sum(df3.isnull().sum()) != 0:\n",
    "        print(df3.isnull().sum())\n",
    "        empty_features = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if empty_features == False:\n",
    "        print('vse zaebis\", pustukh fi4ei net') \n",
    "    #print(len(df3.isnull().sum()))\n",
    "    print(df3.shape,  'check_stuff_2 end') #df3.shape,\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')     \n",
    "    \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b018e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stuff_3(df3):\n",
    "    print(len(df3.columns), df3.columns)\n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a48f726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_stuff(df3):\n",
    "    y = df3['event_action']\n",
    "    \n",
    "    df3 = df3.drop('event_action', axis=1)\n",
    "    print(df3.columns)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df3,y, test_size=0.3)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=400, min_samples_leaf=2, max_features='sqrt')\n",
    "    rf.fit(x_train, y_train)\n",
    "    \n",
    "    predicted_train = rf.predict(x_train)\n",
    "    predicted_test = rf.predict(x_test)\n",
    "    \n",
    "    #print(df3.shape, ' - shape', ' function - ')\n",
    "    \n",
    "    \n",
    "    print('train acc score - ',accuracy_score(y_train, predicted_train))\n",
    "    print('test acc score - ', accuracy_score(y_test, predicted_test))\n",
    "\n",
    "    print('train roc score - ',roc_auc_score(y_train, rf.predict_proba(x_train)[:,1]))\n",
    "    print('test roc score - ',roc_auc_score(y_test, rf.predict_proba(x_test)[:,1]))\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c73138c",
   "metadata": {},
   "source": [
    "with open('models/rf_model.pkl', 'wb') as file:\n",
    "    dill.dump(rf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d65451",
   "metadata": {},
   "source": [
    "## function declarations end here. its wildlands after that...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7334420c",
   "metadata": {},
   "source": [
    "df = pd.read_csv('data/ga_hits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de180c06",
   "metadata": {},
   "source": [
    "df2 = pd.read_csv('data/ga_sessions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8a6381",
   "metadata": {},
   "source": [
    "df3 = pd.merge(df, df2, on='session_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0de393",
   "metadata": {},
   "source": [
    "df3 = event_action(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "301c1097",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = [\n",
    "    [0.6375, 'ad_camp V, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
    "    [0.6375, 'ad_camp X, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
    "    [0.6375, ', ad_camp X, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
    "    [0.6482, ', ad_camp V, resol v1 X, ctry v1 V, ct v1 V, brand v1 V'],\n",
    "    [0.6504, ', ad_camp X, resol v1 X, ctry v1 X, ct v1 X, brand v1 X'],\n",
    "    [0.6409, ', ad_camp X, resol v1 V, ctry v1 X, ct v1 X, brand v1 X'],\n",
    "    [0.6396, ', ad_camp X, resol v2 V, ctry v1 X, ct v1 X, brand v1 X'],\n",
    "    [0.6502, ', ad_camp X, resol v2 X, ctry v1 V, ct v1 X, brand v1 X'],\n",
    "    [0.6503, ', ad_camp X, resol v2 X, ctry v2 V, ct v1 X, brand v1 X'],\n",
    "    [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v1 X, brand v1 X'],\n",
    "    [0.6498, ', ad_camp X, resol v2 X, ctry v2 X, ct v1 V, brand v1 X'],\n",
    "    [0.6389, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 V, brand v1 X'],\n",
    "    [0.649, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v1 V'],\n",
    "    [0.6503, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
    "    [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
    "    [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3befdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['visit_number', 'utm_source', 'utm_medium', 'utm_campaign',\n",
      "       'utm_adcontent', 'device_category', 'device_brand',\n",
      "       'device_screen_resolution', 'device_browser', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate', 'day_of_week'],\n",
      "      dtype='object')\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n",
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['visit_number', 'utm_source', 'utm_medium', 'utm_campaign',\n",
      "       'utm_adcontent', 'device_category', 'device_brand',\n",
      "       'device_screen_resolution', 'device_browser', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate', 'day_of_week'],\n",
      "      dtype='object')\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n",
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['visit_number', 'utm_source', 'utm_medium', 'utm_campaign',\n",
      "       'utm_adcontent', 'device_category', 'device_brand',\n",
      "       'device_screen_resolution', 'device_browser', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate', 'day_of_week'],\n",
      "      dtype='object')\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n",
      "RandomForestClassifier  test roc score -  0.6277333162395026\n",
      "RandomForestClassifier  test acc score -  0.6997450980392157\n",
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['visit_number', 'utm_source', 'utm_medium', 'utm_campaign',\n",
      "       'utm_adcontent', 'device_category', 'device_brand',\n",
      "       'device_screen_resolution', 'device_browser', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate', 'day_of_week'],\n",
      "      dtype='object')\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n",
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['visit_number', 'utm_source', 'utm_medium', 'utm_campaign',\n",
      "       'utm_adcontent', 'device_category', 'device_brand',\n",
      "       'device_screen_resolution', 'device_browser', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate', 'day_of_week'],\n",
      "      dtype='object')\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n",
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['visit_number', 'utm_source', 'utm_medium', 'utm_campaign',\n",
      "       'utm_adcontent', 'device_category', 'device_brand',\n",
      "       'device_screen_resolution', 'device_browser', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate', 'day_of_week'],\n",
      "      dtype='object')\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n",
      "DecisionTreeClassifier  test roc score -  0.5824885060117818\n",
      "DecisionTreeClassifier  test acc score -  0.7016862745098039\n",
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['visit_number', 'utm_source', 'utm_medium', 'utm_campaign',\n",
      "       'utm_adcontent', 'device_category', 'device_brand',\n",
      "       'device_screen_resolution', 'device_browser', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate', 'day_of_week'],\n",
      "      dtype='object')\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['visit_number', 'utm_source', 'utm_medium', 'utm_campaign',\n",
      "       'utm_adcontent', 'device_category', 'device_brand',\n",
      "       'device_screen_resolution', 'device_browser', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate', 'day_of_week'],\n",
      "      dtype='object')\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n",
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['visit_number', 'utm_source', 'utm_medium', 'utm_campaign',\n",
      "       'utm_adcontent', 'device_category', 'device_brand',\n",
      "       'device_screen_resolution', 'device_browser', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate', 'day_of_week'],\n",
      "      dtype='object')\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n",
      "LogisticRegression  test roc score -  0.6377902118083272\n",
      "LogisticRegression  test acc score -  0.7056470588235294\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv('data/df3_340k_70n_30p.csv')\n",
    "\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    #('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "f_transformer = ColumnTransformer(transformers=[\n",
    "    ('categorical', categorical_transformer, make_column_selector(dtype_include='object'))\n",
    "])\n",
    "\n",
    "preprocessor = Pipeline(steps=[\n",
    "    #('event', FunctionTransformer(event_action)),\n",
    "    #('sampling', FunctionTransformer(sample_df3)),\n",
    "    ('ad_campaign_feature_creating', FunctionTransformer(ad_campaign)),\n",
    "    ('day_of_week', FunctionTransformer(day_of_week)),\n",
    "    ('empties', FunctionTransformer(empties)),\n",
    "    ('resolution_func', FunctionTransformer(resolution_func)),\n",
    "    ('country', FunctionTransformer(country)),\n",
    "    ('city', FunctionTransformer(city)),\n",
    "    ('device brand', FunctionTransformer(device_brand)),\n",
    "    ('filter_stuff', FunctionTransformer(filter_stuff)),\n",
    "    #('encode_stuff', FunctionTransformer(encode_stuff)),\n",
    "    ('scale_stuff(visit_num)', FunctionTransformer(scale_stuff)),\n",
    "    ('f_transformer', f_transformer),\n",
    "    #('check_stuff_3', FunctionTransformer(check_stuff_3))\n",
    "])\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=300, max_depth= 10, max_features='sqrt', min_samples_split=2),\n",
    "    #SVC(C=10, gamma=0.01, kernel='rbf'),\n",
    "    DecisionTreeClassifier(criterion='gini', max_depth=7, min_samples_split=10),\n",
    "    LogisticRegression( C=1.0, penalty='l2', solver='saga')\n",
    "    ]\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "\n",
    "    pipeline = Pipeline(steps = [\n",
    "        ('preprocessor', preprocessor), \n",
    "        ('classifier', model)  \n",
    "    ])\n",
    "\n",
    "    y = df4['event_action']\n",
    "    x = df4.drop('event_action', axis=1)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    predictions = pipeline.predict(x_test)\n",
    "    probs = pipeline.predict_proba(x_test)\n",
    "    print(type(model).__name__,' test roc score - ', roc_auc_score(y_test, probs[:,1]))\n",
    "    print(type(model).__name__,' test acc score - ', accuracy_score(y_test, predictions))\n",
    "    #interm_scores.append((str(model), 'test roc score - ', roc_auc_score(y_test, pipeline.predict_proba(x_test)[:,1])))\n",
    "    #interm_scores.append((str(model), 'test acc score - ', accuracy_score(y_test, predictions)))\n",
    "    \n",
    "    #log = 'ad_camp V, resol V, cntry V, ct V, brand V'\n",
    "    #score = cross_val_score(pipeline, x, y, cv=4, scoring='roc_auc')\n",
    "    #score = cross_val_score(pipeline, x, y, cv=4, scoring='accuracy')\n",
    "    #cv_scores.append([ round(score.mean(), 4), log]) #type(model).__name__,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9174ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fab2d5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57935     1\n",
       "303849    0\n",
       "324907    0\n",
       "29718     1\n",
       "264378    0\n",
       "309521    0\n",
       "265538    0\n",
       "Name: event_action, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[101993:102000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ea8c215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26147092, 0.73852908],\n",
       "       [0.85764563, 0.14235437],\n",
       "       [0.68091218, 0.31908782],\n",
       "       [0.56319319, 0.43680681],\n",
       "       [0.71138692, 0.28861308],\n",
       "       [0.69080172, 0.30919828],\n",
       "       [0.66625229, 0.33374771]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[101993:102000,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ffa87e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6375, 'ad_camp V, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
       " [0.6375, 'ad_camp X, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
       " [0.6375, ', ad_camp X, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
       " [0.6482, ', ad_camp V, resol v1 X, ctry v1 V, ct v1 V, brand v1 V'],\n",
       " [0.6504, ', ad_camp X, resol v1 X, ctry v1 X, ct v1 X, brand v1 X'],\n",
       " [0.6409, ', ad_camp X, resol v1 V, ctry v1 X, ct v1 X, brand v1 X'],\n",
       " [0.6396, ', ad_camp X, resol v2 V, ctry v1 X, ct v1 X, brand v1 X'],\n",
       " [0.6502, ', ad_camp X, resol v2 X, ctry v1 V, ct v1 X, brand v1 X'],\n",
       " [0.6503, ', ad_camp X, resol v2 X, ctry v2 V, ct v1 X, brand v1 X'],\n",
       " [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v1 X, brand v1 X'],\n",
       " [0.6498, ', ad_camp X, resol v2 X, ctry v2 X, ct v1 V, brand v1 X'],\n",
       " [0.6389, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 V, brand v1 X'],\n",
       " [0.649, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v1 V'],\n",
       " [0.6503, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
       " [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
       " [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
       " [0.6503, 'ad_camp X, resol v2 X, cntry v2 X, ct v2 X, brand v2 X'],\n",
       " [0.7049, 'ad_camp V, resol V, cntry V, ct V, brand V'],\n",
       " [0.6375, 'ad_camp V, resol V, cntry V, ct V, brand V']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f66ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421bfaab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70051ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f40e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "225d5b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_action start\n",
      "event_action start\n",
      "event_action start\n",
      "event_action start\n",
      "event_action start\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3802, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas\\_libs\\index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'event_action'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 437, in fit_transform\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 862, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 236, in transform\n    return self._transform(X, func=self.func, kw_args=self.kw_args)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 307, in _transform\n    return func(X, **(kw_args if kw_args else {}))\n  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1844\\1663308378.py\", line 13, in event_action\n    df3['event_action'] = df3['event_action'].apply(lambda x: 1 if x in target_action else 0)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 3807, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3804, in get_loc\n    raise KeyError(key) from err\nKeyError: 'event_action'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 40\u001b[0m\n\u001b[0;32m     33\u001b[0m high_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     36\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     37\u001b[0m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[0;32m     38\u001b[0m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, rf)\n\u001b[0;32m     39\u001b[0m ])\n\u001b[1;32m---> 40\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, error_score='raise')\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, acc_mean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, acc_std: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m high_score \u001b[38;5;241m<\u001b[39m score\u001b[38;5;241m.\u001b[39mmean():\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(scoring):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3802, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas\\_libs\\index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'event_action'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 437, in fit_transform\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 862, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 236, in transform\n    return self._transform(X, func=self.func, kw_args=self.kw_args)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 307, in _transform\n    return func(X, **(kw_args if kw_args else {}))\n  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1844\\1663308378.py\", line 13, in event_action\n    df3['event_action'] = df3['event_action'].apply(lambda x: 1 if x in target_action else 0)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 3807, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3804, in get_loc\n    raise KeyError(key) from err\nKeyError: 'event_action'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#f_transformer = ColumnTransformer(transformers=[\n",
    " #   ('numerical', numerical_transformer, make_column_selector(dtype_include=['int64', 'float64'])),\n",
    "  #  ('categorical', categorical_transformer, make_column_selector(dtype_include='object'))\n",
    "#])\n",
    "df4 = pd.read_csv('data/df3_10k_50n_50p.csv')\n",
    "\n",
    "#df4 = event_action(df4)\n",
    "\n",
    "#df4 = sample_df3(df4)\n",
    "\n",
    "\n",
    "y = df4['event_action']\n",
    "X = df4.drop('event_action', axis=1)\n",
    "\n",
    "preprocessor = Pipeline(steps=[\n",
    "    ('target', FunctionTransformer(event_action)),\n",
    "    ('sampling', FunctionTransformer(sample_df3)),\n",
    "    ('ad_campaign_feature_creating', FunctionTransformer(ad_campaign)),\n",
    "    ('day_of_week', FunctionTransformer(day_of_week)),\n",
    "    ('empties', FunctionTransformer(empties)),\n",
    "    ('resolution_func', FunctionTransformer(resolution_func)),\n",
    "    ('country', FunctionTransformer(country)),\n",
    "    ('city', FunctionTransformer(city)),\n",
    "    ('encode_stuff', FunctionTransformer(encode_stuff)),\n",
    "    ('scale_stuff', FunctionTransformer(scale_stuff)),\n",
    "    ('filter_stuff', FunctionTransformer(filter_stuff)),\n",
    "    ('check_stuff', FunctionTransformer(check_stuff))\n",
    "    ])\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=400, min_samples_leaf=2, max_features='sqrt')\n",
    "\n",
    "\n",
    "high_score = 0\n",
    "\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "('preprocessor', preprocessor),\n",
    "('classifier', rf)\n",
    "])\n",
    "score = cross_val_score(pipe, X, y, cv=5, scoring='a''accuracy')#, error_score='raise')\n",
    "print(f'model: {type(model).__name__}, acc_mean: {score.mean():.4f}, acc_std: {score.std():.4f}')\n",
    "if high_score < score.mean():\n",
    "    high_score = score.mean()\n",
    "    cars_pipe = pipe\n",
    "\n",
    "else:\n",
    "    continue\n",
    "\n",
    "\n",
    "#cars_pipe.fit(X, y)\n",
    "\n",
    "\n",
    "#with open('data/cars_pipe.pkl', 'wb') as file:\n",
    "#    dill.dump({\n",
    "#        'model': cars_pipe,\n",
    "#        'metadata': {\n",
    "#            'name': 'car price prediction',\n",
    "#           'author': 'collaborative ffs by this point can i really write myself here yet?)',\n",
    "#           'version': 0.00000000000000000001,\n",
    "#            'date': datetime.now(),\n",
    "#            'type': type(cars_pipe.named_steps[\"classifier\"]).__name__,\n",
    "#           'accuracy': high_score\n",
    "#       }\n",
    "#   }, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "989dd4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2abb4648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8084ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4f461240",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/best_params_lr_10k_50_50.json', 'w') as f: json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be1b28cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country v2  start\n",
      "country v2 end\n",
      "-\n",
      "city v2  start\n",
      "city v2 end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "encode_stuff start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\2704320582.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\4057170813.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[scaled_feature_names] = scaled_features\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15072\\4057170813.py:15: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[scaled_feature_names] = scaled_features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_stuff end\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['event_action', 'device_brand', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate', 'utm_source_BHcvLfOaCWvWTykYqHVe',\n",
      "       'utm_source_BKeImrJuRDZcHiSSTdzm', 'utm_source_DnEUulZAecfGPvdtZBYS',\n",
      "       'utm_source_EvhrtRzIJnQYHziPiLzV', 'utm_source_FTAuYVNoYYxgvKMpKSLW',\n",
      "       ...\n",
      "       'utm_campaign_ydXTgkwKyFWEAJoahduP',\n",
      "       'utm_campaign_yxtFdhyijaALzWWYtzHE',\n",
      "       'utm_campaign_zDGMDYOBPSeVFZNNwoxT',\n",
      "       'utm_campaign_zPJpddwzkFqLMSYgtDqy',\n",
      "       'utm_campaign_zfwIehuEfWYdYrEZgRLo',\n",
      "       'utm_campaign_zmnpxOKDENholtspXiGy',\n",
      "       'utm_campaign_zxoiLxhuSIFrCeTLQVWZ', 'utm_campaign_nan',\n",
      "       'visit_number_scaled', 'day_of_week_scaled'],\n",
      "      dtype='object', length=376)\n",
      "-\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 10}\n",
      "Best Parameters:  {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 10}\n",
      "Best Score (ROC AUC):  0.6005072640206555\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "df4 = pd.read_csv('data/df3_10k_50n_50p.csv')\n",
    "\n",
    "\n",
    "df4 = ad_campaign(df4)\n",
    "df4 = day_of_week(df4)\n",
    "df4 = empties(df4)\n",
    "df4 = resolution_func(df4)\n",
    "df4 = country_v_2(df4)\n",
    "df4 = city_v_2(df4)\n",
    "df4 = device_brand(df4)\n",
    "df4 = encode_stuff(df4)\n",
    "df4 = scale_stuff(df4)\n",
    "df4 = filter_stuff(df4)\n",
    "\n",
    "y = df4['event_action']\n",
    "x = df4.drop('event_action', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define parameters and their possible values in a dictionary\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Create Logistic Regression classifier object\n",
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Perform Grid Search with cross-validation (e.g., using k-fold CV)\n",
    "grid_search = GridSearchCV(classifier,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='roc_auc',\n",
    "                           cv=5)\n",
    "\n",
    "# Fit the model on training data and find optimal parameters based on performance metric (default is accuracy)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get best parameters found during grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best estimator/model for predictions on test data \n",
    "y_pred = grid_search.predict(x_test)\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score (ROC AUC): \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd1a29f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/best_params_des_tree_10k_50_50.json', 'w') as f: json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "011eb1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "-\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "-\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "-\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "-\n",
      "-\n",
      "country v2  start\n",
      "country v2 end\n",
      "-\n",
      "-\n",
      "-\n",
      "city v2  start\n",
      "city v2 end\n",
      "-\n",
      "-\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "-\n",
      "-\n",
      "encode_stuff start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\1991897665.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[scaled_feature_names] = scaled_features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_stuff end\n",
      "-\n",
      "-\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n",
      "-\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "-\n",
      "-\n",
      "-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1.0, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.5863333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "df4 = pd.read_csv('data/df3_10k_50n_50p.csv')\n",
    "\n",
    "\n",
    "df4 = ad_campaign(df4)\n",
    "df4 = day_of_week(df4)\n",
    "df4 = empties(df4)\n",
    "df4 = resolution_func(df4)\n",
    "df4 = country_v_2(df4)\n",
    "df4 = city_v_2(df4)\n",
    "df4 = device_brand(df4)\n",
    "df4 = encode_stuff(df4)\n",
    "df4 = scale_stuff(df4)\n",
    "df4 = filter_stuff(df4)\n",
    "\n",
    "y = df4['event_action']\n",
    "x = df4.drop('event_action', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\n",
    "\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],                # Regularization penalty ('l1' or 'l2')\n",
    "    'C': [0.01, 0.1, 1.0],                   # Inverse regularization strength (smaller values specify stronger regularization)\n",
    "    'solver': ['liblinear', 'saga']          # Algorithm to use in optimization problem\n",
    "}\n",
    "\n",
    "# Create Logistic Regression classifier object\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Perform Grid Search with cross-validation (e.g., using k-fold CV)\n",
    "grid_search = GridSearchCV(estimator=lr_model, param_grid=param_grid)\n",
    "\n",
    "# Fit the model on training data and find optimal parameters based on performance metric (default is accuracy)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get best parameters found during grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best estimator/model for predictions on test data \n",
    "y_pred = grid_search.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a6d44992",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/best_params_rf_10k_50_50.json', 'w') as f: json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e7ee9da5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "-\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "-\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "-\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "-\n",
      "-\n",
      "country v2  start\n",
      "country v2 end\n",
      "-\n",
      "-\n",
      "-\n",
      "city v2  start\n",
      "city v2 end\n",
      "-\n",
      "-\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "-\n",
      "-\n",
      "encode_stuff start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\1991897665.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[scaled_feature_names] = scaled_features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_stuff end\n",
      "-\n",
      "-\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n",
      "-\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "-\n",
      "-\n",
      "-\n",
      "Best Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 300}\n",
      "0.5943333333333334\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv('data/df3_10k_50n_50p.csv')\n",
    "\n",
    "\n",
    "df4 = ad_campaign(df4)\n",
    "df4 = day_of_week(df4)\n",
    "df4 = empties(df4)\n",
    "df4 = resolution_func(df4)\n",
    "df4 = country_v_2(df4)\n",
    "df4 = city_v_2(df4)\n",
    "df4 = device_brand(df4)\n",
    "df4 = encode_stuff(df4)\n",
    "df4 = scale_stuff(df4)\n",
    "df4 = filter_stuff(df4)\n",
    "\n",
    "y = df4['event_action']\n",
    "x = df4.drop('event_action', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400],    # Number of trees in the forest\n",
    "    'max_depth': [None, 5, 10],          # Maximum depth of each tree\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'min_samples_split': [2, 5, 10], # Minimum number of samples required to split an internal node\n",
    "}\n",
    "\n",
    "# Create Random Forest classifier object\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Perform Grid Search with cross-validation (e.g., using k-fold CV)\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid)\n",
    "\n",
    "# Fit the model on training data and find optimal parameters based on performance metric (default is accuracy)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get best parameters found during grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best estimator/model for predictions on test data \n",
    "y_pred = grid_search.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "47e21c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200k, 70n\\x18p'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
