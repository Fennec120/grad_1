{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb2aa0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import json\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b8766df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_action(df3):\n",
    "    print('event_action start')\n",
    "    target_action = ['sub_car_claim_click', \n",
    "                 'sub_car_claim_submit_click',\n",
    "                 'sub_open_dialog_click', \n",
    "                 'sub_custom_question_submit_click', \n",
    "                 'sub_call_number_click', \n",
    "                 'sub_callback_submit_click', \n",
    "                 'sub_submit_success', \n",
    "                 'sub_car_request_submit_click'\n",
    "                ]\n",
    "\n",
    "    df3['event_action'] = df3['event_action'].apply(lambda x: 1 if x in target_action else 0)\n",
    "    \n",
    "    print( 'event_action end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d1991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_df3(df3, total_rows =  200000, neg_percent = 50, pos_percent = 50):\n",
    "    print( 'sample_df3 start')\n",
    "    df3_pos = df3[df3['event_action'] == 1].sample(int(total_rows / 100 * pos_percent))\n",
    "    df3_neg = df3[df3['event_action'] == 0].sample(int(total_rows / 100 * neg_percent))\n",
    "    df3_pos = df3_pos.reset_index()\n",
    "    df3_neg = df3_neg.reset_index()\n",
    "    df3_pos = df3_pos.drop('index', axis=1)\n",
    "    df3_neg = df3_neg.drop('index', axis=1)\n",
    "    df3 = pd.concat([df3_pos, df3_neg])\n",
    "    \n",
    "    print( 'sample_df3 end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "540c97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ad_campaign(df3):\n",
    "    print( 'ad_campaign start')\n",
    "    try:\n",
    "        with open('data/utm_c_frec_dict1.json', 'r') as f:\n",
    "            utm_c_frec_dict = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "\n",
    "        utm_c_frec_dict = {}\n",
    "        counter = 1\n",
    "        for pos in df3.utm_campaign.unique():\n",
    "            if len(df3[(df3.utm_campaign == pos) & (df3.event_action == 1)]) == 0:\n",
    "                utm_c_frec_dict[str(pos)] = 0\n",
    "            else:\n",
    "                utm_c_frec_dict[str(pos)] = round(len(df3[(df3.utm_campaign == pos) & (df3.event_action == 1)]) / len(df3[df3.utm_campaign == pos]), 5)\n",
    "\n",
    "            #print(counter)\n",
    "            counter = counter  + 1\n",
    "        with open('data/utm_c_frec_dict1.json', 'w') as f: \n",
    "            json.dump(utm_c_frec_dict, f)\n",
    "\n",
    "    finally:\n",
    "        df3['camp_succ_rate'] = df3.utm_campaign.apply(lambda x: utm_c_frec_dict[str(x)])\n",
    "    \n",
    "    print( 'ad_campaign end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40072e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_of_week(df3):\n",
    "    print( 'day_of_week start')\n",
    "    df3['new_date'] = pd.to_datetime(df3['visit_date'])\n",
    "    df3['day_of_week'] = df3.new_date.dt.dayofweek\n",
    "    \n",
    "    df3 = df3.drop('new_date', axis=1)\n",
    "    print('day_of_week end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21610a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def empties(df3):\n",
    "    print( 'empties end')\n",
    "    df3.loc[df3.utm_source.isna() == True, 'utm_source'] = 'other'\n",
    "    df3.loc[df3.utm_adcontent.isna() == True, 'utm_adcontent'] = 'Other'\n",
    "    df3.loc[df3.device_brand.isna() == True, 'device_brand'] = 'other'\n",
    "    \n",
    "    print( 'empties end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')  \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41d98c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolution_func(df3):\n",
    "    print('resolution_func start')\n",
    "    #resolution\n",
    "    bounds = []\n",
    "    df3['resolution'] = df3.device_screen_resolution.apply(lambda x:eval(x.replace('x','*')))\n",
    "    for device in df3.device_category.unique():\n",
    "        q25 = df3[df3.device_category == device].resolution.quantile(0.25)\n",
    "        q75 = df3[df3.device_category == device].resolution.quantile(0.75)\n",
    "        iqr = q75 - q25\n",
    "        bounds.append((device, q25 - 1.5 * iqr, q75 + 1.5 * iqr))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    test_list = list(df3.device_screen_resolution)\n",
    "    test_list2 = list(df3.device_category)\n",
    "\n",
    "    for i in range(len(test_list)):\n",
    "        test_list[i] = eval(test_list[i].replace('x','*'))\n",
    "\n",
    "    tst_l = list(zip(test_list2, test_list))\n",
    "\n",
    "    resolution = []\n",
    "\n",
    "    for i in range(len(tst_l)):\n",
    "        if tst_l[i][0] == bounds[0][0]:\n",
    "            resolution.append(bounds[0][0]+'_high' if tst_l[i][1] >= bounds[0][2] * 0.7 else (bounds[0][0]+'_medium' if bounds[0][2] * 0.7 > tst_l[i][1] >= bounds[0][2] * 0.1 else bounds[0][0]+'_low'))\n",
    "        elif tst_l[i][0] == bounds[1][0]:\n",
    "            resolution.append(bounds[1][0]+'_high' if tst_l[i][1] >= bounds[1][2] * 0.7 else (bounds[1][0]+'_medium' if bounds[1][2] * 0.7 > tst_l[i][1] >= bounds[1][2] * 0.1 else bounds[1][0]+'_low'))\n",
    "        elif tst_l[i][0] == bounds[2][0]:\n",
    "            resolution.append(bounds[2][0]+'_high' if tst_l[i][1] >= bounds[2][2] * 0.7 else (bounds[2][0]+'_medium' if bounds[2][2] * 0.7 > tst_l[i][1] >= bounds[2][2] * 0.1 else bounds[2][0]+'_low'))\n",
    "\n",
    "    df3['device_screen_resolution'] = resolution\n",
    "    df3 = df3.drop('resolution', axis=1)\n",
    "    \n",
    "    print('resolution_func end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    \n",
    "    return df3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f81310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolution_func_v_2(df3):\n",
    "    print('resolution_func v2 start')\n",
    "    #resolution\n",
    "    bounds = []\n",
    "    df3['device_screen_resolution'] = df3.device_screen_resolution.apply(lambda x:eval(x.replace('x','*')))\n",
    "\n",
    "    \n",
    "    print('resolution_func v2 end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    \n",
    "    return df3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23b6e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country(df3, trsh = 0.001):\n",
    "    print('country start')\n",
    "    #geo_country\n",
    "    country_list = list(df3.geo_country.unique())\n",
    "    for i in range(len(country_list)):\n",
    "        country_list[i] = ( len(df3[df3.geo_country == country_list[i]]), country_list[i])\n",
    "    country_list = sorted(country_list, reverse=True)\n",
    "\n",
    "#    trsh = 0.0005\n",
    "    df3_len = len(df3) \n",
    "    for item in country_list:\n",
    "        if item[0] / df3_len >= trsh:\n",
    "            continue\n",
    "        else:\n",
    "            df3.loc[df3.geo_country == item[1], 'geo_country'] = 'some_unimportant_country'\n",
    "    \n",
    "    print( 'country end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3af77a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_v_2(df3):\n",
    "    print('country v2  start')\n",
    "    #geo_country\n",
    "    counter = 0\n",
    "    country_list_new = dict()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        with open('data/country_list_new.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                country_list_new[my_tuple[0]] = my_tuple[1]\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "        \n",
    "        succ_total = len(df3[df3.event_action == 1])\n",
    "        country_list_success = df3[df3.event_action == 1].geo_country.value_counts().sort_values(ascending=False)\n",
    "        country_list_new = []\n",
    "        for country in country_list_success.keys():\n",
    "            country_list_new.append(f'{country}*{str(round(country_list_success[country] / succ_total, 4))}%')\n",
    "            counter += 1\n",
    "            if counter == 23:\n",
    "                break\n",
    "\n",
    "        with open('data/country_list_new.txt', 'w') as f:\n",
    "            for t in country_list_new:\n",
    "                f.write(str(t) +'\\n')\n",
    "                \n",
    "        country_list_new = dict()        \n",
    "        with open('data/country_list_new.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                country_list_new[my_tuple[0]] = my_tuple[1]                \n",
    "\n",
    "\n",
    "    finally:\n",
    "        df3['geo_country'] = df3['geo_country'].apply(lambda x: country_list_new[x] if x in country_list_new else 0.0001)\n",
    "        \n",
    "    \n",
    "\n",
    "    #print(sum(df4.isnull().sum().values))\n",
    "    #print(df4.isnull().sum())\n",
    "    print('country v2 end')    \n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')     \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82a5c836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def city(df3, trsh = 0.001):\n",
    "    print('city start')\n",
    "    #geo_city\n",
    "    city_list = []\n",
    "    df3_len = len(df3)\n",
    "    try:\n",
    "        with open('data/city_list1.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace('(', '').replace(')', '').replace(\"'\", '')\n",
    "                # split on comma and convert each element to correct type\n",
    "                tuple_elements = [int(e.strip()) if e.strip().isdigit() else e.strip() for e in line.split(',')]\n",
    "                # create tuple and add to list\n",
    "                my_tuple = tuple(tuple_elements)\n",
    "                city_list.append(my_tuple)\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "\n",
    "        city_list = list(zip(df3.geo_city.value_counts().values, df3.geo_city.value_counts().keys() ))\n",
    "        city_list = sorted(city_list, reverse=True)\n",
    "\n",
    "        with open('data/city_list1.txt', 'w') as f:\n",
    "            for t in city_list:\n",
    "                f.write(str(t) +'\\n')\n",
    "\n",
    "\n",
    "\n",
    "    finally:\n",
    "#        trsh = 0.0005\n",
    "        city_list_valid = []\n",
    "        \n",
    "        for item in city_list:\n",
    "            #print(item[1], ' - ', round(item[0] / df3_len, 4),'%' )\n",
    "            if round(item[0] / df3_len, 4) >= trsh:\n",
    "                city_list_valid.append(item[1])\n",
    "                #print('trsh == 2000 - ', item[0], item[1], round(item[0] / df3_len, 4) >= trsh, ' - appended')\n",
    "\n",
    "        df3.loc[(~df3['geo_city'].isin(city_list_valid)), 'geo_city'] = 'some_unimportant_city'\n",
    "    \n",
    "    \n",
    "\n",
    "    #print(sum(df4.isnull().sum().values))\n",
    "    #print(df4.isnull().sum())\n",
    "    print('city end')    \n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')      \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d07109ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def city_v_2(df3):\n",
    "    print('city v2  start')\n",
    "    #geo_city\n",
    "    counter = 0\n",
    "    city_list_new = dict()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        with open('data/city_list_new.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                city_list_new[my_tuple[0]] = my_tuple[1]\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "        \n",
    "        succ_total = len(df3[df3.event_action == 1])\n",
    "        city_list_success = df3[df3.event_action == 1].geo_city.value_counts().sort_values(ascending=False)\n",
    "        city_list_new = []\n",
    "        for city in city_list_success.keys():\n",
    "            city_list_new.append(f'{city}*{str(round(city_list_success[city] / succ_total, 4))}%')\n",
    "            counter += 1\n",
    "            if counter == 26:\n",
    "                break\n",
    "\n",
    "        with open('data/city_list_new.txt', 'w') as f:\n",
    "            for t in city_list_new:\n",
    "                f.write(str(t) +'\\n')\n",
    "                \n",
    "        with open('data/city_list_new.txt', 'r') as f:\n",
    "            city_list_new = dict()\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                city_list_new[my_tuple[0]] = my_tuple[1]                \n",
    "\n",
    "\n",
    "    finally:\n",
    "        \n",
    "        df3['geo_city'] = df3['geo_city'].apply(lambda x: city_list_new[x] if x in city_list_new else 0.0001)\n",
    "        \n",
    "    \n",
    "\n",
    "    #print(sum(df4.isnull().sum().values))\n",
    "    #print(df4.isnull().sum())\n",
    "    print('city v2 end')    \n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')      \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae66ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def device_brand(df3):\n",
    "    print('device_brand start')\n",
    "    #device_brand\n",
    "    counter = 0\n",
    "    device_brand_list_new = dict()\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        with open('data/device_brand_list_new.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                device_brand_list_new[my_tuple[0]] = my_tuple[1]\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "        succ_total = len(df3[df3.event_action == 1])\n",
    "        device_brand_list_success = df3[df3.event_action == 1].device_brand.value_counts().sort_values(ascending=False)\n",
    "        device_brand_list_new = []\n",
    "        for device_brand in device_brand_list_success.keys():\n",
    "            device_brand_list_new.append(f'{device_brand}*{str(round(device_brand_list_success[device_brand] / succ_total, 4))}%')\n",
    "            counter += 1\n",
    "            if counter == 23:\n",
    "                break\n",
    "\n",
    "        with open('data/device_brand_list_new.txt', 'w') as f:\n",
    "            for t in device_brand_list_new:\n",
    "                f.write(str(t) +'\\n')\n",
    "                \n",
    "        device_brand_list_new = dict()        \n",
    "        with open('data/device_brand_list_new.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace(\"%\", '')\n",
    "                tuple_elements = line.split('*')\n",
    "                my_tuple = (tuple_elements[0], eval(tuple_elements[1]))\n",
    "                device_brand_list_new[my_tuple[0]] = my_tuple[1]                \n",
    "\n",
    "\n",
    "    finally:\n",
    "        df3['device_brand'] = df3['device_brand'].apply(lambda x: device_brand_list_new[x] if x in device_brand_list_new else 0.0001)\n",
    "        \n",
    "    \n",
    "\n",
    "    #print(sum(df4.isnull().sum().values))\n",
    "    #print(df4.isnull().sum())\n",
    "    print('device_brand end')    \n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')      \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2719895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def device_brand_v_2(df3, trsh = 0.0012):\n",
    "    print('device_brand v 2 start')\n",
    "    #device_brand\n",
    "    brand_list = []\n",
    "    df3_len = len(df3)\n",
    "    \n",
    "    try:\n",
    "        with open('data/brand_list1.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                # remove newline character and parentheses\n",
    "                line = line.rstrip('\\n').replace('(', '').replace(')', '').replace(\"'\", '')\n",
    "                # split on comma and convert each element to correct type\n",
    "                tuple_elements = [int(e.strip()) if e.strip().isdigit() else e.strip() for e in line.split(',')]\n",
    "                # create tuple and add to list\n",
    "                my_tuple = tuple(tuple_elements)\n",
    "                brand_list.append(my_tuple)\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"oh.., looks like its the first time you run it - lil' bit longer then, m8. pls hold:)\")\n",
    "\n",
    "        brand_list = list(zip(df3.device_brand.value_counts().values, df3.device_brand.value_counts().keys() ))\n",
    "        brand_list = sorted(brand_list, reverse=True)\n",
    "\n",
    "        with open('data/brand_list1.txt', 'w') as f:\n",
    "            for t in brand_list:\n",
    "                f.write(str(t) +'\\n')\n",
    "\n",
    "\n",
    "\n",
    "    finally:\n",
    "#        trsh = 0.0005\n",
    "        brand_list_valid = []\n",
    "        \n",
    "        for item in brand_list:\n",
    "            #print(item[0], ' ', item[0] / df3_len,'>=', trsh, ' ', round(item[0] / df3_len, 4) >= trsh )\n",
    "            if item[0] / df3_len >= trsh:\n",
    "                brand_list_valid.append(item[1])\n",
    "                #print(len(brand_list_valid), ' ', item[0],' ',item[1] )\n",
    "\n",
    "        df3.loc[(~df3['device_brand'].isin(brand_list_valid)), 'device_brand'] = 'some_unimportant_brand'\n",
    "    \n",
    "    \n",
    "    print('device_brand v 2 end')    \n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')      \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff60f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_stuff(df3):\n",
    "    print('encode_stuff start')\n",
    "    cols_to_encode = ['utm_source', \n",
    "                      'utm_medium', \n",
    "                      'utm_adcontent', \n",
    "                      'device_brand', \n",
    "                      'device_category', \n",
    "                      'device_screen_resolution', \n",
    "                      'device_browser',\n",
    "                      'utm_campaign',\n",
    "                      'geo_country',\n",
    "                      'geo_city'\n",
    "                     ]\n",
    "    \n",
    "    #encoding\n",
    "    encoded_features = pd.DataFrame()\n",
    "\n",
    "    for col in cols_to_encode:\n",
    "\n",
    "        pre_encoded_df3 = df3[[col]]\n",
    "        encoder = OneHotEncoder(categories='auto', handle_unknown='ignore', sparse=False)\n",
    "        encoded_array = encoder.fit_transform(pre_encoded_df3)\n",
    "        #feature_names = [f'{col}_{name}' for name in encoder.get_feature_names_out()]\n",
    "        feature_names = encoder.get_feature_names_out()\n",
    "        encoded_df3 = pd.DataFrame(encoded_array, columns=feature_names)\n",
    "\n",
    "        #if len(encoded_features) == 0:\n",
    "        #    encoded_features = encoded_df3.copy()\n",
    "        #else:\n",
    "        #    encoded_features[feature_names] = encoded_df3.values\n",
    "        \n",
    "        df3[feature_names] = encoded_df3.values\n",
    "    #print(encoded_features.isnull().sum())\n",
    "\n",
    "    #df3 = df3.join(encoded_features)\n",
    "    #print(df3.isnull().sum())\n",
    "    df3 = df3.drop(cols_to_encode, axis=1)\n",
    "    print( 'encode_stuff end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')  \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "439622ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_stuff(df3):\n",
    "    #scaling\n",
    "    print('scale_stuff start')\n",
    "    cols_to_scale = ['visit_number',\n",
    "                     'day_of_week'\n",
    "                    # ,'device_screen_resolution'\n",
    "                    ]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(df3.loc[:,cols_to_scale])\n",
    "    scaled_feature_names = [f'{name}_scaled' for name in scaler.get_feature_names_out()]\n",
    "    #scaler.get_feature_names_out()\n",
    "\n",
    "    #scaled_df = pd.DataFrame(scaled_features, columns=scaled_feature_names)\n",
    "    df3[scaled_feature_names] = scaled_features\n",
    "    #print(scaled_df.shape, scaled_df.columns)\n",
    "    #print(scaled_df.isnull().sum())\n",
    "\n",
    "    #df3['scaled_feature_names'] = scaled_df\n",
    "    #print(df3.shape, df3.columns)\n",
    "    df3 = df3.drop(cols_to_scale, axis=1)\n",
    "    \n",
    "    #print(df3.isnull().sum())\n",
    "    #print(len(df3.columns), df3.columns)\n",
    "    print('scale_stuff end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')  \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2a7612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stuff(df3):\n",
    "    #pre-existing list of columns\n",
    "    print('filter_stuff start')\n",
    "    cols_to_drop = [\n",
    "        'session_id',\n",
    "        'hit_date',\n",
    "        'hit_time',\n",
    "        'hit_number',\n",
    "        'hit_type',\n",
    "        'hit_referer',\n",
    "        'hit_page_path',\n",
    "        'event_category',\n",
    "        'event_label',\n",
    "        'event_value',\n",
    "        'client_id',\n",
    "        #'new_date',\n",
    "        'visit_date',\n",
    "        'utm_keyword',\n",
    "        'device_os',\n",
    "        'device_model',\n",
    "        'visit_time'\n",
    "    ]\n",
    "    \n",
    "    cols_to_encode = [\n",
    "        'utm_source',\n",
    "        'utm_medium', \n",
    "        'utm_adcontent',\n",
    "        'device_brand', \n",
    "        'device_category', \n",
    "        'device_screen_resolution',\n",
    "        'device_browser',\n",
    "        'utm_campaign',\n",
    "        'geo_country',\n",
    "        'geo_city'\n",
    "    ]\n",
    "    #dropping\n",
    "    #cols_to_drop = []\n",
    "    #for col in df_columns:\n",
    "    #    cols_to_drop.append(str(col))\n",
    "    #cols_to_drop = cols_to_drop + ['client_id','new_date', 'visit_date', 'utm_keyword', 'device_os', 'device_model', 'visit_time']    \n",
    "    \n",
    "    df3 = df3.drop(cols_to_drop, axis=1)\n",
    "    #df3 = df3.drop(cols_to_encode, axis=1)\n",
    "    \n",
    "    try:\n",
    "        df3 = df3.drop('Unnamed: 0', axis=1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        df3 = df3.drop('Unnamed: 0.1', axis=1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        df3 = df3.drop('Unnamed: 0.2', axis=1)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    print('filter_stuff end')\n",
    "    #print(sum(df3.isnull().sum().values))\n",
    "    #print(df3.isnull().sum())\n",
    "    print(df3.columns)\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "859940a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stuff(df3):\n",
    "    #checking\n",
    "    print('check_stuff start')\n",
    "    counter = 0\n",
    "    for feature in df3.columns:\n",
    "        if df3[feature].dtype != 'O':\n",
    "            #print(feature, ' - ', df3[feature].dtype)\n",
    "            counter += 1\n",
    "        else:\n",
    "            print(feature)\n",
    "    print(counter == len(df3.columns))\n",
    "\n",
    "\n",
    "    #checking 2\n",
    "    counter = 0\n",
    "    for feature in df3.columns:\n",
    "        if len(df3[df3[str(feature)].isna() == True]) != 0:\n",
    "            print(feature, ' - ', len(df3[df3[str(feature)].isna() == True]))\n",
    "            counter += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if counter == 0:\n",
    "        print('vse zaebis\", pustukh fi4ei net')    \n",
    "    \n",
    "    \n",
    "    print('check_stuff end')\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-') \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "814b693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stuff_2(df3):\n",
    "    #checking\n",
    "    print('check_stuff_2 start')\n",
    "\n",
    "    counter = 0\n",
    "    for feature in df3.columns:\n",
    "        if df3[feature].dtype != 'O':\n",
    "            #print(feature, ' - ', df3[feature].dtype)\n",
    "            counter += 1\n",
    "        else:\n",
    "            print(feature)\n",
    "    print(counter == len(df3.columns))\n",
    "\n",
    "\n",
    "    #checking 2\n",
    "    empty_features = False\n",
    "    if sum(df3.isnull().sum()) != 0:\n",
    "        print(df3.isnull().sum())\n",
    "        empty_features = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if empty_features == False:\n",
    "        print('vse zaebis\", pustukh fi4ei net') \n",
    "    #print(len(df3.isnull().sum()))\n",
    "    print(df3.shape,  'check_stuff_2 end') #df3.shape,\n",
    "    print('-')      \n",
    "    #print('-')      \n",
    "    #print('-')     \n",
    "    \n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b018e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stuff_3(df3):\n",
    "    for column in df3.columns:\n",
    "        print(column)\n",
    "        print(df3[column].value_counts())\n",
    "    print(len(df3.columns))\n",
    "    print(' - ')\n",
    "    \n",
    "    return df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a48f726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_stuff(df3):\n",
    "    y = df3['event_action']\n",
    "    \n",
    "    df3 = df3.drop('event_action', axis=1)\n",
    "    print(df3.columns)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df3,y, test_size=0.3)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=400, min_samples_leaf=2, max_features='sqrt')\n",
    "    rf.fit(x_train, y_train)\n",
    "    \n",
    "    predicted_train = rf.predict(x_train)\n",
    "    predicted_test = rf.predict(x_test)\n",
    "    \n",
    "    #print(df3.shape, ' - shape', ' function - ')\n",
    "    \n",
    "    \n",
    "    print('train acc score - ',accuracy_score(y_train, predicted_train))\n",
    "    print('test acc score - ', accuracy_score(y_test, predicted_test))\n",
    "\n",
    "    print('train roc score - ',roc_auc_score(y_train, rf.predict_proba(x_train)[:,1]))\n",
    "    print('test roc score - ',roc_auc_score(y_test, rf.predict_proba(x_test)[:,1]))\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c73138c",
   "metadata": {},
   "source": [
    "with open('models/rf_model.pkl', 'wb') as file:\n",
    "    dill.dump(rf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d65451",
   "metadata": {},
   "source": [
    "## function declarations end here. its wildlands after that...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c058ea",
   "metadata": {},
   "source": [
    "df = pd.read_csv('data/ga_hits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbfd6d3",
   "metadata": {},
   "source": [
    "df2 = pd.read_csv('data/ga_sessions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78c3c69",
   "metadata": {},
   "source": [
    "df3 = pd.merge(df, df2, on='session_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821eb757",
   "metadata": {},
   "source": [
    "df3 = event_action(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b9e1b8",
   "metadata": {},
   "source": [
    "df4= sample_df3(df3, 1000000, 90, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80fb891",
   "metadata": {},
   "source": [
    "df4.to_csv('data/df3_1kk_90n_10p.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "301c1097",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = [\n",
    "    [0.6375, 'ad_camp V, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
    "    [0.6375, 'ad_camp X, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
    "    [0.6375, ', ad_camp X, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
    "    [0.6482, ', ad_camp V, resol v1 X, ctry v1 V, ct v1 V, brand v1 V'],\n",
    "    [0.6504, ', ad_camp X, resol v1 X, ctry v1 X, ct v1 X, brand v1 X'],\n",
    "    [0.6409, ', ad_camp X, resol v1 V, ctry v1 X, ct v1 X, brand v1 X'],\n",
    "    [0.6396, ', ad_camp X, resol v2 V, ctry v1 X, ct v1 X, brand v1 X'],\n",
    "    [0.6502, ', ad_camp X, resol v2 X, ctry v1 V, ct v1 X, brand v1 X'],\n",
    "    [0.6503, ', ad_camp X, resol v2 X, ctry v2 V, ct v1 X, brand v1 X'],\n",
    "    [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v1 X, brand v1 X'],\n",
    "    [0.6498, ', ad_camp X, resol v2 X, ctry v2 X, ct v1 V, brand v1 X'],\n",
    "    [0.6389, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 V, brand v1 X'],\n",
    "    [0.649, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v1 V'],\n",
    "    [0.6503, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
    "    [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
    "    [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "602a34c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_single_fit = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6250b842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['visit_number', 'utm_source', 'utm_medium', 'utm_campaign',\n",
      "       'utm_adcontent', 'device_category', 'device_brand',\n",
      "       'device_screen_resolution', 'device_browser', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "visit_number\n",
      "1      95093\n",
      "2      19292\n",
      "3       7138\n",
      "4       4440\n",
      "5       2510\n",
      "       ...  \n",
      "418        1\n",
      "200        1\n",
      "154        1\n",
      "170        1\n",
      "513        1\n",
      "Name: visit_number, Length: 386, dtype: int64\n",
      "utm_source\n",
      "ZpYIoDJMcFzVoPFsHGJL    44779\n",
      "fDLlAcSmythWSCVMvqvL    28400\n",
      "kjsLglQLzykiRbcDiGcD    17318\n",
      "bByPQxmDaMXgpHeypKSM    14269\n",
      "BHcvLfOaCWvWTykYqHVe    11191\n",
      "                        ...  \n",
      "JcVHXwVSrnfIuOMMEkrJ        1\n",
      "hJvOVTMdhkqIBqjVrsOL        1\n",
      "CXgqTLNTvvxWUWoOfjNF        1\n",
      "gaFBXpMUrvHAilRkjPSS        1\n",
      "IijdaxEpmKKxJWOGIWwC        1\n",
      "Name: utm_source, Length: 137, dtype: int64\n",
      "utm_medium\n",
      "banner             42344\n",
      "cpc                28998\n",
      "(none)             28400\n",
      "referral           20289\n",
      "cpm                 6645\n",
      "organic             5797\n",
      "push                2419\n",
      "email               1649\n",
      "blogger_channel      684\n",
      "stories              540\n",
      "smartbanner          439\n",
      "cpa                  348\n",
      "cpv                  231\n",
      "tg                   215\n",
      "blogger_stories      197\n",
      "smm                  179\n",
      "post                 128\n",
      "outlook              100\n",
      "(not set)             94\n",
      "clicks                89\n",
      "link                  55\n",
      "landing               40\n",
      "app                   37\n",
      "sms                   31\n",
      "info_text             15\n",
      "blogger_header        11\n",
      "CPM                    5\n",
      "medium                 5\n",
      "partner                4\n",
      "fb_smm                 3\n",
      "static                 2\n",
      "article                2\n",
      "social                 1\n",
      "google_cpc             1\n",
      "vk_smm                 1\n",
      "yandex_cpc             1\n",
      "dom_click              1\n",
      "Name: utm_medium, dtype: int64\n",
      "utm_campaign\n",
      "LTuZkdKfxRGVceoWkVyg    48823\n",
      "LEoPHuyFvzoNfnzGgfcd    26602\n",
      "gecBYcKZCPMcVYdSSzKP    11569\n",
      "FTjNLDyTrXaWYgZymFkV     6533\n",
      "sbJRYgVfvcnqKJNDDYIr     1694\n",
      "                        ...  \n",
      "vRnpYItqvTLeHOrhMWuq        1\n",
      "JkhCpeDGCtTwhwqWLywv        1\n",
      "kKtSojgDlfomwthXhPjz        1\n",
      "NTQAiqAhSTbkRRmxVKoQ        1\n",
      "MHdHrBKQwbDaRalwnlJq        1\n",
      "Name: utm_campaign, Length: 273, dtype: int64\n",
      "utm_adcontent\n",
      "JNHcPlZPxEMWDnRiyoBf    89510\n",
      "Other                   25969\n",
      "vCIpmpaGBnIQhyYNkXqp    13357\n",
      "xhoenQgDQsgfEPYNPwKO     3012\n",
      "PkybGvWbaqORmxjNunqZ     2325\n",
      "                        ...  \n",
      "JJRVNKFvKSInZxhrcjHK        1\n",
      "qalfRbxdosSpdWRPPVpn        1\n",
      "UGlXItXGltYEohQihUoy        1\n",
      "EsbpyHMkFkavykEeYhch        1\n",
      "SlNhGpjMhrdNXGxbGvDU        1\n",
      "Name: utm_adcontent, Length: 150, dtype: int64\n",
      "device_category\n",
      "mobile     103844\n",
      "desktop     34998\n",
      "tablet       1158\n",
      "Name: device_category, dtype: int64\n",
      "device_brand\n",
      "0.0001    140000\n",
      "Name: device_brand, dtype: int64\n",
      "device_screen_resolution\n",
      "mobile_medium     71341\n",
      "mobile_high       32503\n",
      "desktop_medium    32144\n",
      "desktop_high       2714\n",
      "tablet_medium      1090\n",
      "desktop_low         140\n",
      "tablet_high          66\n",
      "tablet_low            2\n",
      "Name: device_screen_resolution, dtype: int64\n",
      "device_browser\n",
      "Chrome                              75425\n",
      "Safari                              37094\n",
      "YaBrowser                           11446\n",
      "Safari (in-app)                      4284\n",
      "Android Webview                      4108\n",
      "Samsung Internet                     2657\n",
      "Firefox                              1799\n",
      "Edge                                 1599\n",
      "Opera                                1498\n",
      "UC Browser                             67\n",
      "Maxthon                                 4\n",
      "Android Runtime                         4\n",
      "Mozilla Compatible Agent                4\n",
      "Puffin                                  3\n",
      "com.vk.vkclient                         2\n",
      "[FBAN                                   1\n",
      "Internet Explorer                       1\n",
      "Instagram 209.0.0.21.119 Android        1\n",
      "Instagram 208.0.0.32.135 Android        1\n",
      "Amazon Silk                             1\n",
      "MRCHROME                                1\n",
      "Name: device_browser, dtype: int64\n",
      "geo_country\n",
      "Russia                      136849\n",
      "some_unimportant_country      1594\n",
      "Ukraine                        586\n",
      "United States                  251\n",
      "Germany                        209\n",
      "Belarus                        200\n",
      "Kazakhstan                     158\n",
      "Turkey                         153\n",
      "Name: geo_country, dtype: int64\n",
      "geo_city\n",
      "Moscow                   65363\n",
      "Saint Petersburg         19935\n",
      "some_unimportant_city     5081\n",
      "Kazan                     2933\n",
      "Krasnodar                 2740\n",
      "                         ...  \n",
      "Poronaysk                    1\n",
      "Walldorf                     1\n",
      "Geldern                      1\n",
      "Cologne                      1\n",
      "Zaporizhzhia                 1\n",
      "Name: geo_city, Length: 611, dtype: int64\n",
      "camp_succ_rate\n",
      "0    140000\n",
      "Name: camp_succ_rate, dtype: int64\n",
      "12\n",
      " - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['visit_number', 'utm_source', 'utm_medium', 'utm_campaign',\n",
      "       'utm_adcontent', 'device_category', 'device_brand',\n",
      "       'device_screen_resolution', 'device_browser', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "visit_number\n",
      "1      101892\n",
      "2       20671\n",
      "3        7574\n",
      "4        4776\n",
      "5        2682\n",
      "        ...  \n",
      "481         1\n",
      "537         1\n",
      "225         1\n",
      "328         1\n",
      "230         1\n",
      "Name: visit_number, Length: 388, dtype: int64\n",
      "utm_source\n",
      "ZpYIoDJMcFzVoPFsHGJL    48113\n",
      "fDLlAcSmythWSCVMvqvL    30368\n",
      "kjsLglQLzykiRbcDiGcD    18360\n",
      "bByPQxmDaMXgpHeypKSM    15340\n",
      "BHcvLfOaCWvWTykYqHVe    12073\n",
      "                        ...  \n",
      "pcvPxfVFaAmhwFmvIeYd        1\n",
      "uqttCIyjtWRiZIgdaLzw        1\n",
      "IFkbipeRquzIeCjUtxny        1\n",
      "DfoBrvtzFbohFKcUrmMV        1\n",
      "MSMDmOPoIWuXYqCanGOT        1\n",
      "Name: utm_source, Length: 145, dtype: int64\n",
      "utm_medium\n",
      "banner             45479\n",
      "cpc                31159\n",
      "(none)             30368\n",
      "referral           21736\n",
      "cpm                 7138\n",
      "organic             6043\n",
      "push                2619\n",
      "email               1769\n",
      "blogger_channel      712\n",
      "stories              558\n",
      "smartbanner          481\n",
      "cpa                  390\n",
      "cpv                  232\n",
      "tg                   218\n",
      "blogger_stories      215\n",
      "smm                  195\n",
      "post                 144\n",
      "(not set)            112\n",
      "outlook              107\n",
      "clicks               100\n",
      "link                  63\n",
      "app                   40\n",
      "landing               34\n",
      "sms                   34\n",
      "info_text             16\n",
      "blogger_header        14\n",
      "partner                6\n",
      "CPM                    4\n",
      "fb_smm                 3\n",
      "medium                 3\n",
      "static                 2\n",
      "article                2\n",
      "yandex_cpc             1\n",
      "social                 1\n",
      "dom_click              1\n",
      "vk_smm                 1\n",
      "Name: utm_medium, dtype: int64\n",
      "utm_campaign\n",
      "LTuZkdKfxRGVceoWkVyg    52137\n",
      "LEoPHuyFvzoNfnzGgfcd    28519\n",
      "gecBYcKZCPMcVYdSSzKP    12486\n",
      "FTjNLDyTrXaWYgZymFkV     6982\n",
      "sbJRYgVfvcnqKJNDDYIr     1862\n",
      "                        ...  \n",
      "jUuukNIbGoOYdGYzBthG        1\n",
      "BHqsCPwtnpaQSryaVXya        1\n",
      "xEbpvlxtkygYVvQKMatl        1\n",
      "CqFuKxSYgtGbcafqJwij        1\n",
      "IOQFgDqnjywyYyRldWoF        1\n",
      "Name: utm_campaign, Length: 287, dtype: int64\n",
      "utm_adcontent\n",
      "JNHcPlZPxEMWDnRiyoBf    95950\n",
      "Other                   27867\n",
      "vCIpmpaGBnIQhyYNkXqp    14257\n",
      "xhoenQgDQsgfEPYNPwKO     3236\n",
      "PkybGvWbaqORmxjNunqZ     2477\n",
      "                        ...  \n",
      "KyMReDIldRzztqfDbJqp        1\n",
      "AREbWGOhRGJXAffGqZTc        1\n",
      "uybLnTwkttHEjPnVuTWA        1\n",
      "MGatbcZxAUUBKBwPWOkg        1\n",
      "QjKPYbVQrUvYVYVhWTUK        1\n",
      "Name: utm_adcontent, Length: 153, dtype: int64\n",
      "device_category\n",
      "mobile     111435\n",
      "desktop     37307\n",
      "tablet       1258\n",
      "Name: device_category, dtype: int64\n",
      "device_brand\n",
      "0.0001    150000\n",
      "Name: device_brand, dtype: int64\n",
      "device_screen_resolution\n",
      "mobile_medium     76606\n",
      "mobile_high       34829\n",
      "desktop_medium    34308\n",
      "desktop_high       2833\n",
      "tablet_medium      1184\n",
      "desktop_low         166\n",
      "tablet_high          72\n",
      "tablet_low            2\n",
      "Name: device_screen_resolution, dtype: int64\n",
      "device_browser\n",
      "Chrome                              80675\n",
      "Safari                              39791\n",
      "YaBrowser                           12236\n",
      "Safari (in-app)                      4580\n",
      "Android Webview                      4407\n",
      "Samsung Internet                     2852\n",
      "Firefox                              1971\n",
      "Edge                                 1713\n",
      "Opera                                1677\n",
      "UC Browser                             72\n",
      "Android Runtime                         6\n",
      "Maxthon                                 5\n",
      "Mozilla Compatible Agent                3\n",
      "Internet Explorer                       2\n",
      "Puffin                                  2\n",
      "com.vk.vkclient                         2\n",
      "[FBAN                                   1\n",
      "Instagram 208.0.0.32.135 Android        1\n",
      "Instagram 216.0.0.12.135                1\n",
      "MRCHROME                                1\n",
      "Android Browser                         1\n",
      "Instagram 209.0.0.21.119 Android        1\n",
      "Name: device_browser, dtype: int64\n",
      "geo_country\n",
      "Russia                      146633\n",
      "some_unimportant_country      1724\n",
      "Ukraine                        618\n",
      "United States                  262\n",
      "Germany                        225\n",
      "Belarus                        216\n",
      "Kazakhstan                     166\n",
      "Turkey                         156\n",
      "Name: geo_country, dtype: int64\n",
      "geo_city\n",
      "Moscow                   69991\n",
      "Saint Petersburg         21280\n",
      "some_unimportant_city     5383\n",
      "Kazan                     3144\n",
      "Krasnodar                 3002\n",
      "                         ...  \n",
      "Wermelskirchen               1\n",
      "Beni-Mellal                  1\n",
      "Budva                        1\n",
      "Seville                      1\n",
      "Kryvyi Rih                   1\n",
      "Name: geo_city, Length: 608, dtype: int64\n",
      "camp_succ_rate\n",
      "0    150000\n",
      "Name: camp_succ_rate, dtype: int64\n",
      "12\n",
      " - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['visit_number', 'utm_source', 'utm_medium', 'utm_campaign',\n",
      "       'utm_adcontent', 'device_category', 'device_brand',\n",
      "       'device_screen_resolution', 'device_browser', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "visit_number\n",
      "1      33948\n",
      "2       6865\n",
      "3       2604\n",
      "4       1546\n",
      "5        940\n",
      "       ...  \n",
      "413        1\n",
      "338        1\n",
      "437        1\n",
      "170        1\n",
      "228        1\n",
      "Name: visit_number, Length: 293, dtype: int64\n",
      "utm_source\n",
      "ZpYIoDJMcFzVoPFsHGJL    15996\n",
      "fDLlAcSmythWSCVMvqvL    10083\n",
      "kjsLglQLzykiRbcDiGcD     6202\n",
      "bByPQxmDaMXgpHeypKSM     5059\n",
      "BHcvLfOaCWvWTykYqHVe     3981\n",
      "                        ...  \n",
      "xEbgdGZJlqXAaRmeJQdW        1\n",
      "NTQAiqAhSTbkRRmxVKoQ        1\n",
      "LkGnzVRewoaOHnMCwadT        1\n",
      "JcVHXwVSrnfIuOMMEkrJ        1\n",
      "SbQJoCCWibshtEmQeuVM        1\n",
      "Name: utm_source, Length: 109, dtype: int64\n",
      "utm_medium\n",
      "banner             15115\n",
      "cpc                10356\n",
      "(none)             10083\n",
      "referral            7254\n",
      "cpm                 2348\n",
      "organic             2106\n",
      "push                 844\n",
      "email                641\n",
      "blogger_channel      259\n",
      "stories              190\n",
      "smartbanner          176\n",
      "cpa                  127\n",
      "cpv                   93\n",
      "blogger_stories       65\n",
      "tg                    62\n",
      "smm                   55\n",
      "post                  49\n",
      "outlook               32\n",
      "clicks                31\n",
      "link                  23\n",
      "(not set)             22\n",
      "app                   18\n",
      "landing               18\n",
      "sms                   14\n",
      "info_text              5\n",
      "blogger_header         5\n",
      "medium                 4\n",
      "CPM                    2\n",
      "fb_smm                 2\n",
      "google_cpc             1\n",
      "Name: utm_medium, dtype: int64\n",
      "utm_campaign\n",
      "LTuZkdKfxRGVceoWkVyg    17423\n",
      "LEoPHuyFvzoNfnzGgfcd     9519\n",
      "gecBYcKZCPMcVYdSSzKP     4079\n",
      "FTjNLDyTrXaWYgZymFkV     2328\n",
      "sbJRYgVfvcnqKJNDDYIr      598\n",
      "                        ...  \n",
      "WjjvSVHOFOxHwlNJQcyk        1\n",
      "eGPqcrOyAyMvXPpbVMLD        1\n",
      "klTrhUaShgnjIbaPmqjc        1\n",
      "gNOygIoePsujXLVGYNZi        1\n",
      "NCOBaqbWTRpdTXezdNNg        1\n",
      "Name: utm_campaign, Length: 236, dtype: int64\n",
      "utm_adcontent\n",
      "JNHcPlZPxEMWDnRiyoBf    31863\n",
      "Other                    9290\n",
      "vCIpmpaGBnIQhyYNkXqp     4770\n",
      "xhoenQgDQsgfEPYNPwKO     1052\n",
      "PkybGvWbaqORmxjNunqZ      829\n",
      "                        ...  \n",
      "nSnusQfrtOmmGJFrHBZf        1\n",
      "JKvVAMEfeoNMSMFzAAfE        1\n",
      "tCLxWkPNVjjdHjETjiXL        1\n",
      "WaWpHWszYFymgCSbpGVL        1\n",
      "vqphquiMFsuWRdetWcjn        1\n",
      "Name: utm_adcontent, Length: 116, dtype: int64\n",
      "device_category\n",
      "mobile     37058\n",
      "desktop    12521\n",
      "tablet       421\n",
      "Name: device_category, dtype: int64\n",
      "device_brand\n",
      "0.0001    50000\n",
      "Name: device_brand, dtype: int64\n",
      "device_screen_resolution\n",
      "mobile_medium     25574\n",
      "mobile_high       11484\n",
      "desktop_medium    11476\n",
      "desktop_high       1006\n",
      "tablet_medium       337\n",
      "tablet_high          84\n",
      "desktop_low          39\n",
      "Name: device_screen_resolution, dtype: int64\n",
      "device_browser\n",
      "Chrome                      27056\n",
      "Safari                      13148\n",
      "YaBrowser                    4181\n",
      "Safari (in-app)              1471\n",
      "Android Webview              1466\n",
      "Samsung Internet              938\n",
      "Firefox                       630\n",
      "Edge                          574\n",
      "Opera                         505\n",
      "UC Browser                     25\n",
      "Puffin                          2\n",
      "Mozilla Compatible Agent        2\n",
      "Amazon Silk                     1\n",
      "Android Runtime                 1\n",
      "Name: device_browser, dtype: int64\n",
      "geo_country\n",
      "Russia                      48878\n",
      "some_unimportant_country      622\n",
      "Ukraine                       215\n",
      "United States                  91\n",
      "Belarus                        69\n",
      "Germany                        68\n",
      "Turkey                         57\n",
      "Name: geo_country, dtype: int64\n",
      "geo_city\n",
      "Moscow                   23340\n",
      "Saint Petersburg          7198\n",
      "some_unimportant_city     1767\n",
      "Kazan                     1022\n",
      "Krasnodar                  988\n",
      "                         ...  \n",
      "Dallas                       1\n",
      "Varadero                     1\n",
      "Kropotkin                    1\n",
      "Hanover                      1\n",
      "Altoona                      1\n",
      "Name: geo_city, Length: 582, dtype: int64\n",
      "camp_succ_rate\n",
      "0    50000\n",
      "Name: camp_succ_rate, dtype: int64\n",
      "12\n",
      " - \n",
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['visit_number', 'utm_source', 'utm_medium', 'utm_campaign',\n",
      "       'utm_adcontent', 'device_category', 'device_brand',\n",
      "       'device_screen_resolution', 'device_browser', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "visit_number\n",
      "1      101846\n",
      "2       20643\n",
      "3        7615\n",
      "4        4719\n",
      "5        2718\n",
      "        ...  \n",
      "292         1\n",
      "412         1\n",
      "481         1\n",
      "204         1\n",
      "230         1\n",
      "Name: visit_number, Length: 385, dtype: int64\n",
      "utm_source\n",
      "ZpYIoDJMcFzVoPFsHGJL    48056\n",
      "fDLlAcSmythWSCVMvqvL    30358\n",
      "kjsLglQLzykiRbcDiGcD    18506\n",
      "bByPQxmDaMXgpHeypKSM    15273\n",
      "BHcvLfOaCWvWTykYqHVe    12004\n",
      "                        ...  \n",
      "zhqxcsahQYAzJvRzebNp        1\n",
      "YDhRPNErghvKCwWcfSFO        1\n",
      "JcVHXwVSrnfIuOMMEkrJ        1\n",
      "yxJKymlSGVuKIPTxbysx        1\n",
      "MSMDmOPoIWuXYqCanGOT        1\n",
      "Name: utm_source, Length: 140, dtype: int64\n",
      "utm_medium\n",
      "banner             45425\n",
      "cpc                31124\n",
      "(none)             30358\n",
      "referral           21739\n",
      "cpm                 7100\n",
      "organic             6138\n",
      "push                2571\n",
      "email               1837\n",
      "blogger_channel      730\n",
      "stories              560\n",
      "smartbanner          510\n",
      "cpa                  372\n",
      "cpv                  253\n",
      "blogger_stories      217\n",
      "tg                   207\n",
      "smm                  171\n",
      "post                 142\n",
      "(not set)            108\n",
      "outlook              107\n",
      "clicks               100\n",
      "link                  58\n",
      "app                   42\n",
      "sms                   39\n",
      "landing               37\n",
      "info_text             16\n",
      "blogger_header        15\n",
      "medium                 6\n",
      "CPM                    5\n",
      "fb_smm                 4\n",
      "partner                3\n",
      "social                 1\n",
      "yandex_cpc             1\n",
      "static                 1\n",
      "google_cpc             1\n",
      "vk_smm                 1\n",
      "article                1\n",
      "Name: utm_medium, dtype: int64\n",
      "utm_campaign\n",
      "LTuZkdKfxRGVceoWkVyg    52268\n",
      "LEoPHuyFvzoNfnzGgfcd    28584\n",
      "gecBYcKZCPMcVYdSSzKP    12375\n",
      "FTjNLDyTrXaWYgZymFkV     6960\n",
      "sbJRYgVfvcnqKJNDDYIr     1803\n",
      "                        ...  \n",
      "kLcjCnTSVYUxLVdvWAbF        1\n",
      "aCaBoYaQJPVffhjBQnut        1\n",
      "VfhMXDwtKbBKHfyoCvdn        1\n",
      "xEbpvlxtkygYVvQKMatl        1\n",
      "SoCnOWJkUDarGowlGDnC        1\n",
      "Name: utm_campaign, Length: 282, dtype: int64\n",
      "utm_adcontent\n",
      "JNHcPlZPxEMWDnRiyoBf    95846\n",
      "Other                   27808\n",
      "vCIpmpaGBnIQhyYNkXqp    14309\n",
      "xhoenQgDQsgfEPYNPwKO     3205\n",
      "PkybGvWbaqORmxjNunqZ     2456\n",
      "                        ...  \n",
      "LrfKeexYNjGjsqQVSCdi        1\n",
      "MGatbcZxAUUBKBwPWOkg        1\n",
      "TxYGPZoJvwkuNUkpHgpP        1\n",
      "nSnusQfrtOmmGJFrHBZf        1\n",
      "QjKPYbVQrUvYVYVhWTUK        1\n",
      "Name: utm_adcontent, Length: 152, dtype: int64\n",
      "device_category\n",
      "mobile     111270\n",
      "desktop     37449\n",
      "tablet       1281\n",
      "Name: device_category, dtype: int64\n",
      "device_brand\n",
      "0.0001    150000\n",
      "Name: device_brand, dtype: int64\n",
      "device_screen_resolution\n",
      "mobile_medium     76674\n",
      "mobile_high       34596\n",
      "desktop_medium    34399\n",
      "desktop_high       2895\n",
      "tablet_medium      1206\n",
      "desktop_low         155\n",
      "tablet_high          74\n",
      "tablet_low            1\n",
      "Name: device_screen_resolution, dtype: int64\n",
      "device_browser\n",
      "Chrome                              80834\n",
      "Safari                              39756\n",
      "YaBrowser                           12367\n",
      "Safari (in-app)                      4485\n",
      "Android Webview                      4398\n",
      "Samsung Internet                     2825\n",
      "Firefox                              1917\n",
      "Edge                                 1692\n",
      "Opera                                1632\n",
      "UC Browser                             77\n",
      "Mozilla Compatible Agent                4\n",
      "Android Runtime                         4\n",
      "Puffin                                  3\n",
      "Internet Explorer                       2\n",
      "Amazon Silk                             1\n",
      "Android Browser                         1\n",
      "Instagram 209.0.0.21.119 Android        1\n",
      "Maxthon                                 1\n",
      "Name: device_browser, dtype: int64\n",
      "geo_country\n",
      "Russia                      146625\n",
      "some_unimportant_country      1738\n",
      "Ukraine                        628\n",
      "United States                  267\n",
      "Belarus                        214\n",
      "Germany                        211\n",
      "Turkey                         161\n",
      "Kazakhstan                     156\n",
      "Name: geo_country, dtype: int64\n",
      "geo_city\n",
      "Moscow                   70049\n",
      "Saint Petersburg         21381\n",
      "some_unimportant_city     5429\n",
      "Kazan                     3124\n",
      "Krasnodar                 3006\n",
      "                         ...  \n",
      "Doha                         1\n",
      "Birobidzhan                  1\n",
      "Bobrovskiy                   1\n",
      "Geldern                      1\n",
      "Kryvyi Rih                   1\n",
      "Name: geo_city, Length: 619, dtype: int64\n",
      "camp_succ_rate\n",
      "0    150000\n",
      "Name: camp_succ_rate, dtype: int64\n",
      "12\n",
      " - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['visit_number', 'utm_source', 'utm_medium', 'utm_campaign',\n",
      "       'utm_adcontent', 'device_category', 'device_brand',\n",
      "       'device_screen_resolution', 'device_browser', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "visit_number\n",
      "1      33994\n",
      "2       6893\n",
      "3       2563\n",
      "4       1603\n",
      "5        904\n",
      "       ...  \n",
      "180        1\n",
      "288        1\n",
      "420        1\n",
      "129        1\n",
      "173        1\n",
      "Name: visit_number, Length: 298, dtype: int64\n",
      "utm_source\n",
      "ZpYIoDJMcFzVoPFsHGJL    16053\n",
      "fDLlAcSmythWSCVMvqvL    10093\n",
      "kjsLglQLzykiRbcDiGcD     6056\n",
      "bByPQxmDaMXgpHeypKSM     5126\n",
      "BHcvLfOaCWvWTykYqHVe     4050\n",
      "                        ...  \n",
      "eYRDXZIocNyHVjEHzesr        1\n",
      "NCOBaqbWTRpdTXezdNNg        1\n",
      "TkzfDRIBKntFdWkzUePd        1\n",
      "pcvPxfVFaAmhwFmvIeYd        1\n",
      "YDhRPNErghvKCwWcfSFO        1\n",
      "Name: utm_source, Length: 116, dtype: int64\n",
      "utm_medium\n",
      "banner             15169\n",
      "cpc                10391\n",
      "(none)             10093\n",
      "referral            7251\n",
      "cpm                 2386\n",
      "organic             2011\n",
      "push                 892\n",
      "email                573\n",
      "blogger_channel      241\n",
      "stories              188\n",
      "smartbanner          147\n",
      "cpa                  145\n",
      "smm                   79\n",
      "tg                    73\n",
      "cpv                   72\n",
      "blogger_stories       63\n",
      "post                  51\n",
      "outlook               32\n",
      "clicks                31\n",
      "link                  28\n",
      "(not set)             26\n",
      "app                   16\n",
      "landing               15\n",
      "sms                    9\n",
      "info_text              5\n",
      "blogger_header         4\n",
      "partner                3\n",
      "medium                 1\n",
      "dom_click              1\n",
      "CPM                    1\n",
      "fb_smm                 1\n",
      "static                 1\n",
      "article                1\n",
      "Name: utm_medium, dtype: int64\n",
      "utm_campaign\n",
      "LTuZkdKfxRGVceoWkVyg    17292\n",
      "LEoPHuyFvzoNfnzGgfcd     9454\n",
      "gecBYcKZCPMcVYdSSzKP     4190\n",
      "FTjNLDyTrXaWYgZymFkV     2350\n",
      "sbJRYgVfvcnqKJNDDYIr      657\n",
      "                        ...  \n",
      "TOtlRhDcJiAMnHYarArU        1\n",
      "InOGyxvxAfYvSHCpIjJZ        1\n",
      "cccMlyVfjXspfaCSrMsO        1\n",
      "CTxTNVPeWxOUJWpkjRjV        1\n",
      "aCaBoYaQJPVffhjBQnut        1\n",
      "Name: utm_campaign, Length: 236, dtype: int64\n",
      "utm_adcontent\n",
      "JNHcPlZPxEMWDnRiyoBf    31967\n",
      "Other                    9349\n",
      "vCIpmpaGBnIQhyYNkXqp     4718\n",
      "xhoenQgDQsgfEPYNPwKO     1083\n",
      "PkybGvWbaqORmxjNunqZ      850\n",
      "                        ...  \n",
      "sDHhLoedJZYxlBhsXywf        1\n",
      "LAoDnzvTFLNWMTAhqJjV        1\n",
      "ePOwRDMsDnhYErGgxfUz        1\n",
      "LneEZMBzQifgNGkbGWMt        1\n",
      "CxCBGzPzbDmiZjhHYhSs        1\n",
      "Name: utm_adcontent, Length: 117, dtype: int64\n",
      "device_category\n",
      "mobile     37223\n",
      "desktop    12379\n",
      "tablet       398\n",
      "Name: device_category, dtype: int64\n",
      "device_brand\n",
      "0.0001    50000\n",
      "Name: device_brand, dtype: int64\n",
      "device_screen_resolution\n",
      "mobile_medium     25506\n",
      "mobile_high       11717\n",
      "desktop_medium    11385\n",
      "desktop_high        944\n",
      "tablet_medium       375\n",
      "desktop_low          50\n",
      "tablet_high          21\n",
      "tablet_low            2\n",
      "Name: device_screen_resolution, dtype: int64\n",
      "device_browser\n",
      "Chrome                              26897\n",
      "Safari                              13183\n",
      "YaBrowser                            4050\n",
      "Safari (in-app)                      1566\n",
      "Android Webview                      1475\n",
      "Samsung Internet                      965\n",
      "Firefox                               684\n",
      "Edge                                  595\n",
      "Opera                                 550\n",
      "UC Browser                             20\n",
      "Maxthon                                 4\n",
      "Android Runtime                         3\n",
      "com.vk.vkclient                         2\n",
      "MRCHROME                                1\n",
      "Mozilla Compatible Agent                1\n",
      "Instagram 208.0.0.32.135 Android        1\n",
      "[FBAN                                   1\n",
      "Puffin                                  1\n",
      "Instagram 216.0.0.12.135                1\n",
      "Name: device_browser, dtype: int64\n",
      "geo_country\n",
      "Russia                      48886\n",
      "some_unimportant_country      560\n",
      "Ukraine                       205\n",
      "United States                  86\n",
      "Germany                        82\n",
      "Belarus                        71\n",
      "Kazakhstan                     58\n",
      "Turkey                         52\n",
      "Name: geo_country, dtype: int64\n",
      "geo_city\n",
      "Moscow                   23282\n",
      "Saint Petersburg          7097\n",
      "some_unimportant_city     1720\n",
      "Kazan                     1042\n",
      "Krasnodar                  984\n",
      "                         ...  \n",
      "Ivano-Frankivsk              1\n",
      "Gurgaon                      1\n",
      "Ashgabat                     1\n",
      "Colombo                      1\n",
      "Belaya Kalitva               1\n",
      "Name: geo_city, Length: 571, dtype: int64\n",
      "camp_succ_rate\n",
      "0    50000\n",
      "Name: camp_succ_rate, dtype: int64\n",
      "12\n",
      " - \n",
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['visit_number', 'utm_source', 'utm_medium', 'utm_campaign',\n",
      "       'utm_adcontent', 'device_category', 'device_brand',\n",
      "       'device_screen_resolution', 'device_browser', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "visit_number\n",
      "1      101958\n",
      "2       20588\n",
      "3        7664\n",
      "4        4768\n",
      "5        2722\n",
      "        ...  \n",
      "422         1\n",
      "342         1\n",
      "481         1\n",
      "515         1\n",
      "230         1\n",
      "Name: visit_number, Length: 383, dtype: int64\n",
      "utm_source\n",
      "ZpYIoDJMcFzVoPFsHGJL    48037\n",
      "fDLlAcSmythWSCVMvqvL    30235\n",
      "kjsLglQLzykiRbcDiGcD    18404\n",
      "bByPQxmDaMXgpHeypKSM    15336\n",
      "BHcvLfOaCWvWTykYqHVe    12048\n",
      "                        ...  \n",
      "KkNQdfTjqxnSBHFFEsRG        1\n",
      "YmnqPKMqodkOEiiyvBYk        1\n",
      "SbQJoCCWibshtEmQeuVM        1\n",
      "eYRDXZIocNyHVjEHzesr        1\n",
      "xKilurCKKiYaehWwdleb        1\n",
      "Name: utm_source, Length: 144, dtype: int64\n",
      "utm_medium\n",
      "banner             45402\n",
      "cpc                31093\n",
      "(none)             30235\n",
      "referral           21794\n",
      "cpm                 7190\n",
      "organic             6166\n",
      "push                2591\n",
      "email               1824\n",
      "blogger_channel      734\n",
      "stories              564\n",
      "smartbanner          483\n",
      "cpa                  407\n",
      "cpv                  231\n",
      "tg                   211\n",
      "blogger_stories      206\n",
      "smm                  193\n",
      "post                 147\n",
      "outlook              102\n",
      "(not set)             91\n",
      "clicks                90\n",
      "link                  68\n",
      "app                   48\n",
      "landing               42\n",
      "sms                   32\n",
      "info_text             16\n",
      "blogger_header        14\n",
      "medium                 6\n",
      "partner                6\n",
      "CPM                    5\n",
      "fb_smm                 4\n",
      "static                 2\n",
      "dom_click              1\n",
      "google_cpc             1\n",
      "article                1\n",
      "Name: utm_medium, dtype: int64\n",
      "utm_campaign\n",
      "LTuZkdKfxRGVceoWkVyg    52173\n",
      "LEoPHuyFvzoNfnzGgfcd    28578\n",
      "gecBYcKZCPMcVYdSSzKP    12327\n",
      "FTjNLDyTrXaWYgZymFkV     7055\n",
      "sbJRYgVfvcnqKJNDDYIr     1852\n",
      "                        ...  \n",
      "QzAELPgNYUjFjCPggkiD        1\n",
      "TdiFPEJuNonAMXzGxOdj        1\n",
      "BHcvLfOaCWvWTykYqHVe        1\n",
      "iOMuvNvFqsfUXNqBuSzy        1\n",
      "FhMPkFqqAboknIypeYDz        1\n",
      "Name: utm_campaign, Length: 282, dtype: int64\n",
      "utm_adcontent\n",
      "JNHcPlZPxEMWDnRiyoBf    95796\n",
      "Other                   27854\n",
      "vCIpmpaGBnIQhyYNkXqp    14277\n",
      "xhoenQgDQsgfEPYNPwKO     3267\n",
      "PkybGvWbaqORmxjNunqZ     2494\n",
      "                        ...  \n",
      "AREbWGOhRGJXAffGqZTc        1\n",
      "JJRVNKFvKSInZxhrcjHK        1\n",
      "flODqtPxdAuXewIUDGNw        1\n",
      "PlanrlymnpCeYvUrUTVJ        1\n",
      "QjKPYbVQrUvYVYVhWTUK        1\n",
      "Name: utm_adcontent, Length: 147, dtype: int64\n",
      "device_category\n",
      "mobile     111323\n",
      "desktop     37424\n",
      "tablet       1253\n",
      "Name: device_category, dtype: int64\n",
      "device_brand\n",
      "0.0001    150000\n",
      "Name: device_brand, dtype: int64\n",
      "device_screen_resolution\n",
      "mobile_medium     76458\n",
      "mobile_high       34865\n",
      "desktop_medium    34381\n",
      "desktop_high       2903\n",
      "tablet_medium       988\n",
      "tablet_high         265\n",
      "desktop_low         140\n",
      "Name: device_screen_resolution, dtype: int64\n",
      "device_browser\n",
      "Chrome                              80759\n",
      "Safari                              39684\n",
      "YaBrowser                           12293\n",
      "Safari (in-app)                      4523\n",
      "Android Webview                      4412\n",
      "Samsung Internet                     2876\n",
      "Firefox                              1998\n",
      "Edge                                 1719\n",
      "Opera                                1645\n",
      "UC Browser                             68\n",
      "Maxthon                                 5\n",
      "Android Runtime                         4\n",
      "Mozilla Compatible Agent                3\n",
      "Puffin                                  3\n",
      "com.vk.vkclient                         2\n",
      "MRCHROME                                1\n",
      "Amazon Silk                             1\n",
      "Instagram 208.0.0.32.135 Android        1\n",
      "[FBAN                                   1\n",
      "Instagram 216.0.0.12.135                1\n",
      "Instagram 209.0.0.21.119 Android        1\n",
      "Name: device_browser, dtype: int64\n",
      "geo_country\n",
      "Russia                      146677\n",
      "some_unimportant_country      1707\n",
      "Ukraine                        621\n",
      "United States                  252\n",
      "Germany                        219\n",
      "Belarus                        213\n",
      "Turkey                         156\n",
      "Kazakhstan                     155\n",
      "Name: geo_country, dtype: int64\n",
      "geo_city\n",
      "Moscow                   70154\n",
      "Saint Petersburg         21352\n",
      "some_unimportant_city     5381\n",
      "Kazan                     3163\n",
      "Krasnodar                 2976\n",
      "                         ...  \n",
      "Dovzhansk                    1\n",
      "Brussels                     1\n",
      "Torrevieja                   1\n",
      "Beni-Mellal                  1\n",
      "Varna                        1\n",
      "Name: geo_city, Length: 619, dtype: int64\n",
      "camp_succ_rate\n",
      "0    150000\n",
      "Name: camp_succ_rate, dtype: int64\n",
      "12\n",
      " - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['visit_number', 'utm_source', 'utm_medium', 'utm_campaign',\n",
      "       'utm_adcontent', 'device_category', 'device_brand',\n",
      "       'device_screen_resolution', 'device_browser', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "visit_number\n",
      "1      33882\n",
      "2       6948\n",
      "3       2514\n",
      "4       1554\n",
      "5        900\n",
      "       ...  \n",
      "218        1\n",
      "135        1\n",
      "134        1\n",
      "172        1\n",
      "152        1\n",
      "Name: visit_number, Length: 304, dtype: int64\n",
      "utm_source\n",
      "ZpYIoDJMcFzVoPFsHGJL    16072\n",
      "fDLlAcSmythWSCVMvqvL    10216\n",
      "kjsLglQLzykiRbcDiGcD     6158\n",
      "bByPQxmDaMXgpHeypKSM     5063\n",
      "BHcvLfOaCWvWTykYqHVe     4006\n",
      "                        ...  \n",
      "rGDSdilqpnHoxSsEYvjb        1\n",
      "pvCdohkUBGPPZOsCzVAu        1\n",
      "maiZOsuEAMdeoRVsYoFk        1\n",
      "hONgZhBaHwLGhvJSefNE        1\n",
      "DsqwamlMwRgMTyspCjFR        1\n",
      "Name: utm_source, Length: 108, dtype: int64\n",
      "utm_medium\n",
      "banner             15192\n",
      "cpc                10422\n",
      "(none)             10216\n",
      "referral            7196\n",
      "cpm                 2296\n",
      "organic             1983\n",
      "push                 872\n",
      "email                586\n",
      "blogger_channel      237\n",
      "stories              184\n",
      "smartbanner          174\n",
      "cpa                  110\n",
      "cpv                   94\n",
      "blogger_stories       74\n",
      "tg                    69\n",
      "smm                   57\n",
      "post                  46\n",
      "(not set)             43\n",
      "clicks                41\n",
      "outlook               37\n",
      "link                  18\n",
      "sms                   16\n",
      "landing               10\n",
      "app                   10\n",
      "info_text              5\n",
      "blogger_header         5\n",
      "yandex_cpc             1\n",
      "social                 1\n",
      "CPM                    1\n",
      "fb_smm                 1\n",
      "medium                 1\n",
      "vk_smm                 1\n",
      "article                1\n",
      "Name: utm_medium, dtype: int64\n",
      "utm_campaign\n",
      "LTuZkdKfxRGVceoWkVyg    17387\n",
      "LEoPHuyFvzoNfnzGgfcd     9460\n",
      "gecBYcKZCPMcVYdSSzKP     4238\n",
      "FTjNLDyTrXaWYgZymFkV     2255\n",
      "sbJRYgVfvcnqKJNDDYIr      608\n",
      "                        ...  \n",
      "KAcUKGokhYlMktQhYKHx        1\n",
      "OztZDxVyKavDuqIwuDEW        1\n",
      "exUGYSXnDUQrIBIREJPO        1\n",
      "akoPqAqaJrLGbjrrIVPH        1\n",
      "WUAADskMKtAjHudRNZNk        1\n",
      "Name: utm_campaign, Length: 239, dtype: int64\n",
      "utm_adcontent\n",
      "JNHcPlZPxEMWDnRiyoBf    32017\n",
      "Other                    9303\n",
      "vCIpmpaGBnIQhyYNkXqp     4750\n",
      "xhoenQgDQsgfEPYNPwKO     1021\n",
      "PkybGvWbaqORmxjNunqZ      812\n",
      "                        ...  \n",
      "NnaLweGiAhdtkuktFipk        1\n",
      "QEPLWgIvqPEGXcwBrsFw        1\n",
      "WaWpHWszYFymgCSbpGVL        1\n",
      "ePOwRDMsDnhYErGgxfUz        1\n",
      "jGIBHItAWSMJqMByEHbB        1\n",
      "Name: utm_adcontent, Length: 124, dtype: int64\n",
      "device_category\n",
      "mobile     37170\n",
      "desktop    12404\n",
      "tablet       426\n",
      "Name: device_category, dtype: int64\n",
      "device_brand\n",
      "0.0001    50000\n",
      "Name: device_brand, dtype: int64\n",
      "device_screen_resolution\n",
      "mobile_medium     25722\n",
      "mobile_high       11448\n",
      "desktop_medium    11403\n",
      "desktop_high        936\n",
      "tablet_medium       396\n",
      "desktop_low          65\n",
      "tablet_high          30\n",
      "Name: device_screen_resolution, dtype: int64\n",
      "device_browser\n",
      "Chrome                      26972\n",
      "Safari                      13255\n",
      "YaBrowser                    4124\n",
      "Safari (in-app)              1528\n",
      "Android Webview              1461\n",
      "Samsung Internet              914\n",
      "Firefox                       603\n",
      "Edge                          568\n",
      "Opera                         537\n",
      "UC Browser                     29\n",
      "Android Runtime                 3\n",
      "Internet Explorer               2\n",
      "Mozilla Compatible Agent        2\n",
      "Puffin                          1\n",
      "Android Browser                 1\n",
      "Name: device_browser, dtype: int64\n",
      "geo_country\n",
      "Russia                      48834\n",
      "some_unimportant_country      591\n",
      "Ukraine                       212\n",
      "United States                 101\n",
      "Germany                        74\n",
      "Belarus                        72\n",
      "Kazakhstan                     59\n",
      "Turkey                         57\n",
      "Name: geo_country, dtype: int64\n",
      "geo_city\n",
      "Moscow                   23177\n",
      "Saint Petersburg          7126\n",
      "some_unimportant_city     1788\n",
      "Krasnodar                 1014\n",
      "Kazan                     1003\n",
      "                         ...  \n",
      "Iskitim                      1\n",
      "Zaporizhzhia                 1\n",
      "Polatsk                      1\n",
      "Ust-Labinsk                  1\n",
      "Shanghai                     1\n",
      "Name: geo_city, Length: 560, dtype: int64\n",
      "camp_succ_rate\n",
      "0    50000\n",
      "Name: camp_succ_rate, dtype: int64\n",
      "12\n",
      " - \n",
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['visit_number', 'utm_source', 'utm_medium', 'utm_campaign',\n",
      "       'utm_adcontent', 'device_category', 'device_brand',\n",
      "       'device_screen_resolution', 'device_browser', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "visit_number\n",
      "1      101824\n",
      "2       20706\n",
      "3        7681\n",
      "4        4703\n",
      "5        2744\n",
      "        ...  \n",
      "200         1\n",
      "334         1\n",
      "178         1\n",
      "474         1\n",
      "152         1\n",
      "Name: visit_number, Length: 386, dtype: int64\n",
      "utm_source\n",
      "ZpYIoDJMcFzVoPFsHGJL    48121\n",
      "fDLlAcSmythWSCVMvqvL    30392\n",
      "kjsLglQLzykiRbcDiGcD    18416\n",
      "bByPQxmDaMXgpHeypKSM    15248\n",
      "BHcvLfOaCWvWTykYqHVe    12037\n",
      "                        ...  \n",
      "cqgnjDbqrtCipVvzhxqa        1\n",
      "KkNQdfTjqxnSBHFFEsRG        1\n",
      "hONgZhBaHwLGhvJSefNE        1\n",
      "QKpFeggpjKAvhtjHKHZC        1\n",
      "DsqwamlMwRgMTyspCjFR        1\n",
      "Name: utm_source, Length: 140, dtype: int64\n",
      "utm_medium\n",
      "banner             45476\n",
      "cpc                31169\n",
      "(none)             30392\n",
      "referral           21701\n",
      "cpm                 7030\n",
      "organic             6100\n",
      "push                2608\n",
      "email               1800\n",
      "blogger_channel      737\n",
      "stories              562\n",
      "smartbanner          497\n",
      "cpa                  382\n",
      "cpv                  259\n",
      "tg                   204\n",
      "blogger_stories      202\n",
      "smm                  191\n",
      "post                 146\n",
      "clicks               103\n",
      "outlook              101\n",
      "(not set)             91\n",
      "link                  69\n",
      "app                   44\n",
      "landing               43\n",
      "sms                   39\n",
      "info_text             15\n",
      "blogger_header        14\n",
      "medium                 6\n",
      "fb_smm                 4\n",
      "CPM                    4\n",
      "partner                3\n",
      "article                2\n",
      "dom_click              1\n",
      "static                 1\n",
      "yandex_cpc             1\n",
      "social                 1\n",
      "google_cpc             1\n",
      "vk_smm                 1\n",
      "Name: utm_medium, dtype: int64\n",
      "utm_campaign\n",
      "LTuZkdKfxRGVceoWkVyg    52102\n",
      "LEoPHuyFvzoNfnzGgfcd    28433\n",
      "gecBYcKZCPMcVYdSSzKP    12507\n",
      "FTjNLDyTrXaWYgZymFkV     6933\n",
      "sbJRYgVfvcnqKJNDDYIr     1863\n",
      "                        ...  \n",
      "iSHFQRYsNeVeKceWxpSo        1\n",
      "UbQpozKfTgYxQovHjkQM        1\n",
      "InOGyxvxAfYvSHCpIjJZ        1\n",
      "QzAELPgNYUjFjCPggkiD        1\n",
      "WUAADskMKtAjHudRNZNk        1\n",
      "Name: utm_campaign, Length: 284, dtype: int64\n",
      "utm_adcontent\n",
      "JNHcPlZPxEMWDnRiyoBf    95847\n",
      "Other                   27942\n",
      "vCIpmpaGBnIQhyYNkXqp    14238\n",
      "xhoenQgDQsgfEPYNPwKO     3156\n",
      "PkybGvWbaqORmxjNunqZ     2491\n",
      "                        ...  \n",
      "XVKNbZXFFeCXocbAHwpS        1\n",
      "flODqtPxdAuXewIUDGNw        1\n",
      "PlanrlymnpCeYvUrUTVJ        1\n",
      "OmCxvySbGRRBWURUORal        1\n",
      "jGIBHItAWSMJqMByEHbB        1\n",
      "Name: utm_adcontent, Length: 153, dtype: int64\n",
      "device_category\n",
      "mobile     111451\n",
      "desktop     37304\n",
      "tablet       1245\n",
      "Name: device_category, dtype: int64\n",
      "device_brand\n",
      "0.0001    150000\n",
      "Name: device_brand, dtype: int64\n",
      "device_screen_resolution\n",
      "mobile_medium     76802\n",
      "mobile_high       34649\n",
      "desktop_medium    34264\n",
      "desktop_high       2886\n",
      "tablet_medium      1170\n",
      "desktop_low         154\n",
      "tablet_high          72\n",
      "tablet_low            3\n",
      "Name: device_screen_resolution, dtype: int64\n",
      "device_browser\n",
      "Chrome                              80925\n",
      "Safari                              39586\n",
      "YaBrowser                           12355\n",
      "Safari (in-app)                      4565\n",
      "Android Webview                      4402\n",
      "Samsung Internet                     2817\n",
      "Firefox                              1917\n",
      "Edge                                 1737\n",
      "Opera                                1592\n",
      "UC Browser                             74\n",
      "Android Runtime                         7\n",
      "Mozilla Compatible Agent                5\n",
      "Maxthon                                 4\n",
      "Puffin                                  4\n",
      "com.vk.vkclient                         2\n",
      "Internet Explorer                       2\n",
      "MRCHROME                                1\n",
      "Amazon Silk                             1\n",
      "Instagram 208.0.0.32.135 Android        1\n",
      "[FBAN                                   1\n",
      "Instagram 216.0.0.12.135                1\n",
      "Android Browser                         1\n",
      "Name: device_browser, dtype: int64\n",
      "geo_country\n",
      "Russia                      146598\n",
      "some_unimportant_country      1725\n",
      "Ukraine                        632\n",
      "United States                  278\n",
      "Germany                        224\n",
      "Belarus                        212\n",
      "Turkey                         166\n",
      "Kazakhstan                     165\n",
      "Name: geo_country, dtype: int64\n",
      "geo_city\n",
      "Moscow                   69799\n",
      "Saint Petersburg         21421\n",
      "some_unimportant_city     5473\n",
      "Kazan                     3067\n",
      "Krasnodar                 2986\n",
      "                         ...  \n",
      "Phuket                       1\n",
      "Houston                      1\n",
      "Mersin                       1\n",
      "Kushchyovskaya               1\n",
      "Chicago                      1\n",
      "Name: geo_city, Length: 612, dtype: int64\n",
      "camp_succ_rate\n",
      "0    150000\n",
      "Name: camp_succ_rate, dtype: int64\n",
      "12\n",
      " - \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country start\n",
      "country end\n",
      "-\n",
      "city start\n",
      "city end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['visit_number', 'utm_source', 'utm_medium', 'utm_campaign',\n",
      "       'utm_adcontent', 'device_category', 'device_brand',\n",
      "       'device_screen_resolution', 'device_browser', 'geo_country', 'geo_city',\n",
      "       'camp_succ_rate'],\n",
      "      dtype='object')\n",
      "-\n",
      "visit_number\n",
      "1      34016\n",
      "2       6830\n",
      "3       2497\n",
      "4       1619\n",
      "5        878\n",
      "       ...  \n",
      "485        1\n",
      "337        1\n",
      "415        1\n",
      "282        1\n",
      "230        1\n",
      "Name: visit_number, Length: 301, dtype: int64\n",
      "utm_source\n",
      "ZpYIoDJMcFzVoPFsHGJL    15988\n",
      "fDLlAcSmythWSCVMvqvL    10059\n",
      "kjsLglQLzykiRbcDiGcD     6146\n",
      "bByPQxmDaMXgpHeypKSM     5151\n",
      "BHcvLfOaCWvWTykYqHVe     4017\n",
      "                        ...  \n",
      "rgsINTLYFsElIlfRtNDP        1\n",
      "XzfzEBYZWgSDtJNXOadn        1\n",
      "CqeIpFwJscTsZoYXdHsP        1\n",
      "MlvrtLODeciGJoIzwoNf        1\n",
      "xKilurCKKiYaehWwdleb        1\n",
      "Name: utm_source, Length: 112, dtype: int64\n",
      "utm_medium\n",
      "banner             15118\n",
      "cpc                10346\n",
      "(none)             10059\n",
      "referral            7289\n",
      "cpm                 2456\n",
      "organic             2049\n",
      "push                 855\n",
      "email                610\n",
      "blogger_channel      234\n",
      "stories              186\n",
      "smartbanner          160\n",
      "cpa                  135\n",
      "blogger_stories       78\n",
      "tg                    76\n",
      "cpv                   66\n",
      "smm                   59\n",
      "post                  47\n",
      "(not set)             43\n",
      "outlook               38\n",
      "clicks                28\n",
      "link                  17\n",
      "app                   14\n",
      "sms                    9\n",
      "landing                9\n",
      "info_text              6\n",
      "blogger_header         5\n",
      "partner                3\n",
      "CPM                    2\n",
      "static                 1\n",
      "medium                 1\n",
      "fb_smm                 1\n",
      "Name: utm_medium, dtype: int64\n",
      "utm_campaign\n",
      "LTuZkdKfxRGVceoWkVyg    17458\n",
      "LEoPHuyFvzoNfnzGgfcd     9605\n",
      "gecBYcKZCPMcVYdSSzKP     4058\n",
      "FTjNLDyTrXaWYgZymFkV     2377\n",
      "sbJRYgVfvcnqKJNDDYIr      597\n",
      "                        ...  \n",
      "muXSoqIAVnfVKUwxNbDi        1\n",
      "DlOlXJaBJgWQVhgtCeWo        1\n",
      "gaFBXpMUrvHAilRkjPSS        1\n",
      "rKHSSStqLNTbdGVZMwfG        1\n",
      "IOQFgDqnjywyYyRldWoF        1\n",
      "Name: utm_campaign, Length: 241, dtype: int64\n",
      "utm_adcontent\n",
      "JNHcPlZPxEMWDnRiyoBf    31966\n",
      "Other                    9215\n",
      "vCIpmpaGBnIQhyYNkXqp     4789\n",
      "xhoenQgDQsgfEPYNPwKO     1132\n",
      "PkybGvWbaqORmxjNunqZ      815\n",
      "                        ...  \n",
      "ZbhjTfTaZOUpHAHHpvsP        1\n",
      "AREbWGOhRGJXAffGqZTc        1\n",
      "sMBIidTLSrYkjsCEvwht        1\n",
      "isYoUwVPnRHJczHiHQbB        1\n",
      "vhVTQFAHzzstHBwdbSyd        1\n",
      "Name: utm_adcontent, Length: 119, dtype: int64\n",
      "device_category\n",
      "mobile     37042\n",
      "desktop    12524\n",
      "tablet       434\n",
      "Name: device_category, dtype: int64\n",
      "device_brand\n",
      "0.0001    50000\n",
      "Name: device_brand, dtype: int64\n",
      "device_screen_resolution\n",
      "mobile_medium     25378\n",
      "mobile_high       11664\n",
      "desktop_medium    11520\n",
      "desktop_high        953\n",
      "tablet_medium       342\n",
      "tablet_high          92\n",
      "desktop_low          51\n",
      "Name: device_screen_resolution, dtype: int64\n",
      "device_browser\n",
      "Chrome                              26806\n",
      "Safari                              13353\n",
      "YaBrowser                            4062\n",
      "Safari (in-app)                      1486\n",
      "Android Webview                      1471\n",
      "Samsung Internet                      973\n",
      "Firefox                               684\n",
      "Opera                                 590\n",
      "Edge                                  550\n",
      "UC Browser                             23\n",
      "Instagram 209.0.0.21.119 Android        1\n",
      "Maxthon                                 1\n",
      "Name: device_browser, dtype: int64\n",
      "geo_country\n",
      "Russia                      48913\n",
      "some_unimportant_country      669\n",
      "Ukraine                       201\n",
      "United States                  75\n",
      "Belarus                        73\n",
      "Germany                        69\n",
      "Name: geo_country, dtype: int64\n",
      "geo_city\n",
      "Moscow                   23532\n",
      "Saint Petersburg          7057\n",
      "some_unimportant_city     1687\n",
      "Kazan                     1099\n",
      "Krasnodar                 1004\n",
      "                         ...  \n",
      "Kurchatov                    1\n",
      "Netanya                      1\n",
      "Tunis                        1\n",
      "Minusinsk                    1\n",
      "Fort Worth                   1\n",
      "Name: geo_city, Length: 577, dtype: int64\n",
      "camp_succ_rate\n",
      "0    50000\n",
      "Name: camp_succ_rate, dtype: int64\n",
      "12\n",
      " - \n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv('data/df3_200k_50n_50p.csv')\n",
    "\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    #('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "f_transformer = ColumnTransformer(transformers=[\n",
    "    ('categorical', categorical_transformer, make_column_selector(dtype_include='object'))\n",
    "])\n",
    "\n",
    "preprocessor = Pipeline(steps=[\n",
    "    #('event', FunctionTransformer(event_action)),\n",
    "    #('sampling', FunctionTransformer(sample_df3)),\n",
    "    ('ad_campaign_feature_creating', FunctionTransformer(ad_campaign)),\n",
    "    #('day_of_week', FunctionTransformer(day_of_week)),\n",
    "    ('empties', FunctionTransformer(empties)),\n",
    "    ('resolution_func', FunctionTransformer(resolution_func)),\n",
    "    ('country', FunctionTransformer(country)),\n",
    "    ('city', FunctionTransformer(city)),\n",
    "    ('device brand', FunctionTransformer(device_brand)),\n",
    "    ('filter_stuff', FunctionTransformer(filter_stuff)),\n",
    "    #('encode_stuff', FunctionTransformer(encode_stuff)),\n",
    "    #('scale_stuff(visit_num)', FunctionTransformer(scale_stuff)),\n",
    "    ('check_stuff_3', FunctionTransformer(check_stuff_3)),\n",
    "    ('f_transformer', f_transformer),\n",
    "    #('filter_stuff', FunctionTransformer(filter_stuff)),\n",
    "    #('check_stuff_3', FunctionTransformer(check_stuff_3))\n",
    "])\n",
    "\n",
    "models = [\n",
    "    #RandomForestClassifier(n_estimators=300, max_depth= 10, max_features='sqrt', min_samples_split=2),\n",
    "    #SVC(C=10, gamma=0.01, kernel='rbf'),\n",
    "    #DecisionTreeClassifier(criterion='gini', max_depth=7, min_samples_split=10),\n",
    "    #LogisticRegression( C=1.0, penalty='l2', solver='saga'),\n",
    "    MLPClassifier(hidden_layer_sizes=(100, ), solver='adam', activation='tanh')\n",
    "    ]\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "\n",
    "    pipeline = Pipeline(steps = [\n",
    "        ('preprocessor', preprocessor), \n",
    "        ('classifier', model)  \n",
    "    ])\n",
    "\n",
    "    y = df4['event_action']\n",
    "    x = df4.drop('event_action', axis=1)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    #predictions = pipeline.predict(x_test)\n",
    "    #probs = pipeline.predict_proba(x_test)\n",
    "    #scores_single_fit.append([type(model).__name__,' test roc score - ', roc_auc_score(y_test, probs[:,1])])\n",
    "    #scores_single_fit.append([type(model).__name__,' test acc score - ', accuracy_score(y_test, predictions)])\n",
    "    #print(type(model).__name__,' test roc score - ', roc_auc_score(y_test, probs[:,1]))\n",
    "    #print(type(model).__name__,' test acc score - ', accuracy_score(y_test, predictions))\n",
    "    #interm_scores.append((str(model), 'test roc score - ', roc_auc_score(y_test, pipeline.predict_proba(x_test)[:,1])))\n",
    "    #interm_scores.append((str(model), 'test acc score - ', accuracy_score(y_test, predictions)))\n",
    "    \n",
    "    log = 'ad_camp V, resol V, cntry V, ct V, brand V'\n",
    "    score = cross_val_score(pipeline, x, y, cv=4, scoring='roc_auc')\n",
    "    #score = cross_val_score(pipeline, x, y, cv=4, scoring='accuracy')\n",
    "    cv_scores.append([ round(score.mean(), 4), log]) #type(model).__name__,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43ff2129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6375, 'ad_camp V, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
       " [0.6375, 'ad_camp X, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
       " [0.6375, ', ad_camp X, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
       " [0.6482, ', ad_camp V, resol v1 X, ctry v1 V, ct v1 V, brand v1 V'],\n",
       " [0.6504, ', ad_camp X, resol v1 X, ctry v1 X, ct v1 X, brand v1 X'],\n",
       " [0.6409, ', ad_camp X, resol v1 V, ctry v1 X, ct v1 X, brand v1 X'],\n",
       " [0.6396, ', ad_camp X, resol v2 V, ctry v1 X, ct v1 X, brand v1 X'],\n",
       " [0.6502, ', ad_camp X, resol v2 X, ctry v1 V, ct v1 X, brand v1 X'],\n",
       " [0.6503, ', ad_camp X, resol v2 X, ctry v2 V, ct v1 X, brand v1 X'],\n",
       " [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v1 X, brand v1 X'],\n",
       " [0.6498, ', ad_camp X, resol v2 X, ctry v2 X, ct v1 V, brand v1 X'],\n",
       " [0.6389, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 V, brand v1 X'],\n",
       " [0.649, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v1 V'],\n",
       " [0.6503, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
       " [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
       " [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
       " [0.6603, 'ad_camp V, resol V, cntry V, ct V, brand V']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0c8ed89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['LogisticRegression', ' test roc score - ', 0.63630310690601],\n",
       " ['MLPClassifier', ' test roc score - ', 0.6577514254324037]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_single_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9174ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fab2d5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57935     1\n",
       "303849    0\n",
       "324907    0\n",
       "29718     1\n",
       "264378    0\n",
       "309521    0\n",
       "265538    0\n",
       "Name: event_action, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[101993:102000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ea8c215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26147092, 0.73852908],\n",
       "       [0.85764563, 0.14235437],\n",
       "       [0.68091218, 0.31908782],\n",
       "       [0.56319319, 0.43680681],\n",
       "       [0.71138692, 0.28861308],\n",
       "       [0.69080172, 0.30919828],\n",
       "       [0.66625229, 0.33374771]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[101993:102000,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ffa87e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6375, 'ad_camp V, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
       " [0.6375, 'ad_camp X, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
       " [0.6375, ', ad_camp X, resol v1 V, ctry v1 V, ct v1 V, brand v1 V'],\n",
       " [0.6482, ', ad_camp V, resol v1 X, ctry v1 V, ct v1 V, brand v1 V'],\n",
       " [0.6504, ', ad_camp X, resol v1 X, ctry v1 X, ct v1 X, brand v1 X'],\n",
       " [0.6409, ', ad_camp X, resol v1 V, ctry v1 X, ct v1 X, brand v1 X'],\n",
       " [0.6396, ', ad_camp X, resol v2 V, ctry v1 X, ct v1 X, brand v1 X'],\n",
       " [0.6502, ', ad_camp X, resol v2 X, ctry v1 V, ct v1 X, brand v1 X'],\n",
       " [0.6503, ', ad_camp X, resol v2 X, ctry v2 V, ct v1 X, brand v1 X'],\n",
       " [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v1 X, brand v1 X'],\n",
       " [0.6498, ', ad_camp X, resol v2 X, ctry v2 X, ct v1 V, brand v1 X'],\n",
       " [0.6389, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 V, brand v1 X'],\n",
       " [0.649, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v1 V'],\n",
       " [0.6503, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
       " [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
       " [0.6504, ', ad_camp X, resol v2 X, ctry v2 X, ct v2 X, brand v2 V'],\n",
       " [0.6503, 'ad_camp X, resol v2 X, cntry v2 X, ct v2 X, brand v2 X'],\n",
       " [0.7049, 'ad_camp V, resol V, cntry V, ct V, brand V'],\n",
       " [0.6375, 'ad_camp V, resol V, cntry V, ct V, brand V']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f66ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421bfaab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70051ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f40e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "225d5b63",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_action start\n",
      "event_action start\n",
      "event_action start\n",
      "event_action start\n",
      "event_action start\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3802, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas\\_libs\\index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'event_action'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 437, in fit_transform\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 862, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 236, in transform\n    return self._transform(X, func=self.func, kw_args=self.kw_args)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 307, in _transform\n    return func(X, **(kw_args if kw_args else {}))\n  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1844\\1663308378.py\", line 13, in event_action\n    df3['event_action'] = df3['event_action'].apply(lambda x: 1 if x in target_action else 0)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 3807, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3804, in get_loc\n    raise KeyError(key) from err\nKeyError: 'event_action'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 40\u001b[0m\n\u001b[0;32m     33\u001b[0m high_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     36\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     37\u001b[0m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[0;32m     38\u001b[0m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, rf)\n\u001b[0;32m     39\u001b[0m ])\n\u001b[1;32m---> 40\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, error_score='raise')\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, acc_mean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, acc_std: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m high_score \u001b[38;5;241m<\u001b[39m score\u001b[38;5;241m.\u001b[39mmean():\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(scoring):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3802, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas\\_libs\\index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index.pyx\", line 165, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5745, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 5753, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'event_action'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 437, in fit_transform\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 862, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 142, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 236, in transform\n    return self._transform(X, func=self.func, kw_args=self.kw_args)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 307, in _transform\n    return func(X, **(kw_args if kw_args else {}))\n  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1844\\1663308378.py\", line 13, in event_action\n    df3['event_action'] = df3['event_action'].apply(lambda x: 1 if x in target_action else 0)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 3807, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 3804, in get_loc\n    raise KeyError(key) from err\nKeyError: 'event_action'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#f_transformer = ColumnTransformer(transformers=[\n",
    " #   ('numerical', numerical_transformer, make_column_selector(dtype_include=['int64', 'float64'])),\n",
    "  #  ('categorical', categorical_transformer, make_column_selector(dtype_include='object'))\n",
    "#])\n",
    "df4 = pd.read_csv('data/df3_10k_50n_50p.csv')\n",
    "\n",
    "#df4 = event_action(df4)\n",
    "\n",
    "#df4 = sample_df3(df4)\n",
    "\n",
    "\n",
    "y = df4['event_action']\n",
    "X = df4.drop('event_action', axis=1)\n",
    "\n",
    "preprocessor = Pipeline(steps=[\n",
    "    ('target', FunctionTransformer(event_action)),\n",
    "    ('sampling', FunctionTransformer(sample_df3)),\n",
    "    ('ad_campaign_feature_creating', FunctionTransformer(ad_campaign)),\n",
    "    ('day_of_week', FunctionTransformer(day_of_week)),\n",
    "    ('empties', FunctionTransformer(empties)),\n",
    "    ('resolution_func', FunctionTransformer(resolution_func)),\n",
    "    ('country', FunctionTransformer(country)),\n",
    "    ('city', FunctionTransformer(city)),\n",
    "    ('encode_stuff', FunctionTransformer(encode_stuff)),\n",
    "    ('scale_stuff', FunctionTransformer(scale_stuff)),\n",
    "    ('filter_stuff', FunctionTransformer(filter_stuff)),\n",
    "    ('check_stuff', FunctionTransformer(check_stuff))\n",
    "    ])\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=400, min_samples_leaf=2, max_features='sqrt')\n",
    "\n",
    "\n",
    "high_score = 0\n",
    "\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "('preprocessor', preprocessor),\n",
    "('classifier', rf)\n",
    "])\n",
    "score = cross_val_score(pipe, X, y, cv=5, scoring='a''accuracy')#, error_score='raise')\n",
    "print(f'model: {type(model).__name__}, acc_mean: {score.mean():.4f}, acc_std: {score.std():.4f}')\n",
    "if high_score < score.mean():\n",
    "    high_score = score.mean()\n",
    "    cars_pipe = pipe\n",
    "\n",
    "else:\n",
    "    continue\n",
    "\n",
    "\n",
    "#cars_pipe.fit(X, y)\n",
    "\n",
    "\n",
    "#with open('data/cars_pipe.pkl', 'wb') as file:\n",
    "#    dill.dump({\n",
    "#        'model': cars_pipe,\n",
    "#        'metadata': {\n",
    "#            'name': 'car price prediction',\n",
    "#           'author': 'collaborative ffs by this point can i really write myself here yet?)',\n",
    "#           'version': 0.00000000000000000001,\n",
    "#            'date': datetime.now(),\n",
    "#            'type': type(cars_pipe.named_steps[\"classifier\"]).__name__,\n",
    "#           'accuracy': high_score\n",
    "#       }\n",
    "#   }, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "989dd4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2abb4648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8084ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4f461240",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/best_params_lr_10k_50_50.json', 'w') as f: json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be1b28cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "country v2  start\n",
      "country v2 end\n",
      "-\n",
      "city v2  start\n",
      "city v2 end\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "encode_stuff start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1792\\615650011.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_stuff end\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "Index(['event_action', 'camp_succ_rate', 'utm_source_BHcvLfOaCWvWTykYqHVe',\n",
      "       'utm_source_BKeImrJuRDZcHiSSTdzm', 'utm_source_DnEUulZAecfGPvdtZBYS',\n",
      "       'utm_source_EvhrtRzIJnQYHziPiLzV', 'utm_source_FTAuYVNoYYxgvKMpKSLW',\n",
      "       'utm_source_GmILPdZyuAVJCPsUBHeN', 'utm_source_GpAkIXsclxDGyILfNlrR',\n",
      "       'utm_source_HFaOtpcChAlcMuxEAlpu',\n",
      "       ...\n",
      "       'utm_campaign_zDGMDYOBPSeVFZNNwoxT',\n",
      "       'utm_campaign_zPJpddwzkFqLMSYgtDqy',\n",
      "       'utm_campaign_zfwIehuEfWYdYrEZgRLo',\n",
      "       'utm_campaign_zmnpxOKDENholtspXiGy',\n",
      "       'utm_campaign_zxoiLxhuSIFrCeTLQVWZ', 'utm_campaign_nan',\n",
      "       'geo_country_0.0001', 'geo_city_0.0001', 'visit_number_scaled',\n",
      "       'day_of_week_scaled'],\n",
      "      dtype='object', length=376)\n",
      "-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
      "Best Parameters:  {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
      "Best Score (ROC AUC):  0.6126422706985116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "{'activation': 'tanh', 'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "df4 = pd.read_csv('data/df3_10k_50n_50p.csv')\n",
    "\n",
    "\n",
    "df4 = ad_campaign(df4)\n",
    "df4 = day_of_week(df4)\n",
    "df4 = empties(df4)\n",
    "df4 = resolution_func(df4)\n",
    "df4 = country_v_2(df4)\n",
    "df4 = city_v_2(df4)\n",
    "df4 = device_brand(df4)\n",
    "df4 = encode_stuff(df4)\n",
    "df4 = scale_stuff(df4)\n",
    "df4 = filter_stuff(df4)\n",
    "\n",
    "y = df4['event_action']\n",
    "x = df4.drop('event_action', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define parameters and their possible values in a dictionary\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(10,), (50,), (100,)],  # different hidden layer sizes\n",
    "    'activation': ['relu', 'tanh'],                 # activation functions to try\n",
    "    'solver': ['sgd', 'adam'],                       # optimization solvers to try\n",
    "}\n",
    "\n",
    "# Create Logistic Regression classifier object\n",
    "classifier = MLPClassifier()\n",
    "\n",
    "# Perform Grid Search with cross-validation (e.g., using k-fold CV)\n",
    "grid_search = GridSearchCV(classifier,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='roc_auc',\n",
    "                           cv=5)\n",
    "\n",
    "# Fit the model on training data and find optimal parameters based on performance metric (default is accuracy)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get best parameters found during grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best estimator/model for predictions on test data \n",
    "y_pred = grid_search.predict(x_test)\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score (ROC AUC): \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd1a29f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/best_params_mlp_10k_50_50.json', 'w') as f: json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "011eb1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "-\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "-\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "-\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "-\n",
      "-\n",
      "country v2  start\n",
      "country v2 end\n",
      "-\n",
      "-\n",
      "-\n",
      "city v2  start\n",
      "city v2 end\n",
      "-\n",
      "-\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "-\n",
      "-\n",
      "encode_stuff start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\1991897665.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[scaled_feature_names] = scaled_features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_stuff end\n",
      "-\n",
      "-\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n",
      "-\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "-\n",
      "-\n",
      "-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1.0, 'penalty': 'l2', 'solver': 'saga'}\n",
      "0.5863333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "df4 = pd.read_csv('data/df3_10k_50n_50p.csv')\n",
    "\n",
    "\n",
    "df4 = ad_campaign(df4)\n",
    "df4 = day_of_week(df4)\n",
    "df4 = empties(df4)\n",
    "df4 = resolution_func(df4)\n",
    "df4 = country_v_2(df4)\n",
    "df4 = city_v_2(df4)\n",
    "df4 = device_brand(df4)\n",
    "df4 = encode_stuff(df4)\n",
    "df4 = scale_stuff(df4)\n",
    "df4 = filter_stuff(df4)\n",
    "\n",
    "y = df4['event_action']\n",
    "x = df4.drop('event_action', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\n",
    "\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],                # Regularization penalty ('l1' or 'l2')\n",
    "    'C': [0.01, 0.1, 1.0],                   # Inverse regularization strength (smaller values specify stronger regularization)\n",
    "    'solver': ['liblinear', 'saga']          # Algorithm to use in optimization problem\n",
    "}\n",
    "\n",
    "# Create Logistic Regression classifier object\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Perform Grid Search with cross-validation (e.g., using k-fold CV)\n",
    "grid_search = GridSearchCV(estimator=lr_model, param_grid=param_grid)\n",
    "\n",
    "# Fit the model on training data and find optimal parameters based on performance metric (default is accuracy)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get best parameters found during grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best estimator/model for predictions on test data \n",
    "y_pred = grid_search.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a6d44992",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/best_params_rf_10k_50_50.json', 'w') as f: json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e7ee9da5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_campaign start\n",
      "ad_campaign end\n",
      "-\n",
      "-\n",
      "-\n",
      "day_of_week start\n",
      "day_of_week end\n",
      "-\n",
      "-\n",
      "-\n",
      "empties end\n",
      "empties end\n",
      "-\n",
      "-\n",
      "-\n",
      "resolution_func start\n",
      "resolution_func end\n",
      "-\n",
      "-\n",
      "-\n",
      "country v2  start\n",
      "country v2 end\n",
      "-\n",
      "-\n",
      "-\n",
      "city v2  start\n",
      "city v2 end\n",
      "-\n",
      "-\n",
      "-\n",
      "device_brand start\n",
      "device_brand end\n",
      "-\n",
      "-\n",
      "-\n",
      "encode_stuff start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\2796334439.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[feature_names] = encoded_df3.values\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11464\\1991897665.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df3[scaled_feature_names] = scaled_features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_stuff end\n",
      "-\n",
      "-\n",
      "-\n",
      "scale_stuff start\n",
      "scale_stuff end\n",
      "-\n",
      "-\n",
      "-\n",
      "filter_stuff start\n",
      "filter_stuff end\n",
      "-\n",
      "-\n",
      "-\n",
      "Best Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 300}\n",
      "0.5943333333333334\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv('data/df3_10k_50n_50p.csv')\n",
    "\n",
    "\n",
    "df4 = ad_campaign(df4)\n",
    "df4 = day_of_week(df4)\n",
    "df4 = empties(df4)\n",
    "df4 = resolution_func(df4)\n",
    "df4 = country_v_2(df4)\n",
    "df4 = city_v_2(df4)\n",
    "df4 = device_brand(df4)\n",
    "df4 = encode_stuff(df4)\n",
    "df4 = scale_stuff(df4)\n",
    "df4 = filter_stuff(df4)\n",
    "\n",
    "y = df4['event_action']\n",
    "x = df4.drop('event_action', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400],    # Number of trees in the forest\n",
    "    'max_depth': [None, 5, 10],          # Maximum depth of each tree\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'min_samples_split': [2, 5, 10], # Minimum number of samples required to split an internal node\n",
    "}\n",
    "\n",
    "# Create Random Forest classifier object\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Perform Grid Search with cross-validation (e.g., using k-fold CV)\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid)\n",
    "\n",
    "# Fit the model on training data and find optimal parameters based on performance metric (default is accuracy)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get best parameters found during grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Use the best estimator/model for predictions on test data \n",
    "y_pred = grid_search.predict(x_test)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "47e21c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200k, 70n\\x18p'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
